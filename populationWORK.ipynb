{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anzahl der einzigartigen Städte im Datensatz: 5156\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# CSV-Datei laden\n",
    "url = 'https://datahub.io/core/population-city/r/unsd-citypopulation-year-both.csv'\n",
    "data = pd.read_csv(url)\n",
    "\n",
    "# Anzahl der einzigartigen Städte ermitteln\n",
    "unique_cities = data['City'].nunique()\n",
    "print(f\"Anzahl der einzigartigen Städte im Datensatz: {unique_cities}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import requests\n",
    "from meteostat import Daily, Stations\n",
    "from datetime import datetime\n",
    "from data_preparation import download_files, files, output_folder\n",
    "from data_preparation import data_import, data_cleaning, weather_data, geo_data, convert_date, population_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spalte 'Specie' fehlt in airquality-covid19-cities.json\n",
      "waqi-covid-2022Q1.csv enthält nach Duplikat-Entfernung keine Daten mehr.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>Specie</th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>median</th>\n",
       "      <th>variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>KR</td>\n",
       "      <td>Jeonju</td>\n",
       "      <td>co</td>\n",
       "      <td>124</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12.3</td>\n",
       "      <td>4.5</td>\n",
       "      <td>55.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-01-22</td>\n",
       "      <td>KR</td>\n",
       "      <td>Jeonju</td>\n",
       "      <td>co</td>\n",
       "      <td>116</td>\n",
       "      <td>4.5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.7</td>\n",
       "      <td>16.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-03-30</td>\n",
       "      <td>KR</td>\n",
       "      <td>Jeonju</td>\n",
       "      <td>co</td>\n",
       "      <td>118</td>\n",
       "      <td>1.2</td>\n",
       "      <td>11.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>35.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-27</td>\n",
       "      <td>KR</td>\n",
       "      <td>Jeonju</td>\n",
       "      <td>co</td>\n",
       "      <td>93</td>\n",
       "      <td>2.3</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>6.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-02-03</td>\n",
       "      <td>KR</td>\n",
       "      <td>Jeonju</td>\n",
       "      <td>co</td>\n",
       "      <td>133</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13.4</td>\n",
       "      <td>7.8</td>\n",
       "      <td>39.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Date Country    City Specie  count  min   max  median  variance\n",
       "0  2015-01-06      KR  Jeonju     co    124  0.1  12.3     4.5     55.74\n",
       "1  2015-01-22      KR  Jeonju     co    116  4.5  10.0     6.7     16.09\n",
       "2  2015-03-30      KR  Jeonju     co    118  1.2  11.2     5.6     35.98\n",
       "3  2015-05-27      KR  Jeonju     co     93  2.3   5.6     3.4      6.54\n",
       "4  2015-02-03      KR  Jeonju     co    133  4.5  13.4     7.8     39.24"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data_import()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keine Geodaten gefunden für: washington d.c.\n",
      "✅ Wetterdaten gesammelt für 578 Städte\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "FutureWarning: SeriesGroupBy.fillna is deprecated and will be removed in a future version. Use obj.ffill() or obj.bfill() for forward or backward filling instead. If you want to fill with a single value, use Series.fillna instead\n",
      "FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Datei wurde gespeichert: ./data/population_data.csv\n",
      "✅ Datei wurde gespeichert: ./data/cleaned_data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "      <th>Population</th>\n",
       "      <th>Co</th>\n",
       "      <th>No2</th>\n",
       "      <th>...</th>\n",
       "      <th>So2</th>\n",
       "      <th>Dew</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Tavg</th>\n",
       "      <th>Tmin</th>\n",
       "      <th>Tmax</th>\n",
       "      <th>Prcp</th>\n",
       "      <th>Wdir</th>\n",
       "      <th>Wspd</th>\n",
       "      <th>Pres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "      <td>SA</td>\n",
       "      <td>Abha</td>\n",
       "      <td>18.21639</td>\n",
       "      <td>42.50528</td>\n",
       "      <td>5616633.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>15.8</td>\n",
       "      <td>24.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>183.0</td>\n",
       "      <td>21.9</td>\n",
       "      <td>1022.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>SA</td>\n",
       "      <td>Abha</td>\n",
       "      <td>18.21639</td>\n",
       "      <td>42.50528</td>\n",
       "      <td>5616633.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>13.5</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>185.0</td>\n",
       "      <td>21.2</td>\n",
       "      <td>1021.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>SA</td>\n",
       "      <td>Abha</td>\n",
       "      <td>18.21639</td>\n",
       "      <td>42.50528</td>\n",
       "      <td>5616633.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>10.8</td>\n",
       "      <td>23.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>186.0</td>\n",
       "      <td>15.2</td>\n",
       "      <td>1022.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>SA</td>\n",
       "      <td>Abha</td>\n",
       "      <td>18.21639</td>\n",
       "      <td>42.50528</td>\n",
       "      <td>5616633.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>15.9</td>\n",
       "      <td>10.8</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>196.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>1023.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>SA</td>\n",
       "      <td>Abha</td>\n",
       "      <td>18.21639</td>\n",
       "      <td>42.50528</td>\n",
       "      <td>5616633.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>58.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>22.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.2</td>\n",
       "      <td>1023.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year  Month  Day Country  City  Latitude  Longitude  Population  Co  No2  \\\n",
       "0  2019      2   28      SA  Abha  18.21639   42.50528   5616633.0 NaN  NaN   \n",
       "1  2019      3    1      SA  Abha  18.21639   42.50528   5616633.0 NaN  NaN   \n",
       "2  2019      3    2      SA  Abha  18.21639   42.50528   5616633.0 NaN  0.0   \n",
       "3  2019      3    3      SA  Abha  18.21639   42.50528   5616633.0 NaN  0.0   \n",
       "4  2019      3    4      SA  Abha  18.21639   42.50528   5616633.0 NaN  0.0   \n",
       "\n",
       "   ...  So2   Dew  Humidity  Tavg  Tmin  Tmax  Prcp   Wdir  Wspd    Pres  \n",
       "0  ...  NaN   6.0      45.0  18.8  15.8  24.1   NaN  183.0  21.9  1022.3  \n",
       "1  ...  NaN  12.0      64.0  17.0  13.5  23.0   NaN  185.0  21.2  1021.9  \n",
       "2  ...  0.0   9.0      63.0  16.7  10.8  23.6   NaN  186.0  15.2  1022.3  \n",
       "3  ...  0.0   6.0      55.0  15.9  10.8  22.0   NaN  196.0  16.5  1023.4  \n",
       "4  ...  0.0   3.0      58.0  16.1   9.0  22.5   NaN    NaN  11.2  1023.8  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=data_cleaning(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Year', 'Month', 'Day', 'Country', 'City', 'Latitude', 'Longitude',\n",
       "       'Population', 'Co', 'No2', 'O3', 'Pm10', 'Pm25', 'So2', 'Dew',\n",
       "       'Humidity', 'Tavg', 'Tmin', 'Tmax', 'Prcp', 'Wdir', 'Wspd', 'Pres'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['variance', 'min', 'max'], errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.groupby([\"Date\", \"Country\", \"City\", \"Specie\"], as_index=False).agg({\"median\": \"mean\"})  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.pivot(index=[\"Date\", \"Country\", \"City\"], columns=\"Specie\", values='median').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"City\"] = df[\"City\"].str.lower().str.strip()\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = geo_data(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = weather_data(df)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_date(df)\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['City'] = df['City'].str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population = pd.read_csv(\n",
    "                    './data/population.csv',\n",
    "                    sep=',', \n",
    "                    header=0,\n",
    "                    engine='python',  # Hilft oft bei Parsing-Problemen\n",
    "                    on_bad_lines='skip',  # Methode zum Überspringen von fehlerhaften Zeilen\n",
    "                    encoding='utf-8')  # Falls Sonderzeichen vorhanden sind\n",
    "df_population.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population = df_population[['City', 'Value', 'Year']]\n",
    "df_population.rename(columns={'Value': 'Population'}, inplace=True)\n",
    "df_population.dropna(inplace=True)\n",
    "df_population['Population'] = df_population['Population'].astype(int)\n",
    "df_population.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spaltennamen anpassen\n",
    "df.columns = df.columns.str.capitalize()\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "df_population['Year'] = df_population['Year'].astype(int)\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sortieren nach 'City' und 'Year'\n",
    "df = df.sort_values(by=['City', 'Year']).reset_index(drop=True)\n",
    "print(df.head(10))\n",
    "df_population = df_population.sort_values(by=['City', 'Year']).reset_index(drop=True)\n",
    "df_population.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # **Nochmal sicherstellen, dass die Sortierung stimmt**\n",
    "# if not df['Year'].is_monotonic_increasing:\n",
    "#     raise ValueError(\"❌ 'df' ist nicht korrekt sortiert! Überprüfe die Sortierung nach 'Year'.\")\n",
    "# if not df_population['Year'].is_monotonic_increasing:\n",
    "#     raise ValueError(\"❌ 'df_population' ist nicht korrekt sortiert!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!!!!\n",
    "df = df.merge(df_population, on=['City', 'Year'], how='left')\n",
    "df['Population'] = df.groupby('City')['Population'].fillna(method='ffill').fillna(method='bfill')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.sample(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df['Population'].isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "    # Merge mit dem nächstgelegenen Jahr\n",
    "    df = pd.merge_asof(df, df_population, on='Year', by='City', direction='nearest')\n",
    "\n",
    "    # Datei speichern\n",
    "    output_path = './data/population_data.csv'\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✅ Datei wurde gespeichert: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    \"\"\"Bereinigung der Daten\n",
    "    - nicht benötigte Spalten löschen\n",
    "    - Zusammenfassung der Daten nach Datum, Land, Stadt und Spezies, so dass nur ein Messwert je Species (Median) pro Tag/ Stadt verbleibt\n",
    "    - Spalte Species aufteilen\n",
    "    - df als csv speichern im Datenverzeichnis\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df.drop(columns=['variance', 'min', 'max'], errors='ignore')\n",
    "\n",
    "    df = df.groupby([\"Date\", \"Country\", \"City\", \"Specie\"], as_index=False).agg({\"median\": \"mean\"})  \n",
    "\n",
    "    df = df.pivot(index=[\"Date\", \"Country\", \"City\"], columns=\"Specie\", values='median').reset_index()\n",
    "\n",
    "    df[\"City\"] = df[\"City\"].str.lower().str.strip()\n",
    "    df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    df = geo_data(df)\n",
    "\n",
    "    df = weather_data(df)\n",
    "\n",
    "    df = convert_date(df)\n",
    "\n",
    "    df['City'] = df['City'].str.capitalize()\n",
    "\n",
    "    df = population_data(df)\n",
    "\n",
    "    #spalten sortieren\n",
    "    df = df[['Year', 'Month', 'Day', 'Country', 'City', 'Latitude', 'Longitude', 'Population', 'Co', 'No2', 'O3', 'Pm10', 'Pm25',\n",
    "       'Pressure', 'So2', 'Temperature', 'Wind-gust', 'Wind-speed', 'Dew', 'Humidity', 'Tavg', 'Tmin', 'Tmax', 'Prcp', 'Wdir', 'Wspd', 'Pres',\n",
    "        ]]\n",
    "\n",
    "    #Redundante Wetter-Spalten löschen\n",
    "    df = df.drop(columns=[['Precipitation', 'Pressure', 'Uvi', 'Wd']], errors='ignore')\n",
    "    df = df.drop(columns=[['Temperature', 'Wind-gust', 'Wind-speed']], errors='ignore')\n",
    "\n",
    "    #Spalten mit mehr als 90% NaNs löschen\n",
    "    df = df.loc[:, df.isnull().mean() < 0.9]\n",
    "\n",
    "    output_path = './data/cleaned_data.csv'\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✅ Datei wurde gespeichert: {output_path}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.copy()\n",
    "df = data_cleaning(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alle raus, wo mehr al 90% der daten fehlen (aqi, D, Mepaqi, Neph, Pm1, Pol, Precipittion, psi, Temperature\tUvi\tWd\tWind-gust\tWind-speed ) # type: ignore\n",
    "# wetterdaten aus einer quelle\n",
    "# spalten sortieren\n",
    "# wo sind die pop daten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Funktion für Übersicht über dtypes, missing values, unique values etc.\n",
    "def overview(df):\n",
    "    '''\n",
    "     Erstelle einen Überblick über einige Eigenschaften der Spalten eines DataFrames.\n",
    "     VARs\n",
    "         df: Der zu betrachtende DataFrame\n",
    "     RETURNS:\n",
    "         None\n",
    "     '''\n",
    "    display(pd.DataFrame({'dtype': df.dtypes,\n",
    "                           'total': df.count(),\n",
    "                           'missing': df.isna().sum(),\n",
    "                           'missing%': df.isna().mean()*100,\n",
    "                           'n_uniques': df.nunique(),\n",
    "                           'uniques%': df.nunique()/df.shape[0]*100,\n",
    "                           'uniques': [df[col].unique() for col in df.columns]\n",
    "                          }))\n",
    "    #return overview(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[:, df.isnull().mean() < 0.9]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(df):\n",
    "    # Convert 'Date' column to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # Split 'Date' column into 'year', 'month' and 'day'\n",
    "    df['year'] = df['Date'].dt.year\n",
    "    df['month'] = df['Date'].dt.month\n",
    "    df['day'] = df['Date'].dt.day\n",
    "\n",
    "    # Remove 'Date' column\n",
    "    if 'Date' in df.columns:\n",
    "        df.drop(columns=['Date'], inplace=True)\n",
    "    \n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_=convert_date(df)\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def population_data(df):\n",
    "    '''\n",
    "    Fügt dem jeder Stadt Einwohner hinzu\n",
    "    '''\n",
    "    df = df.copy()\n",
    "    \n",
    "    df_population = pd.read_csv(\n",
    "                    './data/population.csv',\n",
    "                    sep=',', \n",
    "                    header=0,\n",
    "                    engine='python',  # Hilft oft bei Parsing-Problemen\n",
    "                    on_bad_lines='skip',  # Methode zum Überspringen von fehlerhaften Zeilen\n",
    "                    encoding='utf-8')  # Falls Sonderzeichen vorhanden sind\n",
    "\n",
    "\n",
    "    df_population = df_population[['City', 'Value', 'Year']]\n",
    "    df_population.rename(columns={'Value': 'Population'}, inplace=True)\n",
    "    df_population.dropna(inplace=True)\n",
    "    df_population['Population'] = df_population['Population'].astype(int)\n",
    "\n",
    "    # Sicherstellen, dass die Spaltennamen übereinstimmen\n",
    "    df.columns = df.columns.str.capitalize()\n",
    "    df['Year'] = df['Year'].astype(int)\n",
    "    df_population['Year'] = df_population['Year'].astype(int)\n",
    "\n",
    "    # Sortieren für merge_asof (wichtig!)\n",
    "    df = df.sort_values(by=['City', 'Year'])\n",
    "    df_population = df_population.sort_values(by=['City', 'Year'])\n",
    "\n",
    "    # Merge mit nächstgelegenem Jahr\n",
    "    df = pd.merge_asof(df, df_population, on='Year', by='City', direction='nearest')\n",
    "\n",
    "    # Datei speichern\n",
    "    output_path = './data/population_data.csv'\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✅ Datei wurde gespeichert: {output_path}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ALTE DEF()\n",
    "# def population_data(df):\n",
    "#     '''\n",
    "#     Fügt dem jeder Stadt Einwohner hinzu\n",
    "#     '''\n",
    "#     df = df.copy()\n",
    "    \n",
    "#     df_population = pd.read_csv(\n",
    "#                     './data/population.csv',\n",
    "#                     sep=',', \n",
    "#                     header=0,\n",
    "#                     engine='python',  # Hilft oft bei Parsing-Problemen\n",
    "#                     on_bad_lines='skip',  # Methode zum Überspringen von fehlerhaften Zeilen\n",
    "#                     encoding='utf-8')  # Falls Sonderzeichen vorhanden sind\n",
    "\n",
    "#     df_population = df_population[['City', 'Value', 'Year']]\n",
    "\n",
    "#     df_population.rename(columns={'Value': 'Population'}, inplace=True)\n",
    "\n",
    "#     df_population.dropna(inplace=True)\n",
    "#     df_population['Population'] = df_population['Population'].astype(int)\n",
    "\n",
    "#     # Merge der beiden DataFrames basierend auf der \"City\"-Spalte\n",
    "#     df.columns = df.columns.str.capitalize()\n",
    "#     df['Year'] = df['Year'].astype(int)\n",
    "#     df_population['Year'] = df_population['Year'].astype(int)\n",
    "#     df = pd.merge(df, df_population, on=['City', 'Year'], how='left')\n",
    "    \n",
    "\n",
    "#     output_path = './data/population_data.csv'\n",
    "#     os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "#     df_population.to_csv(output_path, index=False)\n",
    "#     print(f\"✅ Datei wurde gespeichert: {output_path}\")\n",
    "\n",
    "#     return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_['City'] = df_['City'].str.capitalize()\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_= population_data(df_)\n",
    "print(df_.shape)\n",
    "df_.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population = population_data(df)\n",
    "df_population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = df.columns.str.capitalize()\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "df_population['Year'] = df_population['Year'].astype(int)\n",
    "df = pd.merge(df, df_population, on=['City', 'Year'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(df):\n",
    "    \"\"\"\n",
    "    Teilt die Spalte Date in Year, Month, Day auf\n",
    "    \"\"\"\n",
    "    # Convert 'Date' column to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # Split 'Date' column into 'year', 'month' and 'day'\n",
    "    df['year'] = df['Date'].dt.year\n",
    "    df['month'] = df['Date'].dt.month\n",
    "    df['day'] = df['Date'].dt.day\n",
    "\n",
    "    # Remove 'Date' column\n",
    "    if 'Date' in df.columns:\n",
    "        df.drop(columns=['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=data_cleaning(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population = pd.read_csv(\n",
    "    '/Users/whypk/01Projekte/air_quality/data/population.csv',\n",
    "    sep=',', \n",
    "    header=0,\n",
    "    engine='python',  # Hilft oft bei Parsing-Problemen\n",
    "    on_bad_lines='skip',  # Methode zum Überspringen von fehlerhaften Zeilen\n",
    "    encoding='utf-8'  # Falls Sonderzeichen vorhanden sind\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_population.head())\n",
    "print(df_population.columns)\n",
    "print(df_population.dtypes)\n",
    "print(df_population.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population= df_population[['City', 'Value', 'Year']]\n",
    "df_population.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#df_population['population'] = df_population['population'].astype(int)\n",
    "#df_population[\"City\"] = df_population[\"City\"].str.lower().str.strip()\n",
    "df_population.rename(columns={'Value': 'Population'}, inplace=True)\n",
    "df_population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_population.dropna(inplace=True)\n",
    "df_population['Population'] = df_population['Population'].astype(int)\n",
    "df_population.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = pd.merge(df, df_population, on=['City', 'Year'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_path = './data/population_data.csv'\n",
    "os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "df_population.to_csv(output_path, index=False)\n",
    "print(f\"✅ Datei wurde gespeichert: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge der beiden DataFrames basierend auf der \"City\"-Spalte\n",
    "df_merged = pd.merge(df, df_population, on='City', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funktion für Übersicht über dtypes, missing values, unique values etc.\n",
    "def overview(df):\n",
    "    '''\n",
    "    Erstelle einen Überblick über einige Eigenschaften der Spalten eines DataFrames.\n",
    "    VARs\n",
    "        df: Der zu betrachtende DataFrame\n",
    "    RETURNS:\n",
    "        None\n",
    "    '''\n",
    "    display(pd.DataFrame({'dtype': df.dtypes,\n",
    "                          'total': df.count(),\n",
    "                          'missing': df.isna().sum(),\n",
    "                          'missing%': df.isna().mean()*100,\n",
    "                          'n_uniques': df.nunique(),\n",
    "                          'uniques%': df.nunique()/df.shape[0]*100,\n",
    "                          'uniques': [df[col].unique() for col in df.columns]\n",
    "                         }))\n",
    "overview(df_population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filtered_population = df_population[df_population['City'].isin(df['City'])][['Country or Area','City', 'Year', 'City type', 'Value']]\n",
    "df_filtered_population['Value'] = df_filtered_population['Value'].astype(int)\n",
    "df_filtered_population.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
