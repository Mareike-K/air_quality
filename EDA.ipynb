{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inhaltsübersicht EDA\n",
    "TD = To Do, TBD = To Be Determined)\n",
    "\n",
    "### 1. Überblick über den Datensatz\n",
    "- Spaltenbeschreibung/Datentypen: Funktion overview()\n",
    "- Fehlende Werte (NaN-Anteile berechnet, diskutiert)\n",
    "\n",
    "- TD: evtl. kurze Beschreibung der Daten (Ursprung, Umfang) --> ins Datenwörterbuch oder DataHowTo\n",
    "\n",
    "### 2. Datenbereinigung\n",
    "- Entfernen unrealistischer Ausreißer (Schadstoffe, Wetterdaten) --> Städte auch noch überprüfen?\n",
    "- Zellenweise Ersetzung durch NaN (statt Zeilenlöschung)\n",
    "- Dokumentaton der Schwellenwerte und Filterlogik\n",
    "\n",
    "- TD: evtl. Tabelle oder Text mit Anzahl der entfernten/extremen Werte\n",
    "\n",
    "### 3. Deskriptive Statistik (Grundanalyse)\n",
    "- describe()-Tabellen für Schadstoffe und Wetterdaten\n",
    "- Vergleich von Mean und Median zu Einschätzung der Schiefe\n",
    "- Berechnung der Schiefe (skew)\n",
    "\n",
    "### 4. Visualisierungen\n",
    "- Stripplots zur Ausreißererkennung für alle numerischen Spalten\n",
    "- Histogramme für ausgewählte Variablen, zur Visualisierung der Schiefe hauptsächlich, aber auch für Platzhalterwerte\n",
    "- Korrelationsmatrix (Pearson) --> Dreieck\n",
    "\n",
    "- TD: Lineplots mit Mittelwert und Streuung (für einzelnen Schadstoffe, noch ausbaufähig)\n",
    "- TD: Weitere Diagramme nach Gruppen (Stadt, Jahr, Kontinent, etc.)\n",
    "\n",
    "### 5. Korrelationsanalyse\n",
    "- Korrelationen berechnet und interpretiert\n",
    "- Stärkste Korrelationen identifiziert und dokumentiert\n",
    "- Empfehlung zur Variablenselektion (evtl. PCA) gegeben\n",
    "\n",
    "### 6. Prüfung auffälliger Größen/Städte (Feedback-Loop aus der Clusteranalyse; weiter oben bei Ausreißerbestimmung einbauen?)\n",
    "- Geprüft wurden: Ashkelon, Ashdod, Netanya\n",
    "\n",
    "- TD: Weitere Städte prüfen (z.B. Tehran noch mal genau berechnen)\n",
    "\n",
    "### 7. Vorbereitung für Clustering und andere Modellierungen\n",
    "- Welche Features sollen verwendet werden?\n",
    "- Standardisierung / Skalierung wie?\n",
    "- Ziel der Clusteranalyse formulieren\n",
    "\n",
    "Allgemein: Dokumentation & Kommunikation\n",
    "- Kommentare und Begründungen im Code, aber mit Markdown\n",
    "- Einführung und Fazit zur EDA?\n",
    "- Strukturierung der finalen NB-Version für GitHub\n",
    "- TD: Einzelergebnisse abspeichern als csv\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fragen/Kommentare von Mareike an Wiebke\n",
    "\n",
    "- Abschnitt 1: Was machen wir mit den Bevölkerungsdaten? 78% fehlen. Kleine separate Analyse nur mit den Städten, wo wir die Daten haben?\n",
    "\n",
    "- Die bereinigten Daten, ohne Ausreißer habe ich in \"cleaned_air_quality_data\" & Datum gespeichert. Das Datum nehmen wir am Ende wohl besser wieder raus. Das ist nur jetzt eine Krücke, falls was kaputtgeht.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Datensatz laden\n",
    "\n",
    "- Spaltennamen überprüfen\n",
    "- redundante Spalten entfernen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# import os\n",
    "# import matplotlib\n",
    "# import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for displaying floats\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./data/cleaned_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns\n",
    "\n",
    "# Some redundant columns still need to be removed from df manually: Temperature, Pressure, Wind-speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop redundant columns (--> könnte man auch in der cleaning pipeline machen)\n",
    "\n",
    "df = df.drop(columns=['Temperature', 'Wind-speed', 'Pressure'])\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Überblick über den Datensatz verschaffen\n",
    "\n",
    "- Überblicksfunktion .overview()\n",
    "- Fehlende Werte ausloten und Spalten mit < 50% Daten entfernen --> Das müssen wir noch besprechen (Population)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create overview for dtypes, missing values, unique values\n",
    "\n",
    "def overview(df):\n",
    "    '''\n",
    "    Erstelle einen Überblick über einige Eigenschaften der Spalten eines DataFrames.\n",
    "    VARs\n",
    "        df: Der zu betrachtende DataFrame\n",
    "    RETURNS:\n",
    "        None\n",
    "    '''\n",
    "    display(pd.DataFrame({'dtype': df.dtypes,\n",
    "                          'total': df.count(),\n",
    "                          'missing': df.isna().sum(),\n",
    "                          'missing%': df.isna().mean()*100,\n",
    "                          'n_uniques': df.nunique(),\n",
    "                          'uniques%': df.nunique()/df.shape[0]*100,\n",
    "                          'uniques': [df[col].unique() for col in df.columns]\n",
    "                         }))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on missing values: Sort missing values (descending)\n",
    "\n",
    "missing_percent = df.isna().mean() * 100\n",
    "missing_percent_sorted = missing_percent.sort_values(ascending=False)\n",
    "\n",
    "print(missing_percent_sorted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all columns with more than 50% missing values\n",
    "# Note: This removes population data entirely!\n",
    "\n",
    "# Anzahl der Spalten vor dem Entfernen merken\n",
    "original_columns = df.shape[1]\n",
    "\n",
    "df = df.loc[:, missing_percent <= 50]\n",
    "\n",
    "# Print what has changed\n",
    "print(f\"Anzahl der entfernten Spalten: {original_columns - df.shape[1]}\")\n",
    "removed = missing_percent[missing_percent > 50].index\n",
    "print(\"Entfernte Spalten:\", list(removed))\n",
    "print(\"Übrige Spalten:\", df.columns)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deskriptive Statistik\n",
    "\n",
    "Dataset has many variables. Statistics will be split up into pollutants, weather and location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of data on pollutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pollutants\n",
    "\n",
    "pollutant_cols = [\"Co\", \"Pm25\", \"Pm10\", \"So2\", \"No2\", \"O3\"]\n",
    "df[pollutant_cols].describe().T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einige Messwerte wie Co = 500 oder Pm25 = 999 deuten auf Platzhalter für fehlende oder ungültige Daten hin und verzerren die Verteilung erheblich. Diese Werte könnten fehlerhaft sein und sollten aus der Analyse ausgeschlossen werden."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse und Bereinigung der Pm25-Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Pm25\"].sort_values(ascending=False).unique() [:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(x=df[\"Pm25\"], size=2, jitter=0.3)\n",
    "plt.title(\"PM2.5 Einzelwerte\")\n",
    "plt.xlabel(\"PM2.5-Konzentration (µg/m³)\")\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation der Pm25-Werte VOR Bereinigung des Datensatzes\n",
    "Bei der visuellen Analyse der PM2.5-Messwerte fällt eine ungewöhnliche Häufung im Bereich zwischen 816 und 834 µg/m³ auf, begleitet von vereinzelten extrem hohen Werten bei 981 und 999 µg/m³. Diese Werte liegen deutlich außerhalb des realistischen Messbereichs und deuten auf Messfehler, Platzhalterwerte oder systembedingte Übertragungsfehler hin. Um die Analyse nicht zu verzerren, werden daher alle PM2.5-Werte ab 816 µg/m³ ausgeschlossen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PM2.5 >= 816\n",
    "df.loc[df[\"Pm25\"] >= 816, \"Pm25\"] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[\"Pm25\"], bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Die Verteilung der Messwerte wirkt nach dem Entfernen der unrealistischen Werte rechtsschief. Überprüfung mit Vergleich Mean/Median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pm25 = df[\"Pm25\"].mean()\n",
    "median_pm25 = df[\"Pm25\"].median()\n",
    "\n",
    "print(f\"Mittelwert (mean): {mean_pm25:.2f}\")\n",
    "print(f\"Median:            {median_pm25:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew\n",
    "\n",
    "skew_pm25 = skew(df[\"Pm25\"].dropna())\n",
    "print(f\"Schiefe (Skewness): {skew_pm25:.2f}\")\n",
    "\n",
    "# Skewness > 0 --> rechtsschiefe Verteilung."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verteilung der bereinigten PM2.5-Werte (Fazit)\n",
    "\n",
    "Die PM2.5-Werte zeigen eine deutlich rechtsschiefe Verteilung. Der Mittelwert liegt bei 53,19 µg/m³, während der Median nur 42,00 µg/m³ beträgt. Zusätzlich ergibt die Berechnung der Schiefe (Skewness) einen Wert von 2,26, was auf eine starke Asymmetrie hindeutet.\n",
    "Diese rechtsschiefe Verteilung bedeutet, dass der Großteil der Messwerte im unteren Bereich liegt, während einige wenige sehr hohe Werte den Mittelwert nach oben ziehen.\n",
    "\n",
    "Um die Analyse nicht durch technisch bedingte Ausreißer zu verzerren, wurden alle PM2.5-Werte ab 816 µg/m³ ausgeschlossen, da sie deutlich außerhalb des natürlichen Messbereichs liegen und teilweise systematisch auftraten."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse und Bereinigung der CO-Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Co\"].sort_values(ascending=False).unique()[:30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(x=df[\"Co\"], size=2, jitter=0.3)\n",
    "plt.title(\"CO Einzelwerte\")\n",
    "plt.xlabel(\"CO-Konzentration (µg/m³)\")\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation der Pm25-Werte VOR Bereinigung des Datensatzes\n",
    "Es gibt zwar einen eindeutigen Platzhalterwert, aber alle anderen Messwerte könnten theoretisch realistisch sein. Überprüfung der Verteilung mit Mean/Median, um den Cutoff festzulegen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_co = df[\"Co\"].mean()\n",
    "median_co = df[\"Co\"].median()\n",
    "skew_co = skew(df[\"Co\"].dropna())\n",
    "\n",
    "print(f\"Mittelwert (mean): {mean_co:.2f}\")\n",
    "print(f\"Median:            {median_co:.2f}\")\n",
    "print(f\"Schiefe:           {skew_co:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bereinigte CO-Werte (Begründung)\n",
    "\n",
    "Die Verteilung der CO-Messwerte ist stark rechtsschief, mit einem Mittelwert von 4.74 µg/m³, einem Median von 3.40 µg/m³ und einer Schiefe von 29.64. Dies deutet auf extreme Ausreißer hin, die den Mittelwert erheblich verzerren. Zusätzlich tritt eine auffällige Häufung exakt bei 500 µg/m³ auf, was sehr wahrscheinlich ein technischer Platzhalterwert ist.\n",
    "\n",
    "Um die Aussagekraft der Analyse zu erhöhen, wurden daher alle Werte ab 300 µg/m³ ausgeschlossen. Dieser Grenzwert liegt deutlich oberhalb der Hauptverteilung und entfernt sowohl technische Ausreißer als auch extreme Einzelwerte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CO > 300 oder CO == 500 → als NaN\n",
    "df.loc[df[\"Co\"] >= 300, \"Co\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse und Bereinigung der No2-Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(x=df[\"No2\"], size=2, jitter=0.3)\n",
    "plt.title(\"NO₂ Einzelwerte\")\n",
    "plt.xlabel(\"NO₂-Konzentration (µg/m³)\")\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_no2 = df[\"No2\"].mean()\n",
    "median_no2 = df[\"No2\"].median()\n",
    "skew_no2 = skew(df[\"No2\"].dropna())\n",
    "\n",
    "print(f\"Mittelwert (mean): {mean_no2:.2f}\")\n",
    "print(f\"Median:            {median_no2:.2f}\")\n",
    "print(f\"Schiefe:           {skew_no2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[\"No2\"], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO2 >= 300 oder == 500\n",
    "df.loc[df[\"No2\"] >= 300, \"No2\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bereinigung der NO₂-Werte\n",
    "Die NO₂-Werte zeigen eine stark rechtsschiefe Verteilung, mit einem Mittelwert von 10.55 µg/m³, einem Median von 8.40 µg/m³ und einer Schiefe von 10.08. Die große Mehrheit der Messwerte liegt unterhalb von 120 µg/m³, während einzelne Ausreißer bis 425 µg/m³ reichen. \n",
    "\n",
    "Zusätzlich tritt eine auffällige Häufung bei 500 µg/m³ auf, was sehr wahrscheinlich auf technische Platzhalterwerte zurückzuführen ist.\n",
    "Um die Analyse nicht durch extreme Einzelwerte zu verzerren, wurden alle NO₂-Werte ab 300 µg/m³ ausgeschlossen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"No2\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse und Bereinigung der So2-Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(x=df[\"So2\"], size=2, jitter=0.3)\n",
    "plt.title(\"SO₂ Einzelwerte\")\n",
    "plt.xlabel(\"SO₂-Konzentration (µg/m³)\")\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_so2 = df[\"So2\"].mean()\n",
    "median_so2 = df[\"So2\"].median()\n",
    "skew_so2 = skew(df[\"So2\"].dropna())\n",
    "\n",
    "print(f\"Mittelwert (mean): {mean_so2:.2f}\")\n",
    "print(f\"Median:            {median_so2:.2f}\")\n",
    "print(f\"Schiefe:           {skew_so2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SO2 >= 300 oder == 500\n",
    "df.loc[df[\"So2\"] >= 300, \"So2\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bereinigung der SO₂-Werte\n",
    "Die Verteilung der Schwefeldioxid-Werte ist stark rechtsschief, mit einem Mittelwert von 4.10 µg/m³, einem Median von 2.60 µg/m³ und einer Schiefe von 10.45. Die große Mehrheit der Messwerte liegt unterhalb von 80 µg/m³, darüber hinaus treten vereinzelt höhere Werte auf – einige davon sind durchaus plausibel.\n",
    "\n",
    "Auffällig ist jedoch eine Datenlücke im Bereich von 300 bis 400 µg/m³, gefolgt von insgesamt neun vereinzelten Extremwerten oberhalb von 400, von denen zwei exakt bei 500 µg/m³ liegen. Diese Muster deuten auf technisch bedingte Ausreißer oder Platzhalterwerte hin.\n",
    "Um die Aussagekraft der Analyse zu erhöhen, wurden daher alle SO₂-Werte ab 300 µg/m³ ausgeschlossen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse und Bereinigung der O3-Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(x=df[\"O3\"], size=2, jitter=0.3)\n",
    "plt.title(\"O3 Einzelwerte\")\n",
    "plt.xlabel(\"O3-Konzentration (µg/m³)\")\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_o3 = df[\"O3\"].mean()\n",
    "median_o3 = df[\"O3\"].median()\n",
    "skew_o3 = skew(df[\"O3\"].dropna())\n",
    "\n",
    "print(f\"Mittelwert (mean): {mean_o3:.2f}\")\n",
    "print(f\"Median:            {median_o3:.2f}\")\n",
    "print(f\"Schiefe:           {skew_o3:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[\"O3\"], bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# O3 >= 380 oder == 500\n",
    "df.loc[df[\"O3\"] >= 380, \"O3\"] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bereinigung der Ozon-Werte (O₃)\n",
    "Die Verteilung der Ozonwerte zeigt eine deutliche Rechtsschiefe mit einem Mittelwert von 20.01 µg/m³, einem Median von 19.10 µg/m³ und einer Schiefe von 7.71. Die große Mehrheit der Messwerte liegt unterhalb von 100 µg/m³, während vereinzelte Extremwerte bis ca. 320 µg/m³ auftreten, die jedoch noch plausibel erscheinen.\n",
    "\n",
    "Auffällig ist eine systematische Häufung im Bereich zwischen 380 und 390 µg/m³, die auf eine technisch bedingte Obergrenze oder einen Messfehler hinweist. Zusätzlich treten vereinzelte Werte beim Maximalwert von 500 µg/m³ auf, was stark auf einen Platzhalterwert schließen lässt.\n",
    "\n",
    "Um die Analyse nicht durch solche systematischen Ausreißer zu verzerren, wurden daher alle O₃-Werte ab 380 µg/m³ aus dem Datensatz ausgeschlossen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse und Bereinigung der Pm10-Werte"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(x=df[\"Pm10\"], size=2, jitter=0.3)\n",
    "plt.title(\"Pm10 Einzelwerte\")\n",
    "plt.xlabel(\"Pm10-Konzentration (µg/m³)\")\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Pm10\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_pm10 = df[\"Pm10\"].mean()\n",
    "median_pm10 = df[\"Pm10\"].median()\n",
    "skew_pm10 = skew(df[\"Pm10\"].dropna())\n",
    "\n",
    "print(f\"Mittelwert (mean): {mean_pm10:.2f}\")\n",
    "print(f\"Median:            {median_pm10:.2f}\")\n",
    "print(f\"Schiefe:           {skew_pm10:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.histplot(df[\"O3\"], bins=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACHTUNG: Der Cutoff bei PM10 ist nicht so eindeutig zu setzen wie bei den anderen Schadstoffen. Es sind also zusätzliche Berechnungen sinnvoll."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wo beginnt die Häufung bei der breiten Linie im Ausreißerbereich (ca. 820-840)?\n",
    "\n",
    "df[\"Pm10\"].value_counts().loc[lambda x: x.index > 820].sort_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"Datenmauer\" plotten (nicht wirklich nötig, aber \"Nice to have\" für Leute, die gerne Visualisierungen mögen...)\n",
    "\n",
    "high_values = df[\"Pm10\"][df[\"Pm10\"] > 800]\n",
    "sns.histplot(high_values, binwidth=1)\n",
    "plt.title(\"Häufigkeit der PM10-Werte > 800\")\n",
    "plt.xlabel(\"PM10-Wert (µg/m³)\")\n",
    "plt.ylabel(\"Anzahl\")\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PM10 >= 867\n",
    "df.loc[df[\"Pm10\"] >= 867, \"Pm10\"] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bereinigung der PM10-Werte\n",
    "Die PM10-Werte zeigen eine deutlich rechtsschiefe Verteilung mit einem Mittelwert von 32.43 µg/m³, einem Median von 24.00 µg/m³ und einer Schiefe von 7.17. Der größte Teil der Messwerte liegt unterhalb von 200 µg/m³, mit einer kontinuierlich abnehmenden Dichte bis in den Bereich von ca. 850 µg/m³.\n",
    "\n",
    "Eine detaillierte Analyse der Einzelwertverteilung ergab jedoch eine auffällige Häufung von Messwerten im Bereich 867–882 µg/m³, insbesondere 40 Messungen mit dem identischen Wert 867. Diese systematische Häufung spricht stark für einen technisch bedingten Fehler oder künstlich begrenzte Wertebereiche. Zusätzlich tritt der Platzhalterwert 999 33 Mal auf.\n",
    "\n",
    "Um die Analyse nicht durch diese systematischen Verzerrungen zu beeinflussen, wurden alle PM10-Werte ab 867 µg/m³ aus dem Datensatz ausgeschlossen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methode zum Entfernen von Platzhalterwerten und starken Ausreißern\n",
    "Zur Datenbereinigung wurden extreme Ausreißer in den Schadstoffwerten nicht durch das Entfernen ganzer Zeilen, sondern durch das gezielte Ersetzen der jeweiligen Zellen mit NaN behandelt. So bleiben andere valide Messwerte in der gleichen Zeile erhalten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overview(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beschreiben, was wir an der neuen, geputzen overview-Funktion sehen:\n",
    "Datensatz nicht wesentlich verändert, keine neuen Spalten mit über 50% fehlenden werten erzeigt\n",
    "Datensatz dadurch besser geeignet für bestimmte Analysen, die sensibel auf Ausreißer reagieren, wie z:B. Clusteranalyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse und Bereinigung der Wettervariablen\n",
    "Analog zum Vorgehen bei den Schadstoffen werden im Folgenden alle Wettervariablen untersucht und ggf. Platzhalterwerte und starke Ausreißer durch NaN ersetzt.\n",
    "\n",
    "Anmerkung: Man KÖNNTE auch nur die Platzhalterwerte durch NaN ersetzten und die Ausreißer gesondert kennzeichen. Aber darauf wird jetzt erst einmal verzichtet.\n",
    "\n",
    "Die Wettervariablen werden in einer Schleife am Stück abgehandelt. Da das Setzen der Grenzwerte und das Entfernen vn Ausreißern für jede Variable individuell entscheiden werden sollte, um möglichst alle realistischen Werte zu erhalten, wir dieser Schritt nachgelagert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Tavg\", \"Tmin\", \"Tmax\", \"Humidity\", \"Wspd\", \"Wdir\", \"Pres\", \"Prcp\", \"Dew\"]].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auswertung von describe()\n",
    "\n",
    "| Spalte | Bedingung für NaN                     | Begründung |\n",
    "|:-------|:--------------------------------------|:-----------|\n",
    "|Tavg    |                                       |                              |\n",
    "|Tmin    |                                       |                          |\n",
    "|Tmax\t |Tmax > 60\t                             |weit über weltweit beobachtete Temperaturen|\n",
    "|Humidity|Humidity < 0 oder > 100                |physikalisch unmöglich / Platzhalter |\n",
    "|Wspd\t |erst visuell prüfen, dann ggf. > 150   |Hurrikan-Grenze |\n",
    "|Wdir    |<0 oder >360                           |Windrichtung wird in Winkelgrad gemessen |\n",
    "|Pres\t |Pres > 1100\t                         |ungewöhnlich hoch → Messfehler möglich |\n",
    "|Prcp\t |nicht filtern, sondern visuell prüfen  |rechtsschiefe, aber plausible Naturverteilung\n",
    "|Dew\t |ggf. ab –70 prüfen                     |tendenziell realistisch, vorsichtiger Umgang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Schleife für Wettervariablen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_columns = [\"Tavg\", \"Tmin\", \"Tmax\", \"Humidity\", \"Wspd\", \"Wdir\", \"Pres\", \"Prcp\", \"Dew\"]\n",
    "\n",
    "for col in weather_columns:\n",
    "    print(f\"\\n📊 Analyse für: {col}\")\n",
    "    \n",
    "    # Stripplot\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    sns.stripplot(x=df[col], size=2, jitter=0.3)\n",
    "    plt.title(f\"{col} – Einzelwerte\")\n",
    "    plt.grid(True)\n",
    "    plt.xlabel(f\"{col}-Wert\")\n",
    "    plt.show()\n",
    "    \n",
    "    # Statistische Kennzahlen\n",
    "    mean_val = df[col].mean()\n",
    "    median_val = df[col].median()\n",
    "    skew_val = df[col].skew()\n",
    "    \n",
    "    print(f\"Mean:   {mean_val:.2f}\")\n",
    "    print(f\"Median: {median_val:.2f}\")\n",
    "    print(f\"Skew:   {skew_val:.2f}\")\n",
    "    \n",
    "    # Cutoff-Vorschlag (nur zur Orientierung)\n",
    "    cutoff = df[col].quantile(0.999)\n",
    "    print(f\"💡 99.9%-Quantil (nicht angewendet!): {cutoff:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cutoffbestimmung und Ausreißerentfernung für Wettervariablen\n",
    "\n",
    "Für Variablen, bei denen der Stripplot keine eindeutige Auskunft gibt, wird der Cutoff-Wert durch einen Blick auf die betreffenden Messwerte bestimmt:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutoff für Tmax genauer bestimmen; oberste 10 Messwerte anschauen:\n",
    "df[\"Tmax\"].value_counts().sort_index(ascending=False).head(10)\n",
    "\n",
    "# --> Cutoff bei 60 Grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Kurzer Neugierigkeitsexkurs zur Verteilung der Windrichtungen:\n",
    "# from windrose import WindroseAxes\n",
    "\n",
    "# # Entferne NaN-Werte aus Wdir\n",
    "# wind_dir = df[\"Wdir\"].dropna()\n",
    "\n",
    "# # Dummy-Windgeschwindigkeit von 1 m/s für alle Einträge (nur zur Visualisierung notwendig)\n",
    "# wind_speed_dummy = np.ones_like(wind_dir)\n",
    "\n",
    "# # Erzeuge Windrose\n",
    "# ax = WindroseAxes.from_ax()\n",
    "# ax.bar(wind_dir, wind_speed_dummy, normed=True, opening=0.8, edgecolor='white')\n",
    "\n",
    "# # Formatierung\n",
    "# ax.set_legend(False)\n",
    "# plt.title(\"Windrose: Häufigkeit der Windrichtungen\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Windrose für Wspd und Wdir zusammen:\n",
    "\n",
    "# wdir = df[\"Wdir\"].dropna()\n",
    "# wspd = df[\"Wspd\"].dropna()\n",
    "\n",
    "# wind_df = df[[\"Wdir\", \"Wspd\"]].dropna()\n",
    "\n",
    "# ax = WindroseAxes.from_ax()\n",
    "# ax.bar(wind_df[\"Wdir\"], wind_df[\"Wspd\"], normed=True, opening=0.8, edgecolor='white')\n",
    "\n",
    "# # Legende und Titel\n",
    "# ax.set_legend(title=\"Windgeschwindigkeit (km/h)\")\n",
    "# plt.title(\"Windrose: Windrichtung & Windgeschwindigkeit\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(df[\"Wspd\"].dropna(), bins=30)\n",
    "# plt.xlabel(\"Windgeschwindigkeit (km/h)\")\n",
    "# plt.title(\"Verteilung der Windgeschwindigkeiten\")\n",
    "# plt.grid(True)\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Sicherstellen, dass keine NaNs enthalten sind\n",
    "# wind_df = df[[\"Wdir\", \"Wspd\"]].dropna()\n",
    "\n",
    "# # Benutzerdefinierte Bins im realistischen Bereich\n",
    "# custom_bins = [0, 5, 10, 15, 20, 25]\n",
    "\n",
    "# # Windrose plotten\n",
    "# ax = WindroseAxes.from_ax()\n",
    "# ax.bar(\n",
    "#     wind_df[\"Wdir\"],\n",
    "#     wind_df[\"Wspd\"],\n",
    "#     bins=custom_bins,\n",
    "#     normed=True,\n",
    "#     opening=0.8,\n",
    "#     edgecolor=\"white\"\n",
    "# )\n",
    "\n",
    "# # Legende und Formatierung\n",
    "# ax.set_legend(title=\"Windgeschwindigkeit (km/h)\")\n",
    "# plt.title(\"Windrose: Häufigkeit und Stärke der Windrichtungen\")\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tmax: realistische Obergrenze bei 60°C\n",
    "df.loc[df[\"Tmax\"] > 60, \"Tmax\"] = np.nan\n",
    "\n",
    "# Humidity: alles < 0 oder > 100 ist physikalisch nicht (bzw. über 100% nur SEHR kurzzeitig) möglich\n",
    "df.loc[(df[\"Humidity\"] < 0) | (df[\"Humidity\"] > 100), \"Humidity\"] = np.nan\n",
    "\n",
    "# Wspd: Werte > 150 km/h (Orkangrenze) sind extrem selten\n",
    "df.loc[df[\"Wspd\"] > 150, \"Wspd\"] = np.nan\n",
    "\n",
    "# Pres: zwei Ausreißer über 1100 hPa → eher technisches Problem\n",
    "df.loc[df[\"Pres\"] > 1100, \"Pres\"] = np.nan\n",
    "\n",
    "# vorsichtige Ausreißerentfernung fpr Niederschlag (Prcp)\n",
    "df.loc[df[\"Prcp\"] > 400, \"Prcp\"] = np.nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ausführliche Beschreibung der Wettervariablen (sinnvoll?)\n",
    "\n",
    "🌡️ Tavg – Durchschnittstemperatur\n",
    "\n",
    "Die Variable Tavg beschreibt die durchschnittliche tägliche Temperatur. Die Verteilung ist leicht linksschief mit einem Skewness-Wert von –0.38. Der Mittelwert beträgt 15.38 °C, der Median liegt bei 15.90 °C, was auf eine weitgehend symmetrische Verteilung mit leichtem Übergewicht kälterer Temperaturen hinweist.\n",
    "\n",
    "Ein Blick auf den Stripplot zeigt, dass sich alle Werte im realistisch meteorologischen Bereich befinden:\n",
    "\n",
    "- Das Minimum liegt bei ca. –42 °C, was in sehr kalten Regionen (z. B. in Sibirien oder Teilen Kanadas) durchaus auftreten kann.\n",
    "- Das Maximum liegt bei ca. 50 °C, was mit bekannten Hitzerekorden weltweit vereinbar ist.\n",
    "\n",
    "Das 99.9%-Quantil liegt bei 38.30 °C. Dennoch wurde bewusst kein Grenzwert (Cutoff) gesetzt, da keine eindeutig unrealistischen Ausreißer erkennbar sind.\n",
    "\n",
    "→ Es wurden keine Werte entfernt oder als Ausreißer markiert.\n",
    "\n",
    "---\n",
    "\n",
    "🌡️ Tmin – Tagestiefsttemperatur\n",
    "\n",
    "Die Variable Tmin beschreibt die tägliche Tiefsttemperatur. Die Verteilung zeigt mit einer Schiefe von –0.32 eine leichte Linksschiefe, was auf ein geringfügiges Übergewicht sehr kalter Tage hinweist.\n",
    "Der Mittelwert beträgt 10.82 °C, der Median 11.00 °C, was auf eine insgesamt symmetrische Verteilung ohne nennenswerte Verzerrungen schließen lässt.\n",
    "\n",
    "Der Stripplot zeigt eine natürliche, kontinuierliche Verteilung der Messwerte.\n",
    "\n",
    "- Das Minimum liegt bei –46 °C, was in kalten Klimazonen realistisch ist.\n",
    "- Das Maximum bei 39 °C ist ungewöhnlich hoch für eine Tiefsttemperatur, aber unter besonderen Bedingungen (z. B. Hitzewellen) möglich.\n",
    "- Das 99.9%-Quantil liegt bei 32.4 °C, wodurch nur sehr wenige extrem hohe Werte überhaupt betroffen wären.\n",
    "\n",
    "Insgesamt zeigen sich keine auffälligen Ausreißer oder technische Artefakte.\n",
    "\n",
    "→ Es wurden keine Werte entfernt oder ersetzt.\n",
    "\n",
    "---\n",
    "\n",
    "🌡️ Tmax – Tageshöchsttemperatur\n",
    "\n",
    "Die Variable Tmax beschreibt die tägliche Höchsttemperatur.\n",
    "Die Verteilung ist mit einem Skewness-Wert von –0.37 leicht linksschief.\n",
    "Der Mittelwert beträgt 20.38 °C, der Median liegt bei 21.10 °C – die Verteilung ist insgesamt gut balanciert.\n",
    "\n",
    "Der Stripplot zeigt einen realistischen Verlauf im Bereich zwischen ca. –37 °C und 50 °C, wobei sich oberhalb von 50 °C vereinzelte Werte häufen. Eine genauere Prüfung der 20 höchsten Werte ergab jedoch drei offensichtliche Ausreißer:\n",
    "→ 60 °C, 76 °C und 87 °C – allesamt deutlich über bekannten meteorologischen Rekorden.\n",
    "\n",
    "Als Grenzwert wurde daher ein Cutoff bei 60 °C gesetzt.\n",
    "\n",
    "→ Drei Werte oberhalb dieses Grenzwerts wurden durch NaN ersetzt.\n",
    "\n",
    "---\n",
    "\n",
    "💧 Humidity – Relative Luftfeuchtigkeit\n",
    "\n",
    "Die Variable Humidity beschreibt die relative Luftfeuchtigkeit in Prozent.\n",
    "Die Verteilung ist extrem linksschief mit einer Skewness von –27.84, was auf starke Ausreißer im negativen und sehr hohen Bereich hindeutet.\n",
    "\n",
    "Die realistischen Messwerte liegen zwischen 0 % und 100 %.\n",
    "Der Stripplot zeigt jedoch vereinzelte, stark auffällige Werte:\n",
    "\n",
    "- Das Minimum beträgt –2671.1 %, was physikalisch unmöglich ist\n",
    "- Das Maximum liegt bei 999.9 %, höchstwahrscheinlich ein Platzhalterwert\n",
    "\n",
    "→ Es wurde daher ein Grenzbereich von 0 % bis 100 % definiert.\n",
    "Alle Werte außerhalb dieses Intervalls wurden durch NaN ersetzt.\n",
    "\n",
    "---\n",
    "\n",
    "💨 Wspd – Windgeschwindigkeit\n",
    "\n",
    "Die Variable Wspd beschreibt die tägliche durchschnittliche Windgeschwindigkeit in km/h.\n",
    "Die Verteilung zeigt eine leichte Rechtsschiefe mit einem Skewness-Wert von 1.51.\n",
    "Der Mittelwert liegt bei 11.34 km/h, der Median bei 10.00 km/h, was auf einen leicht asymmetrischen, aber plausiblen Verlauf hindeutet.\n",
    "\n",
    "Der Stripplot zeigt, dass die meisten Messwerte zwischen 0 und 45 km/h liegen, mit ausdünnender Streuung nach oben – was meteorologisch zu erwarten ist.\n",
    "Drei auffällige Extremwerte oberhalb von 150 km/h wurden identifiziert, der Maximalwert liegt bei 176.3 km/h. Solche Werte sind theoretisch möglich (z. B. bei Orkanen), aber im Kontext dieser Analyse nicht repräsentativ.\n",
    "\n",
    "→ Es wurde ein Cutoff bei 150 km/h gesetzt.\n",
    "Drei Werte oberhalb dieses Grenzwerts wurden durch NaN ersetzt.\n",
    "\n",
    "---\n",
    "\n",
    "🌬️ Pres – Luftdruck\n",
    "\n",
    "Die Variable Pres beschreibt den täglichen Luftdruck in hPa. Die Verteilung ist mit einer Skewness von –0.04 nahezu symmetrisch, was auf eine ausgewogene, realistische Verteilung hinweist.\n",
    "Der Mittelwert liegt bei 1015.15 hPa, was nahe am physikalischen Normaldruck (1013 hPa) liegt.\n",
    "\n",
    "Ein Blick auf die Extremwerte zeigt:\n",
    "\n",
    "- Minimum: 925.2 hPa – plausibel, z. B. bei Tiefdrucklagen\n",
    "- Maximum: 1392.1 hPa – stark unrealistisch, deutlich über bekannten Rekorden\n",
    "\n",
    "→ Es wurde ein Cutoff bei 1100 hPa gesetzt.\n",
    "Zwei klare Ausreißer oberhalb dieses Grenzwerts wurden durch NaN ersetzt."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Welche Features könnten zusammenhängen (Kollinearität)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collinearity of features? (heatmap)\n",
    "\n",
    "# > 0.8 = strong correlation\n",
    "# 0.5 - 0.8 = moderate correlation\n",
    "# < 0.5 = weak correlation\n",
    "\n",
    "# calculate correlation matrix (Pearson)\n",
    "corr_matrix = df.select_dtypes(include=['number']).corr()\n",
    "\n",
    "# Display heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0, linewidths=0.5)\n",
    "plt.title(\"Feature correlations (Pearson)\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show only strong and moderate correlations (>|0.4|); leave out main diagonal (1.0)\n",
    "\n",
    "# Calculte matrix\n",
    "corr_matrix = df.select_dtypes(include=['number']).corr()\n",
    "\n",
    "# extract only strong and moderate correlations (>|0.4|); leave out main diagonal (1.0)\n",
    "strong_corrs = corr_matrix[(corr_matrix.abs() > 0.4) & (corr_matrix.abs() < 1.0)]\n",
    "\n",
    "# Convert df to long list (.stack) and reset index\n",
    "strong_corrs = strong_corrs.stack().reset_index()\n",
    "strong_corrs.columns = [\"Feature 1\", \"Feature 2\", \"Korrelation\"]\n",
    "\n",
    "# remove redundant rows (note: the \"<\"-sign here refers to alphabetic order of feature names, not to numbers of any kind!)\n",
    "strong_corrs = strong_corrs.loc[strong_corrs[\"Feature 1\"] < strong_corrs[\"Feature 2\"]]\n",
    "\n",
    "strong_corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @Wiebke: Der Code hier produziert genau dieselbe Heatmap mit Korrelationen, aber nur die untere Hälfte.\n",
    "# Ich finde das übersichtlicher, weil die Hälften identisch sind und dadurch komplett redundant\n",
    "# Wie das geht:\n",
    "# Duch schreibst eine Maske, die die obere Hälfte der Matrix maskiert (np.triu), np.ones_like erstellt eine Matrix mit den gleichen Dimensionen wie die Korrelationsmatrix\n",
    "# Das Variable corr_matrix enthält die Daten aus dem df und wurde eine Zelle weiter oben definiert.\n",
    "# und dtype=bool sorgt dafür, dass die Maske aus True und False besteht\n",
    "# Dann zeichnest du die Heatmap und übergibst die Maske als Argument\n",
    "\n",
    "\n",
    "mask = np.triu(np.ones_like(corr_matrix, dtype=bool))\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(corr_matrix, mask=mask, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0, linewidths=0.5)\n",
    "plt.title(\"Feature Correlations (Pearson)\");\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyse der Korrelationen (Pearson) und Vorschläge für weitere Analysen\n",
    "\n",
    "Die Korrelationsmatrix zeigt mehrere starke und inhaltlich gut erklärbare Zusammenhänge zwischen den numerischen Variablen. Besonders deutlich sind folgende Muster:\n",
    "\n",
    "**Feinstaub- und Stickstoffdioxidwerte hängen zusammen:**\n",
    "Es besteht eine starke Korrelation zwischen PM10 und PM2.5 (r = 0.83), was plausibel ist, da PM2.5 eine Teilmenge von PM10 ist. Zusätzlich korreliert NO₂ moderat mit beiden Feinstaubkomponenten (r ≈ 0.42–0.48), was auf gemeinsame Emissionsquellen wie Verkehr oder Industrie hindeutet.\n",
    "\n",
    "**Temperaturvariablen sind stark untereinander korreliert:**\n",
    "Die Tagesmitteltemperatur (Tavg) steht in sehr engem Zusammenhang mit Tmin und Tmax (r ≈ 0.97). Auch Tmin und Tmax selbst sind hoch korreliert (r = 0.90). Das ist mathematisch und physikalisch naheliegend und spricht dafür, nicht alle drei Variablen gleichzeitig zu verwenden, um Redundanz zu vermeiden.\n",
    "\n",
    "**Der Taupunkt (Dew) korreliert stark mit Temperatur:**\n",
    "Die stärkste Korrelation liegt zwischen Dew und Tmin (r = 0.87), gefolgt von Tavg (r = 0.82). Dies spiegelt wider, dass die Luftfeuchtigkeit – und damit der Taupunkt – eng mit der Umgebungstemperatur zusammenhängt.\n",
    "\n",
    "**Einige schwächer negative Korrelationen deuten auf atmosphärische Zusammenhänge hin:**\n",
    "Der Luftdruck (Pres) korreliert moderat negativ mit Dew (r = –0.43) und Tmin (r = –0.42), was mit typischen meteorologischen Prozessen in Zusammenhang stehen kann (z. B. feuchtwarme Luft in Tiefdruckgebieten).\n",
    "\n",
    "### **Nutzen der Korrelationsanalyse, bzw. Weiterverwendung der Ergebnisse**\n",
    "\n",
    "Diese Ergebnisse helfen dabei, hoch korrelierte bzw. redundante Variablen zu erkennen und gezielt für weitere Analysen (z. B. Clusteranalyse oder Modellierung) geeignete Features auszuwählen.\n",
    "\n",
    "Für viele Verfahren, wie z. B. Clustering oder Regressionsmodelle, ist es ratsam, von stark korrelierten Variablen jeweils nur eine zu verwenden, um Verzerrungen oder sogenannte Multikollinearität zu vermeiden.\n",
    "\n",
    "Alternativ können Hauptkomponentenanalyse (PCA) oder andere dimensionalitätsreduzierende Verfahren genutzt werden, um mehrere stark korrelierte Variablen zu einer gemeinsamen Komponente zusammenzufassen, ohne wesentliche Information zu verlieren.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"data/cleaned_air_quality_data_2025_03_20.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Krimskrams\n",
    "\n",
    "@Wiebke: Aber hier kommt allerlei Zeugs, von dem ich mir nicht sicher bin, ob wie es in der EDA lassen sollen oder auslagern. Es sind verschiedene \"Experimente\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot changes throughout the year. Example: Analyse CO concentration per month\n",
    "\n",
    "# calculate mean CO per month\n",
    "monthly_co = df.groupby(\"Month\")[\"Co\"].mean()\n",
    "# monthly_co = df.groupby(\"Month\")[\"Co\"].mean()\n",
    "\n",
    "# create plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(monthly_co.index, monthly_co.values, marker='o', linestyle='-')\n",
    "plt.xlabel(\"Monat\")\n",
    "plt.ylabel(\"Mittlere CO-Konzentration\")\n",
    "plt.title(\"Durchschnittliche CO-Konzentration pro Monat\")\n",
    "plt.xticks(range(1, 13), [\"Jan\", \"Feb\", \"Mär\", \"Apr\", \"Mai\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Okt\", \"Nov\", \"Dez\"])\n",
    "plt.grid(True);\n",
    "\n",
    "# DaAn diesem Schaubild kann man zeigen, dass es Quatsch ist, alle Städte weltweit über einen Kamm zu scheren;\n",
    "# Es sagt aber an sich nichts Sinnvolles über die Daten aus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sinnvoller wäre es, die Daten in Nord- und Südhalbkugel zu trennen und getrennt zu betrachten. Aber das ignoriert immer noch viele relevante Faktoren\n",
    "\n",
    "# Trennung der Daten in Nord- und Südhalbkugel\n",
    "\n",
    "# Definieren, welche Länder zur Nord- und Südhalbkugel gehören\n",
    "northern_hemisphere_countries = {\n",
    "    \"US\", \"CA\", \"MX\", \"DE\", \"FR\", \"GB\", \"RU\", \"CN\", \"JP\", \"IN\", \"IT\", \"ES\", \"PL\", \"TR\", \"IR\", \"KR\", \"UA\", \"NL\", \"BE\",\n",
    "    \"CH\", \"SE\", \"AT\", \"NO\", \"FI\", \"DK\", \"GR\", \"CZ\", \"HU\", \"RO\", \"BG\", \"PT\", \"IE\", \"SK\", \"HR\", \"LT\", \"SI\", \"LV\", \"EE\"\n",
    "}\n",
    "southern_hemisphere_countries = {\n",
    "    \"AU\", \"NZ\", \"AR\", \"BR\", \"ZA\", \"CL\", \"ID\", \"PE\", \"BO\", \"EC\", \"PY\", \"UY\", \"MG\"\n",
    "}\n",
    "\n",
    "# Daten für Nord- und Südhalbkugel filtern\n",
    "df_north = df[df[\"Country\"].isin(northern_hemisphere_countries)]\n",
    "df_south = df[df[\"Country\"].isin(southern_hemisphere_countries)]\n",
    "\n",
    "# Mittlere CO-Konzentration pro Monat berechnen\n",
    "monthly_co_north = df_north.groupby(\"Month\")[\"Co\"].mean()\n",
    "monthly_co_south = df_south.groupby(\"Month\")[\"Co\"].mean()\n",
    "\n",
    "# Plot erstellen\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(monthly_co_north.index, monthly_co_north.values, marker='o', linestyle='-', label=\"Nordhalbkugel\", color='b')\n",
    "plt.plot(monthly_co_south.index, monthly_co_south.values, marker='o', linestyle='-', label=\"Südhalbkugel\", color='r')\n",
    "\n",
    "plt.xlabel(\"Monat\")\n",
    "plt.ylabel(\"Mittlere CO-Konzentration\")\n",
    "plt.title(\"Vergleich der CO-Konzentration auf Nord- und Südhalbkugel\")\n",
    "plt.xticks(range(1, 13))  # Monatsskala 1-12\n",
    "plt.legend()\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CO-Werte über das Jahr inklusive Streuung\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df, x=\"Month\", y=\"Co\", errorbar=\"sd\", marker=\"o\")\n",
    "plt.xlabel(\"Monat\")\n",
    "plt.ylabel(\"CO-Wert\")\n",
    "plt.title(\"Kohlenmonoxidwerte Im Jahresverlauf\")\n",
    "plt.xticks(range(1, 13), [\"Jan\", \"Feb\", \"Mär\", \"Apr\", \"Mai\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Okt\", \"Nov\", \"Dez\"])\n",
    "plt.show()\n",
    "\n",
    "# Die Grafik ist nicht intuitiv aussagekräftig. Die Streuung ist zu stark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streuung mit Achsenbegrenzung\n",
    "\n",
    "# Gruppiere nach Monat\n",
    "grouped = df.groupby(\"Month\")[\"Co\"]\n",
    "mean = grouped.mean()\n",
    "std = grouped.std()\n",
    "\n",
    "# Plot erstellen\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(mean.index, mean.values, marker='o', linestyle='-', label='Mittelwert CO')\n",
    "plt.fill_between(mean.index, mean - std, mean + std, color='blue', alpha=0.2, label='±1 SD')\n",
    "\n",
    "# Achsen, Titel, Beschriftungen\n",
    "plt.xlabel(\"Monat\")\n",
    "plt.ylabel(\"CO-Konzentration (ppm)\")\n",
    "plt.title(\"Durchschnittliche CO-Konzentration mit Streuung\")\n",
    "plt.xticks(range(1, 13), [\"Jan\", \"Feb\", \"Mär\", \"Apr\", \"Mai\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Okt\", \"Nov\", \"Dez\"])\n",
    "\n",
    "# Fokus auf relevanten y-Bereich\n",
    "plt.ylim(3, 7)  # oder anpassen je nach Datensatz\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Ergebnis: Die Streuung bedeckt die gesamte Diagrammfläche. Es sollten als die Städte, die die größte Verzerrung bewirken, aussortiert werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_by_city = df.groupby(\"City\")[\"Co\"].mean().sort_values(ascending=False)\n",
    "print(co_by_city.head(10))\n",
    "\n",
    "# Ashkelon ist ein unrealistischer Ausreißer. Siehe separates NB \"Ashkelon\": Es gibt nur Messwerte für Jan und Feb 2022, und diese schwanken extrem. Vielleicht kaputtes Messgerät."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate std per city\n",
    "\n",
    "co_std_by_city = df.groupby(\"City\")[\"Co\"].std().sort_values(ascending=False)\n",
    "print(co_std_by_city.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine mean and std to determine cities that cause the bigges distortions.\n",
    "\n",
    "co_stats = df.groupby(\"City\")[\"Co\"].agg([\"mean\", \"std\"]).sort_values(by=\"mean\", ascending=False)\n",
    "print(co_stats.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The three Israeli cities of Ashkelon, Ashdod and Netanya show highly volatile CO values, measured only in certain months.\n",
    "# This distorts the graph to an extent that calls for dropping these three cities from further analyes of CO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop distorting cities from fürther analyses\n",
    "exclude_cities = [\"Ashkelon\", \"Ashdod\", \"Netanya\"]\n",
    "df_cleaned = df[~df[\"City\"].isin(exclude_cities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Streuung mit Achsenbegrenzung, ohne Ausreißerstädte in Israel\n",
    "\n",
    "# Gruppiere nach Monat\n",
    "grouped = df_cleaned.groupby(\"Month\")[\"Co\"]\n",
    "mean = grouped.mean()\n",
    "std = grouped.std()\n",
    "\n",
    "# Plot erstellen\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(mean.index, mean.values, marker='o', linestyle='-', label='Mittelwert CO')\n",
    "plt.fill_between(mean.index, mean - std, mean + std, color='blue', alpha=0.2, label='±1 SD')\n",
    "\n",
    "# Achsen, Titel, Beschriftungen\n",
    "plt.xlabel(\"Monat\")\n",
    "plt.ylabel(\"CO-Konzentration (ppm)\")\n",
    "plt.title(\"Durchschnittliche CO-Konzentration mit Streuung\")\n",
    "plt.xticks(range(1, 13), [\"Jan\", \"Feb\", \"Mär\", \"Apr\", \"Mai\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Okt\", \"Nov\", \"Dez\"])\n",
    "\n",
    "# Fokus auf relevanten y-Bereich\n",
    "plt.ylim(3, 7)  # oder anpassen je nach Datensatz\n",
    "\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Ergebnis: Die Streuung bedeckt die gesamte Diagrammfläche. Es sollten als die Städte, die die größte Verzerrung bewirken, aussortiert werden.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CO-Werte über das Jahr inklusive Streuung\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df_cleaned, x=\"Month\", y=\"Co\", errorbar=\"sd\", marker=\"o\")\n",
    "plt.xlabel(\"Monat\")\n",
    "plt.ylabel(\"CO-Wert\")\n",
    "plt.title(\"Kohlenmonoxidwerte Im Jahresverlauf\")\n",
    "plt.xticks(range(1, 13), [\"Jan\", \"Feb\", \"Mär\", \"Apr\", \"Mai\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Okt\", \"Nov\", \"Dez\"])\n",
    "plt.show()\n",
    "\n",
    "# Die Grafik ist immer noch nicht nicht intuitiv aussagekräftig. Die Streuung ist weiterhin zu stark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ursachenforschung für die starke CO-Streuung\n",
    "\n",
    "co_std_cleaned = df_cleaned.groupby(\"City\")[\"Co\"].std().sort_values(ascending=False)\n",
    "print(co_std_cleaned.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "co_stats_cleaned = df_cleaned.groupby(\"City\")[\"Co\"].agg([\"mean\", \"std\"]).sort_values(by=\"std\", ascending=False)\n",
    "print(co_stats_cleaned.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weitere Städte mit extremer Varianz entfernen, um eine übersichtliche globale Darstellung zu erzielen\n",
    "\n",
    "more_extreme = [\"Portland\", \"Mérida\", \"Zamboanga\", \"Butuan\", \"Hạ long\", \"Oaxaca\", \"Isfahan\", \"San luis potosí\", \"Tabriz\", \"Tallahassee\"]\n",
    "exclude_cities = [\"Ashkelon\", \"Ashdod\", \"Netanya\"] + more_extreme\n",
    "df_cleaned2 = df[~df[\"City\"].isin(exclude_cities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CO-Werte über das Jahr inklusive Streuung, weiter reduziert\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.lineplot(data=df_cleaned2, x=\"Month\", y=\"Co\", marker=\"o\")\n",
    "plt.fill_between(mean.index, mean - std * 0.5, mean + std * 0.5, alpha=0.2, label='±0.5 SD')\n",
    "plt.xlabel(\"Monat\")\n",
    "plt.ylabel(\"CO-Wert\")\n",
    "plt.title(\"Kohlenmonoxidwerte Im Jahresverlauf\")\n",
    "plt.xticks(range(1, 13), [\"Jan\", \"Feb\", \"Mär\", \"Apr\", \"Mai\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Okt\", \"Nov\", \"Dez\"])\n",
    "plt.show()\n",
    "\n",
    "# Die Grafik ist immer noch nicht nicht intuitiv aussagekräftig. Die Streuung ist weiterhin zu stark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Nord- und Südhalbkugel anhand des Features \"Latitude\" trennen\n",
    "\n",
    "df_cleaned2.loc[:, \"Hemisphere\"] = df_cleaned2.loc[:, \"Latitude\"].apply(lambda x: \"Nordhalbkugel\" if x >= 0 else \"Südhalbkugel\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_north = df_cleaned2[df_cleaned2[\"Hemisphere\"] == \"Nordhalbkugel\"]\n",
    "df_south = df_cleaned2[df_cleaned2[\"Hemisphere\"] == \"Südhalbkugel\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nordhalbkugel\n",
    "grouped_north = df_north.groupby(\"Month\")[\"Co\"]\n",
    "mean_north = grouped_north.mean()\n",
    "std_north = grouped_north.std()\n",
    "\n",
    "# Südhalbkugel\n",
    "grouped_south = df_south.groupby(\"Month\")[\"Co\"]\n",
    "mean_south = grouped_south.mean()\n",
    "std_south = grouped_south.std()\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(mean_north.index, mean_north, marker='o', label=\"Nordhalbkugel\")\n",
    "plt.fill_between(mean_north.index, mean_north - std_north, mean_north + std_north, alpha=0.2)\n",
    "\n",
    "plt.plot(mean_south.index, mean_south, marker='s', label=\"Südhalbkugel\")\n",
    "plt.fill_between(mean_south.index, mean_south - std_south, mean_south + std_south, alpha=0.2)\n",
    "\n",
    "plt.xticks(range(1, 13), [\"Jan\", \"Feb\", \"Mär\", \"Apr\", \"Mai\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Okt\", \"Nov\", \"Dez\"])\n",
    "plt.xlabel(\"Monat\")\n",
    "plt.ylabel(\"CO-Konzentration (ppm)\")\n",
    "plt.title(\"Saisonale CO-Muster nach Hemisphäre\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mittlere CO-Konzentration pro Monat berechnen\n",
    "monthly_co_north = df_north.groupby(\"Month\")[\"Co\"].mean()\n",
    "monthly_co_south = df_south.groupby(\"Month\")[\"Co\"].mean()\n",
    "\n",
    "# Plot erstellen\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(monthly_co_north.index, monthly_co_north.values, marker='o', linestyle='-', label=\"Nordhalbkugel\", color='b')\n",
    "plt.plot(monthly_co_south.index, monthly_co_south.values, marker='o', linestyle='-', label=\"Südhalbkugel\", color='r')\n",
    "\n",
    "plt.xlabel(\"Monat\")\n",
    "plt.ylabel(\"Mittlere CO-Konzentration\")\n",
    "plt.title(\"Vergleich der CO-Konzentration auf Nord- und Südhalbkugel\")\n",
    "plt.xticks(range(1, 13))  # Monatsskala 1-12\n",
    "plt.legend()\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mittlere CO-Konzentration pro Monat berechnen- Median statt Mean, weil robuster gegen Ausreißer\n",
    "monthly_co_north = df_north.groupby(\"Month\")[\"Co\"].median()\n",
    "monthly_co_south = df_south.groupby(\"Month\")[\"Co\"].median()\n",
    "\n",
    "# Plot erstellen\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(monthly_co_north.index, monthly_co_north.values, marker='o', linestyle='-', label=\"Nordhalbkugel\", color='b')\n",
    "plt.plot(monthly_co_south.index, monthly_co_south.values, marker='o', linestyle='-', label=\"Südhalbkugel\", color='r')\n",
    "\n",
    "plt.xlabel(\"Monat\")\n",
    "plt.ylabel(\"Mittlere CO-Konzentration\")\n",
    "plt.title(\"Vergleich der CO-Konzentration auf Nord- und Südhalbkugel\")\n",
    "plt.xticks(range(1, 13))  # Monatsskala 1-12\n",
    "plt.legend()\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sns.histplot(df_north[\"Co\"], kde=True)\n",
    "# sns.histplot(df_south[\"Co\"], kde=True)\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Nordhalbkugel\n",
    "sns.histplot(df_north[\"Co\"], kde=True, label=\"Nordhalbkugel\", stat=\"density\", element=\"step\", fill=True)\n",
    "\n",
    "# Südhalbkugel\n",
    "sns.histplot(df_south[\"Co\"], kde=True, label=\"Südhalbkugel\", stat=\"density\", element=\"step\", fill=True)\n",
    "\n",
    "# Achsen & Legende\n",
    "plt.xlabel(\"CO-Konzentration (ppm)\")\n",
    "plt.ylabel(\"Dichte\")\n",
    "plt.title(\"Verteilung der CO-Werte nach Hemisphäre\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Histogramm Nordhalbkugel\n",
    "sns.histplot(df_north[\"Co\"], kde=True, stat=\"density\", label=\"Nordhalbkugel\", color=\"steelblue\", fill=True)\n",
    "\n",
    "# Histogramm Südhalbkugel\n",
    "sns.histplot(df_south[\"Co\"], kde=True, stat=\"density\", label=\"Südhalbkugel\", color=\"darkorange\", fill=True)\n",
    "\n",
    "# Zoom auf interessanten Bereich\n",
    "plt.xlim(0, 20)    # X-Achse (CO-Werte) begrenzen\n",
    "plt.ylim(0, 0.7)   # Y-Achse (Dichte) begrenzen\n",
    "\n",
    "# Titel & Achsen\n",
    "plt.xlabel(\"CO-Konzentration (ppm)\")\n",
    "plt.ylabel(\"Dichte\")\n",
    "plt.title(\"CO-Verteilung nach Hemisphäre (vergrößerter Bereich)\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mittlere CO-Konzentration pro Land berechnen\n",
    "country_co_avg = df.groupby(\"Country\")[\"Co\"].mean().sort_values(ascending=False)\n",
    "\n",
    "# Barplot erstellen\n",
    "plt.figure(figsize=(12, 6))\n",
    "country_co_avg.plot(kind='bar', color='b', alpha=0.7)\n",
    "plt.xlabel(\"Land\")\n",
    "plt.ylabel(\"Mittlere CO-Konzentration\")\n",
    "plt.title(\"Durchschnittliche CO-Konzentration pro Land\")\n",
    "plt.xticks(rotation=90)  # Länderbeschriftung drehen für bessere Lesbarkeit\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mittlere CO-Konzentration pro Land berechnen\n",
    "\n",
    "# Mindestanzahl an CO-Messwerten pro Land, um in die Analyse aufgenommen zu werden\n",
    "min_measurements = 100  # Falls nötig, anpassen\n",
    "\n",
    "# Anzahl der CO-Messwerte pro Land berechnen\n",
    "country_co_counts = df.groupby(\"Country\")[\"Co\"].count()\n",
    "\n",
    "# Nur Länder behalten, die mindestens `min_measurements` Messwerte haben\n",
    "valid_countries = country_co_counts[country_co_counts >= min_measurements].index\n",
    "\n",
    "# Gefilterten DataFrame mit diesen Ländern erstellen\n",
    "df_valid_countries = df[df[\"Country\"].isin(valid_countries)]\n",
    "\n",
    "# Mittlere CO-Konzentration für diese Länder berechnen\n",
    "country_co_avg_filtered = df_valid_countries.groupby(\"Country\")[\"Co\"].mean().sort_values(ascending=False)\n",
    "\n",
    "# Falls nach der Filterung noch Daten vorhanden sind, Plot erstellen\n",
    "if not country_co_avg_filtered.empty:\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    country_co_avg_filtered.plot(kind='bar', color='b', alpha=0.7)\n",
    "    plt.xlabel(\"Land\")\n",
    "    plt.ylabel(\"Mittlere CO-Konzentration\")\n",
    "    plt.title(\"Durchschnittliche CO-Konzentration pro Land (nur Länder mit ausreichenden Messwerten)\")\n",
    "    plt.xticks(rotation=90)  # Länderbeschriftung drehen für bessere Lesbarkeit\n",
    "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "else:\n",
    "    print(\"Keine ausreichenden Daten für CO-Werte in den Ländern verfügbar.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_co_avg_filtered.head(20).plot(kind='bar')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vergleich von Schadstoffen in verschiedenen Städten\n",
    "\n",
    "# Liste der relevanten Schadstoff-Spalten (falls sie in den Daten vorhanden sind)\n",
    "pollutants = [\"Co\", \"No2\", \"O3\", \"So2\", \"Pm10\", \"Pm25\"]\n",
    "\n",
    "# DataFrame mit nur den relevanten Spalten (fehlende Werte entfernen)\n",
    "df_pollutants = df[pollutants].dropna()\n",
    "\n",
    "# Korrelationsmatrix berechnen\n",
    "corr_matrix = df_pollutants.corr()\n",
    "\n",
    "# Heatmap der Korrelationen erstellen\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0, linewidths=0.5)\n",
    "plt.title(\"Korrelation zwischen CO und anderen Schadstoffen\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"Co\", \"No2\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ab hier Variablen korrigieren!!!\n",
    "\n",
    "# # Korrelation Schadstoffe und Wettervariablen\n",
    "\n",
    "# # Liste der Schadstoffe und Wettervariablen\n",
    "# pollutants = [\"Co\", \"No2\", \"O3\", \"So2\", \"Pm10\", \"Pm25\"]\n",
    "# weather_vars = [\"temperature\", \"pressure\", \"humidity\", \"dew\", \"wind-speed\", \"wind-gust\"]\n",
    "\n",
    "# # DataFrame mit nur den relevanten Spalten (fehlende Werte entfernen)\n",
    "# df_pollutants_weather = df[pollutants + weather_vars].dropna()\n",
    "\n",
    "# # Korrelationsmatrix berechnen\n",
    "# corr_matrix_weather = df_pollutants_weather.corr()\n",
    "\n",
    "# # Heatmap der Korrelationen zwischen Schadstoffen & Wettervariablen\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.heatmap(corr_matrix_weather, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0, linewidths=0.5)\n",
    "# plt.title(\"Korrelation zwischen Schadstoffen und Wetterfaktoren\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[[\"co\", \"temperature\"]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Schadstoffbelastung über die Zeit in verschiedenen Städten\n",
    "\n",
    "# Durchschnittliche Schadstoffwerte pro Jahr berechnen\n",
    "pollutants = [\"Co\", \"No2\", \"O3\", \"So2\", \"Pm10\", \"Pm25\"]\n",
    "yearly_trends = df.groupby(\"Year\")[pollutants].mean()\n",
    "\n",
    "# Liniendiagramm für langfristige Trends erstellen\n",
    "plt.figure(figsize=(12, 6))\n",
    "for pollutant in pollutants:\n",
    "    plt.plot(yearly_trends.index, yearly_trends[pollutant], marker='o', linestyle='-', label=pollutant)\n",
    "\n",
    "plt.xlabel(\"Jahr\")\n",
    "plt.ylabel(\"Mittlere Konzentration\")\n",
    "plt.title(\"Langfristige Entwicklung der Schadstoffwerte\")\n",
    "plt.legend()\n",
    "plt.grid(True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ohne 2014 und 2025, weil zu wenige Daten\n",
    "\n",
    "# Schadstoffe, die analysiert werden sollen\n",
    "pollutants = [\"Co\", \"No2\", \"O3\", \"So2\", \"Pm10\", \"Pm25\"]\n",
    "\n",
    "# Falls \"year\" als String gespeichert ist, in numerischen Wert umwandeln\n",
    "df[\"year\"] = pd.to_numeric(df[\"Year\"], errors=\"coerce\")\n",
    "\n",
    "# Durchschnittliche Schadstoffwerte pro Jahr berechnen, aber 2014 & 2025 ausschließen\n",
    "yearly_trends = df.groupby(\"Year\")[pollutants].mean()\n",
    "yearly_trends = yearly_trends.loc[(yearly_trends.index > 2014) & (yearly_trends.index < 2025)]\n",
    "\n",
    "# Liniendiagramm für langfristige Trends erstellen\n",
    "plt.figure(figsize=(12, 6))\n",
    "for pollutant in pollutants:\n",
    "    plt.plot(yearly_trends.index, yearly_trends[pollutant], marker='o', linestyle='-', label=pollutant)\n",
    "\n",
    "plt.xlabel(\"Jahr\")\n",
    "plt.ylabel(\"Mittlere Konzentration\")\n",
    "plt.title(\"Langfristige Entwicklung der Schadstoffwerte (ohne 2014 & 2025)\")\n",
    "plt.legend()\n",
    "plt.grid(True);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cities_with_data = df.loc[:, [\"City\", \"Co\", \"No2\", \"So2\", \"O3\", \"Pm25\", \"Pm10\"]].dropna(subset=[\"Co\", \"No2\", \"So2\", \"O3\", \"Pm25\", \"Pm10\"], how=\"all\")[\"City\"].nunique()\n",
    "print(f\"Anzahl der Städte mit mindestens einem Messwert: {num_cities_with_data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    # Schadstoffe, die analysiert werden sollen\n",
    "    pollutants = [\"Co\", \"No2\", \"O3\", \"So2\", \"Pm10\", \"Pm25\"]\n",
    "\n",
    "    # Länder nach Regionen gruppieren\n",
    "    regions = {\n",
    "        \"Europe\": {\"DE\", \"FR\", \"GB\", \"IT\", \"ES\", \"PL\", \"NL\", \"SE\", \"AT\", \"CH\", \"BE\"},\n",
    "        \"North America\": {\"US\", \"CA\", \"MX\"},\n",
    "        \"South America\": {\"BR\", \"AR\", \"CO\", \"CL\", \"PE\"},\n",
    "        \"Asia\": {\"CN\", \"IN\", \"JP\", \"KR\", \"IR\"},\n",
    "        \"Africa\": {\"ZA\", \"EG\", \"NG\"},\n",
    "        \"Oceania\": {\"AU\", \"NZ\"}\n",
    "    }\n",
    "\n",
    "    # Falls \"year\" als String gespeichert ist, in numerischen Wert umwandeln\n",
    "    df[\"Year\"] = pd.to_numeric(df[\"Year\"], errors=\"coerce\")\n",
    "\n",
    "    # Regionen durchgehen & Diagramme erstellen\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 8), sharex=True, sharey=True)  # Einheitliche Achsen für bessere Vergleichbarkeit\n",
    "    axes = axes.flatten()  # 2D-Array in 1D-Array umwandeln\n",
    "\n",
    "    # Speichert alle Linien für die gemeinsame Legende\n",
    "    handles, labels = [], []\n",
    "\n",
    "    for i, (region, countries) in enumerate(regions.items()):\n",
    "        df_region = df[df[\"Country\"].isin(countries)]\n",
    "        yearly_trends_region = df_region.groupby(\"Year\")[pollutants].mean()\n",
    "        yearly_trends_region = yearly_trends_region.loc[(yearly_trends_region.index > 2014) & (yearly_trends_region.index < 2025)]\n",
    "        \n",
    "        ax = axes[i]\n",
    "        for pollutant in pollutants:\n",
    "            line, = ax.plot(yearly_trends_region.index, yearly_trends_region[pollutant], marker='o', linestyle='-', label=pollutant)\n",
    "            \n",
    "            # Speichert eine Linie pro Schadstoff für die gemeinsame Legende\n",
    "            if i == 0:  \n",
    "                handles.append(line)\n",
    "                labels.append(pollutant)\n",
    "\n",
    "        ax.set_title(region)\n",
    "        ax.set_xlabel(\"Jahr\")\n",
    "        ax.set_ylabel(\"Mittelwert\")\n",
    "        ax.grid(True)\n",
    "\n",
    "    for ax in axes[:3]:  # Die ersten drei Subplots sind in der oberen Reihe\n",
    "        ax.xaxis.set_tick_params(labelbottom=True)\n",
    "\n",
    "    # Gemeinsame Legende unterhalb der Subplots platzieren\n",
    "    fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.05), ncol=len(pollutants))\n",
    "\n",
    "    # Layout optimieren\n",
    "    plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sechs Top-Länder in Europa\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Schadstoffe, die analysiert werden sollen\n",
    "pollutants = [\"co\", \"no2\", \"o3\", \"so2\", \"pm10\", \"pm25\"]\n",
    "\n",
    "# Europäische Länder definieren\n",
    "european_countries = {\"DE\", \"FR\", \"GB\", \"IT\", \"ES\", \"PL\", \"NL\", \"SE\", \"AT\", \"CH\", \"BE\"}\n",
    "\n",
    "# Falls \"year\" als String gespeichert ist, in numerischen Wert umwandeln\n",
    "df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
    "\n",
    "# Nur europäische Länder auswählen\n",
    "df_europe = df[df[\"Country\"].isin(european_countries)]\n",
    "\n",
    "# Länder mit den meisten Messwerten identifizieren\n",
    "top_countries = df_europe[\"Country\"].value_counts().nlargest(6).index  # Falls nur 6 Länder visualisiert werden sollen\n",
    "\n",
    "# Subplots für die gewählten Länder erstellen\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 8), sharex=True, sharey=True)  # 2 Reihen, 3 Spalten\n",
    "axes = axes.flatten()\n",
    "\n",
    "for i, country in enumerate(top_countries):\n",
    "    df_country = df_europe[df_europe[\"Country\"] == country]\n",
    "    yearly_trends_country = df_country.groupby(\"year\")[pollutants].mean()\n",
    "    yearly_trends_country = yearly_trends_country.loc[(yearly_trends_country.index > 2014) & (yearly_trends_country.index < 2025)]\n",
    "    \n",
    "    ax = axes[i]\n",
    "    for pollutant in pollutants:\n",
    "        ax.plot(yearly_trends_country.index, yearly_trends_country[pollutant], marker='o', linestyle='-', label=pollutant)\n",
    "    \n",
    "    ax.set_title(country)\n",
    "    ax.set_xlabel(\"Jahr\")\n",
    "    ax.set_ylabel(\"Mittelwert\")\n",
    "    ax.grid(True)\n",
    "\n",
    "# Gemeinsame Legende unterhalb der Subplots platzieren\n",
    "fig.legend(pollutants, loc='lower center', bbox_to_anchor=(0.5, -0.05), ncol=len(pollutants))\n",
    "\n",
    "# Layout optimieren\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Korrekation zwischen Ozon und anderen Faktoren\n",
    "\n",
    "# Relevante Spalten auswählen\n",
    "pollutants = [\"co\", \"no2\", \"so2\", \"pm10\", \"pm25\", \"o3\"]\n",
    "weather_vars = [\"temperature\", \"pressure\", \"humidity\", \"dew\", \"wind-speed\", \"wind-gust\"]\n",
    "\n",
    "# DataFrame mit nur den relevanten Spalten (fehlende Werte entfernen)\n",
    "df_ozone_corr = df[pollutants + weather_vars].dropna()\n",
    "\n",
    "# Korrelationsmatrix berechnen\n",
    "corr_matrix_ozone = df_ozone_corr.corr()\n",
    "\n",
    "# Heatmap der Korrelationen zwischen Ozon und anderen Faktoren\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(corr_matrix_ozone, annot=True, fmt=\".2f\", cmap=\"coolwarm\", center=0, linewidths=0.5)\n",
    "plt.title(\"Korrelation zwischen Ozon (O₃) und anderen Faktoren\");\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Durchschnittliche Ozonwerte pro Monat berechnen\n",
    "monthly_o3 = df.groupby(\"month\")[\"o3\"].mean()\n",
    "\n",
    "# Liniendiagramm für die saisonale Entwicklung von Ozon erstellen\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(monthly_o3.index, monthly_o3.values, marker='o', linestyle='-', color='b')\n",
    "plt.xlabel(\"Monat\")\n",
    "plt.ylabel(\"Mittlere O₃-Konzentration\")\n",
    "plt.title(\"Saisonale Entwicklung der Ozonwerte (O₃)\")\n",
    "plt.xticks(range(1, 13), [\"Jan\", \"Feb\", \"Mär\", \"Apr\", \"Mai\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Okt\", \"Nov\", \"Dez\"])\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Länder nach Hemisphäre aufteilen\n",
    "northern_hemisphere_countries = {\n",
    "    \"US\", \"CA\", \"MX\", \"DE\", \"FR\", \"GB\", \"IT\", \"ES\", \"PL\", \"NL\", \"SE\", \"AT\", \"CH\", \"BE\", \"RU\", \"CN\", \"JP\", \"IN\", \"KR\"\n",
    "}\n",
    "southern_hemisphere_countries = {\n",
    "    \"AU\", \"NZ\", \"AR\", \"BR\", \"ZA\", \"CL\", \"ID\", \"PE\", \"BO\", \"EC\", \"PY\", \"UY\", \"MG\"\n",
    "}\n",
    "\n",
    "# Daten für Nord- und Südhalbkugel filtern\n",
    "df_north = df[df[\"Country\"].isin(northern_hemisphere_countries)]\n",
    "df_south = df[df[\"Country\"].isin(southern_hemisphere_countries)]\n",
    "\n",
    "# Durchschnittliche Ozonwerte pro Monat für beide Hemisphären berechnen\n",
    "monthly_o3_north = df_north.groupby(\"month\")[\"o3\"].mean()\n",
    "monthly_o3_south = df_south.groupby(\"month\")[\"o3\"].mean()\n",
    "\n",
    "# Plot erstellen\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(monthly_o3_north.index, monthly_o3_north.values, marker='o', linestyle='-', label=\"Nordhalbkugel\", color='b')\n",
    "plt.plot(monthly_o3_south.index, monthly_o3_south.values, marker='o', linestyle='-', label=\"Südhalbkugel\", color='r')\n",
    "\n",
    "plt.xlabel(\"Monat\")\n",
    "plt.ylabel(\"Mittlere O₃-Konzentration\")\n",
    "plt.title(\"Vergleich der Ozonwerte (O₃) zwischen Nord- und Südhalbkugel\")\n",
    "plt.xticks(range(1, 13), [\"Jan\", \"Feb\", \"Mär\", \"Apr\", \"Mai\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Okt\", \"Nov\", \"Dez\"])\n",
    "plt.legend()\n",
    "plt.grid(True);\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Europäische Länder definieren\n",
    "european_countries = {\"DE\", \"FR\", \"GB\", \"IT\", \"ES\", \"PL\", \"NL\", \"SE\", \"AT\", \"CH\", \"BE\"}\n",
    "\n",
    "# Falls \"year\" als String gespeichert ist, in numerischen Wert umwandeln\n",
    "df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\")\n",
    "\n",
    "# Nur europäische Länder auswählen\n",
    "df_europe = df[df[\"Country\"].isin(european_countries)]\n",
    "\n",
    "# Jahre 2014 & 2025 aus der Analyse entfernen\n",
    "df_europe = df_europe[(df_europe[\"year\"] > 2014) & (df_europe[\"year\"] < 2025)]\n",
    "\n",
    "# Nur Länder behalten, die tatsächlich O₃-Werte haben\n",
    "countries_with_o3 = df_europe.groupby(\"Country\")[\"o3\"].count()\n",
    "valid_countries = countries_with_o3[countries_with_o3 > 0].index  # Länder mit vorhandenen O₃-Werten\n",
    "\n",
    "# DataFrame auf diese Länder filtern\n",
    "df_europe = df_europe[df_europe[\"Country\"].isin(valid_countries)]\n",
    "\n",
    "# Standardabweichung (Schwankungsstärke) von O₃ pro Jahr & Land berechnen\n",
    "ozone_volatility = df_europe.groupby([\"year\", \"Country\"])[\"o3\"].std().unstack()\n",
    "\n",
    "# Diagramm erstellen\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "handles = []  # Zum Speichern der Linien für die Legende\n",
    "labels = []   # Zum Speichern der Ländernamen\n",
    "\n",
    "for country in ozone_volatility.columns:\n",
    "    line, = ax.plot(ozone_volatility.index, ozone_volatility[country], marker='o', linestyle='-', label=country)\n",
    "    handles.append(line)\n",
    "    labels.append(country)\n",
    "\n",
    "ax.set_xlabel(\"Jahr\")\n",
    "ax.set_ylabel(\"Standardabweichung von O₃ (Schwankungsstärke)\")\n",
    "ax.set_title(\"Jährliche Schwankungsstärke der Ozonwerte in europäischen Ländern (nur Länder mit Daten)\")\n",
    "ax.grid(True)\n",
    "\n",
    "# Legende unterhalb des Plots platzieren\n",
    "fig.legend(handles, labels, loc='lower center', bbox_to_anchor=(0.5, -0.15), ncol=len(valid_countries))\n",
    "\n",
    "# Layout optimieren\n",
    "plt.tight_layout();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
