{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Klassifikationsmodell bauen, mit dem St√§dte auf der Grundlage des PM2.5-Werts in zwei Gruppen eingeteilt werden.\n",
    "\n",
    "Mehrstufige Erarbeitung:\n",
    "\n",
    "Schwellenwerte\n",
    "1. WHO-Richtline (fachlicher Standard --> internationale Vergleichbarkeit)\n",
    "2 Median oder Perzentile (datengetrieben --> Mehrwert von Data Science)\n",
    "\n",
    "Modelle\n",
    "1. Logistische Regression\n",
    "2. Random Forest\n",
    "3. Gradient Boosting\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/cleaned_air_quality_data_2025-03-27.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste relevanter Schadstoffe\n",
    "pollutants = ['Co', 'No2', 'O3', 'Pm10', 'Pm25', 'So2']\n",
    "\n",
    "# Mittelwerte pro Stadt berechnen (Index = City)\n",
    "df_means = df.groupby('City')[pollutants].mean()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßæ Definition der Zielvariable AirQualityLabel\n",
    "\n",
    "Um ein Klassifikationsmodell zur Vorhersage der Luftqualit√§t von St√§dten zu erstellen, wurde eine zielvariable AirQualityLabel eingef√ºhrt. Diese ordnet jeder Stadt eine von zwei Klassen zu:\n",
    "\n",
    "- 0 ‚Üí Gute Luftqualit√§t\n",
    "\n",
    "- 1 ‚Üí Schlechte Luftqualit√§t\n",
    "\n",
    "Die Einteilung basiert auf dem Medianwert der durchschnittlichen PM2.5-Konzentration aller St√§dte im Datensatz. Der Median wurde als datengetriebener Grenzwert gew√§hlt, da sich der offiziell empfohlene WHO-Grenzwert von 5‚ÄØ¬µg/m¬≥ in der Praxis als zu streng erwiesen hat: Nur drei St√§dte h√§tten diesen erf√ºllt, was zu einem extremen Klassenungleichgewicht und damit zu einem ungeeigneten Klassifikationsproblem gef√ºhrt h√§tte.\n",
    "\n",
    "Durch die Verwendung des Medians entsteht eine ausgewogene Verteilung zwischen den beiden Klassen, die ein stabiles Training und eine faire Bewertung des Modells erm√∂glicht.\n",
    "\n",
    "Die Berechnung erfolgte folgenderma√üen:\n",
    "\n",
    "    pm25_median = df_means['Pm25'].median()\n",
    "    df_means['AirQualityLabel'] = (df_means['Pm25'] > pm25_median).astype(int)\n",
    "\n",
    " St√§dte mit einem PM2.5-Mittelwert √ºber dem Median wurden als \"schlechte Luftqualit√§t\" (1) klassifiziert, alle anderen als \"gute Luftqualit√§t\" (0).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median von PM2.5 berechnen\n",
    "pm25_median = df_means['Pm25'].median()\n",
    "\n",
    "# Zielvariable hinzuf√ºgen\n",
    "df_means['AirQualityLabel'] = (df_means['Pm25'] > pm25_median).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl St√§dte mit guter/schlechter Luft (nach WHO-Grenzwert)\n",
    "(df_means['Pm25'] <= 5).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# St√§dte mit PM2.5 ‚â§ 5 ¬µg/m¬≥ filtern\n",
    "clean_cities = df_means[df_means['Pm25'] <= 5]\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "clean_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl g√ºltiger PM2.5-Werte pro Stadt\n",
    "pm25_counts = df.groupby('City')['Pm25'].count().sort_values()\n",
    "\n",
    "# Zeige nur die \"sauberen\" St√§dte\n",
    "pm25_counts.loc[['Plovdiv', 'Yazd', 'Z√ºrich']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Nur g√ºltige PM2.5-Werte f√ºr Yazd\n",
    "yazd_pm25 = df[(df['City'] == 'Yazd') & (df['Pm25'].notna())]\n",
    "\n",
    "# Histogramm der Jahresverteilung\n",
    "plt.figure(figsize=(8, 4))\n",
    "yazd_pm25['Month'].value_counts().sort_index().plot(kind='bar', color='steelblue')\n",
    "\n",
    "plt.title(\"Anzahl g√ºltiger PM2.5-Messwerte pro Jahr f√ºr Yazd\")\n",
    "plt.xlabel(\"Jahr\")\n",
    "plt.ylabel(\"Anzahl g√ºltiger Messwerte\")\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste problematischer St√§dte\n",
    "rauswerfen = ['Plovdiv', 'Yazd']\n",
    "\n",
    "# Entferne sie aus df und ggf. df_means\n",
    "df = df[~df['City'].isin(rauswerfen)]\n",
    "\n",
    "# Und aus dem aggregierten Mittelwert-Datensatz\n",
    "df_means = df_means[~df_means.index.isin(rauswerfen)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sehr schnelles Zwischenergebnis:\n",
    "\n",
    "Es gibt nur 3 St√§dte, die den aktuellen WHO-Anspruch von weniger als 5 ¬µg/m¬≥ erf√ºllen: Z√ºrich (Schweiz), Plovdiv (Bulgarien), Yazd (Iran). Bei genauerem Hinschauen f√§llt zus√§tzlich auf, dass es f√ºr Plovidiv nur enen einzigen Messwert gibt, und f√ºr Yazd nur sehr wenige. \n",
    "Die WHO-Richtline kann also nicht verwendet werden, weil ein Modell damit nicht trainierbar ist - es hat keine zweite Klasse.\n",
    "\n",
    "Wir nehmen also direkt den Median, gehen also datengetrieben vor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umgang mit NaN-Werten\n",
    "\n",
    "# Anzahl fehlender Werte pro Spalte\n",
    "df[[\"City\"] + pollutants].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl g√ºltiger Werte pro Stadt und Schadstoff\n",
    "df.groupby('City')[pollutants].count().sort_values(by='Pm25')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Welche St√§dte enthalten √ºberhaupt keine Schadstoffwerte?\n",
    "\n",
    "# Alle Schadstoffspalten\n",
    "pollutants = ['Co', 'No2', 'O3', 'Pm10', 'Pm25', 'So2']\n",
    "\n",
    "# F√ºr jede Stadt z√§hlen, wie viele g√ºltige Werte es insgesamt gibt\n",
    "valid_counts = df.groupby('City')[pollutants].count()\n",
    "\n",
    "# Zeige nur St√§dte mit 0 g√ºltigen Werten in *allen* Schadstoffspalten\n",
    "no_data_cities = valid_counts[(valid_counts == 0).all(axis=1)]\n",
    "\n",
    "# Ausgabe\n",
    "no_data_cities.index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_data_cities = [\n",
    "    'Alor setar', 'George town', 'Ipoh', 'Johor bahru', 'Klang', 'Kota bharu',\n",
    "    'Kuala lumpur', 'Kuantan', 'Kuching', 'Malacca', 'Miri', 'Seremban', 'Taiping'\n",
    "]\n",
    "# Entferne sie aus df und ggf. df_means\n",
    "\n",
    "# Aus dem Haupt-DataFrame\n",
    "df = df[~df['City'].isin(no_data_cities)]\n",
    "\n",
    "# Auch aus df_means entfernen (falls schon berechnet)\n",
    "df_means = df_means[~df_means.index.isin(no_data_cities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relevante Spalten\n",
    "pollutants = ['Co', 'No2', 'O3', 'Pm10', 'Pm25', 'So2']\n",
    "\n",
    "# F√ºr jede Stadt: Wie viele Mittelwerte sind vorhanden?\n",
    "df_means['Num_Valid_Pollutants'] = df_means[pollutants].notna().sum(axis=1)\n",
    "\n",
    "# √úbersicht: Wie viele St√§dte haben wie viele g√ºltige Schadstoffwerte?\n",
    "coverage_summary = df_means['Num_Valid_Pollutants'].value_counts().sort_index()\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "coverage_summary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weil das Imputieren von √ºberhaupt nicht vorhandenen Kategorien (Schadstoffen) f√ºr eine Stadt eigentlich nicht mehr als \"Raten\" ist, machen wir das hier nicht und reduzieren die trainingsdaten auf die 404 St√§dte, die f√ºr alle Schadstoffe Werte gemeldet haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nur St√§dte mit allen 6 Schadstoff-Mittelwerten\n",
    "df_means_complete = df_means[df_means['Num_Valid_Pollutants'] == 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_means_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Co', 'No2', 'O3', 'Pm10', 'So2']\n",
    "X = df_means_complete[features]\n",
    "y = df_means_complete['AirQualityLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir haben  aktuell 404 St√§dte in df_means_complete. Davon nehmen wir 80% f√ºr das Training und 20% f√ºr den Test.\n",
    "# Wir verwenden den Standard-Trainings-Test-Split von scikit-learn.\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Split in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "#  Modelltraining\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen & Bewertung\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir PM10 als Feature drinlassen, klassifiziert das Modell prima - und das ist auch zu erwarten, weil PM2.5 eine Teilmenge von PM10 ist. Also lassen wir PM10 jetzt mal raus und schauen, was dann passiert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_no_PM10 = ['Co', 'No2', 'O3', 'So2']\n",
    "X = df_means_complete[features_no_PM10]\n",
    "y = df_means_complete['AirQualityLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelltraining\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen & Bewertung\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßæ Entscheidung zur Feature-Auswahl: PM10 aus den Features entfernen\n",
    "\n",
    "Um die Luftqualit√§t in St√§dten zu klassifizieren, wurden zun√§chst alle Schadstoffe (CO, NO‚ÇÇ, O‚ÇÉ, PM10, PM2.5, SO‚ÇÇ) als Features in das Modell aufgenommen, obwohl PM10 und PM2.5 naturgem√§√ü eine hohe Korrelation aufweisen (√ºber 97%).\n",
    "\n",
    "üîπ Test mit PM10 als Feature:\n",
    "\n",
    "Das Modell erzielte eine hohe Genauigkeit von 91% und einen sehr hohen F1-Score von 0.92 f√ºr die Vorhersage von schlechter Luft (Klasse 1).\n",
    "\n",
    "Pr√§zision und Recall bei der Klassifikation von ‚Äûschlechter Luft‚Äú waren sehr hoch (nahe 1.0), was das Modell besonders pr√§zise bei der Vorhersage von schlechter Luft machte.\n",
    "\n",
    "Allerdings zeigte sich auch, dass das Modell zwischen den Klassen kaum differenzierte, was die klassenspezifische Leistung bei guter Luft (Klasse 0) beeintr√§chtigte.\n",
    "\n",
    "üîπ Test ohne PM10 als Feature:\n",
    "\n",
    "Nachdem PM10 entfernt wurde, ging die Genauigkeit leicht zur√ºck auf 80% und der F1-Score f√ºr schlechte Luft sank von 0.92 auf 0.83.\n",
    "\n",
    "Das Modell zeigt nun jedoch eine ausgewogenere Klassifikation (bevorzogt nicht mehr das Label \"schlechte Luft\") und ist weniger von redundanten Informationen beeinflusst.\n",
    "\n",
    "üß† Ergebnis:\n",
    "\n",
    "Die Tests haben gezeigt, dass das Modell besser differenziert, wenn PM10 aus den Features entfernt wird. Auch wenn die Gesamtgenauigkeit etwas zur√ºckgeht, ist das Modell nun besser in der Lage, zwischen guter und schlechter Luft zu unterscheiden.\n",
    "Die Entscheidung, PM10 aus den Features zu entfernen, basiert auf der starken Korrelation mit PM2.5, die zu einer Redundanz f√ºhrte und das Modell verzerrte.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and train test split repeated from previous model, just to make clear what is being used:\n",
    "\n",
    "features_no_PM10 = ['Co', 'No2', 'O3', 'So2']\n",
    "X = df_means_complete[features_no_PM10]\n",
    "y = df_means_complete['AirQualityLabel']\n",
    "\n",
    "# Split in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Random Forest-Modell erstellen\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Modell trainieren\n",
    "rf_model.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen & Bewertung drucken\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance extrahieren\n",
    "importances = rf_model.feature_importances_\n",
    "len(importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Feature-Importanz in ein DataFrame umwandeln\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': features_no_PM10,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Feature-Importanz anzeigen\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='viridis')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Am wichtigsten f√ºr die Klassifizierung ist das Feature \"CO\". Kann es sein, dass die flasch klassifizierten St√§dte auff√§llige CO-Werte haben?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Falsch klassifizierte St√§dte finden\n",
    "incorrect_predictions = X_test.copy()\n",
    "incorrect_predictions['True Label'] = y_test\n",
    "incorrect_predictions['Predicted Label'] = y_pred_rf\n",
    "\n",
    "# Nur falsch klassifizierte St√§dte herausfiltern\n",
    "incorrect_predictions = incorrect_predictions[incorrect_predictions['True Label'] != incorrect_predictions['Predicted Label']]\n",
    "\n",
    "# CO-Werte der falsch klassifizierten St√§dte\n",
    "incorrect_predictions['CO'] = X_test.loc[incorrect_predictions.index, 'Co']\n",
    "\n",
    "# Ausgabe der St√§dte mit ihren CO-Werten\n",
    "incorrect_predictions[['True Label', 'Predicted Label', 'CO']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CO-Werte der falsch klassifizierten St√§dte\n",
    "co_values = incorrect_predictions['CO']\n",
    "\n",
    "# Berechne die wichtigsten Statistiken (Durchschnitt, IQR)\n",
    "co_mean = co_values.mean()\n",
    "co_std = co_values.std()\n",
    "co_min = co_values.min()\n",
    "co_max = co_values.max()\n",
    "\n",
    "# Berechne Interquartilsabstand (IQR)\n",
    "Q1 = co_values.quantile(0.25)\n",
    "Q3 = co_values.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Anzeigen der CO-Statistiken\n",
    "print(f\"Durchschnittlicher CO-Wert: {co_mean:.2f}\")\n",
    "print(f\"Standardabweichung: {co_std:.2f}\")\n",
    "print(f\"Minimaler CO-Wert: {co_min:.2f}\")\n",
    "print(f\"Maximaler CO-Wert: {co_max:.2f}\")\n",
    "print(f\"Interquartilsabstand (IQR): {IQR:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier muss man noch nachdenken, wie man das Modell verbessern kann. Man sollte die falsch zugeordneten St√§dte √ºberpr√ºfen, ob da mit den Daten was nicht stimmt. Und dann noch die Hyperparameter besser einstellen und so. Nicht mehr heute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell 3: Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "# Gradient Boosting Modell erstellen\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Modell trainieren\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen & Bewertung\n",
    "y_pred = gb_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "print(confusion_matrix(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
