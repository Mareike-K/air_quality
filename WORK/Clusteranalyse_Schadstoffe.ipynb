{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clusteranalyse\n",
    "\n",
    "Schritte zur Vorbereitung, später evtl. schon im Preprossessing erledigt:\n",
    "\n",
    "Format\n",
    "- Datumsspalte in Jahr, Monat, Tag trennen\n",
    "\n",
    "Daten entfernen\n",
    "- **Zeilen** aus 2014 und 2025 entfernen, weil zu wenige Datenpunkte\n",
    "- **Spalten** mit zu vielen fehlenden Werten entfernen (cut-off: 53% missing values)\n",
    "- Alle Einträge für **Tehran** entfernen, weil die Stadt durch ihre extrem hohen Schadstoffwerte die Clusteranalyse verzerrt\n",
    "\n",
    "Aktuell auch noch relevant, aber im großen Datensatz vielleicht nicht mehr\n",
    "- Bestimmen, in welchen der 95 Städte für **alle Schadstoffe** Messwerte vorliegen --> 54 Städte\n",
    "\n",
    "Clusteranalyse\n",
    "- StandardScaler und KMeans importieren\n",
    "- Liste der Schadstoffe definieren (pollutants)\n",
    "- gruppierten (\"City\") und reduzierten (\"dropna\") mit Mittelwerten (\"mean\") df nach Städten und Schadstoffen für als Datengrundlage der Clusteranalyse erstellen (**df_cluster**). df-cluster hat 53 Zeilen (Städte) und 6 Spalten (Schadstoffe)\n",
    "- Daten skalieren (**df_cluster_scaled**)\n",
    "- mit Ellbow-Methode optimale Clusteranzahl bestimmen --> 5 Cluster (Silhouette wurde auch getestet, brachte keinen Mehrwert)\n",
    "- mit Kmeans Clusterzuordnung durchführen (**df_cluster_numbers**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Settings for displaying floats\n",
    "pd.set_option('display.float_format', '{:,.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/mareikekeller/air_quality/data/cleaned_data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preparation: Manipulating the 'Date' column\n",
    "\n",
    "# Convert 'Date' column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Split 'Date' column into 'year', 'month' and 'day'\n",
    "df['year'] = df['Date'].dt.year\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['day'] = df['Date'].dt.day\n",
    "\n",
    "# Remove 'Date' column\n",
    "if 'Date' in df.columns:\n",
    "    df.drop(columns=['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten für 2014 & 2025 entfernen, weil zu wenige Datenpunkte\n",
    "\n",
    "df = df[(df[\"year\"] > 2014) & (df[\"year\"] < 2025)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tehran komplett entfernen, weil die Schadstoffwerte zu sehr von allen übrigen Städten abweichen\n",
    "df = df[df[\"City\"] != \"Tehran\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tehran noch im DataFrame?\", \"Tehran\" in df[\"City\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['City'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first 5 rows of the dataframe\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spalten mit zu vielen fehlenden Werten entfernen\n",
    "\n",
    "# Berechnen, wie viele Prozent der Werte pro Spalte fehlen\n",
    "missing_percent = df.isna().mean() * 100  \n",
    "\n",
    "# Spalten auswählen, die weniger als 50% fehlende Werte haben\n",
    "df_cleaned = df.loc[:, missing_percent <= 53]\n",
    "\n",
    "# Ergebnis ausgeben\n",
    "print(f\"Anzahl der entfernten Spalten: {df.shape[1] - df_cleaned.shape[1]}\")\n",
    "print(\"Übrige Spalten:\", df_cleaned.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned[\"City\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Mit Heatmap herausfinden, welche Städte für welche Schadstoffe fehlende Werte haben\n",
    "\n",
    "# # Liste der Schadstoff-Features für das Clustering\n",
    "# pollutants = [\"co\", \"no2\", \"o3\", \"so2\", \"pm10\", \"pm25\"]\n",
    "\n",
    "# # DataFrame mit den Schadstoffen pro Stadt erstellen\n",
    "# df_missing = df_cleaned.groupby(\"City\")[pollutants].mean()\n",
    "\n",
    "# # Boolean-Maske für fehlende Werte erstellen (True = fehlend, False = vorhanden)\n",
    "# missing_data = df_missing.isna()\n",
    "\n",
    "# # Größe der Grafik anpassen\n",
    "# plt.figure(figsize=(8, 20))\n",
    "\n",
    "# # Heatmap zeichnen (dunklere Farben = mehr fehlende Werte)\n",
    "# sns.heatmap(missing_data, cmap=\"coolwarm\", cbar=False, linewidths=0.5)\n",
    "\n",
    "# # Achsentitel setzen\n",
    "# plt.xlabel(\"Schadstoffe\")\n",
    "# plt.ylabel(\"Städte\")\n",
    "# plt.title(\"Heatmap der fehlenden Werte pro Stadt und Schadstoff\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing_per_city = df_missing.isna().sum(axis=1)\n",
    "# missing_per_city_sorted = missing_per_city.sort_values(ascending=False)\n",
    "# print(missing_per_city_sorted.to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code für Clusteranalyse (K-Means) zur Schadstoffbelastung"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clusteranalyse zur Schadstoffbelastung\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Liste der Schadstoff-Features für das Clustering\n",
    "pollutants = [\"co\", \"no2\", \"o3\", \"so2\", \"pm10\", \"pm25\"]\n",
    "\n",
    "# Durchschnittliche Schadstoffwerte pro Stadt berechnen\n",
    "df_cluster = df_cleaned.groupby(\"City\")[pollutants].mean().dropna()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daten skalieren (K-Means ist empfindlich gegenüber unterschiedlichen Skalen)\n",
    "scaler = StandardScaler()\n",
    "df_scaled = scaler.fit_transform(df_cluster)\n",
    "\n",
    "# Ergebnis als DataFrame zurückgeben\n",
    "df_cluster_scaled = pd.DataFrame(df_scaled, index=df_cluster.index, columns=pollutants)\n",
    "\n",
    "# Überprüfen, ob die Daten korrekt vorbereitet sind\n",
    "df_cluster_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Teste verschiedene Clusterzahlen (k = 1 bis 10)\n",
    "inertia = []\n",
    "k_values = range(1, 31)\n",
    "\n",
    "for k in k_values:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(df_cluster_scaled)\n",
    "    inertia.append(kmeans.inertia_)  # Speichert den Fehler (Inertia)\n",
    "\n",
    "# Elbow-Plot erstellen\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.plot(k_values, inertia, marker='o', linestyle='-')\n",
    "plt.xlabel(\"Anzahl der Cluster (k)\")\n",
    "plt.ylabel(\"Inertia (Fehler)\")\n",
    "plt.title(\"Elbow-Methode zur Bestimmung der optimalen Clusterzahl\")\n",
    "plt.grid(True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means-Clustering\n",
    "kmeans = KMeans(n_clusters=6, random_state=42, n_init=10)\n",
    "df_cluster_scaled[\"Cluster\"] = kmeans.fit_predict(df_cluster_scaled)\n",
    "\n",
    "# Neue Cluster-Zuordnung der Städte anzeigen\n",
    "df_cluster_numbers = df_cluster_scaled[[\"Cluster\"]].sort_values(by=\"Cluster\")\n",
    "df_cluster_numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster = df_cluster_scaled.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster.to_csv(\"df_cluster.csv\", index=True)  # Index speichern, damit die Städtenamen erhalten bleiben\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Delhi wird bei 5 und 6 Clustern von KMeans als eigenes Cluster isoliert.\n",
    "# # Test, ob DBSCAN eine andere Clusterbildung erzielt\n",
    "\n",
    "# from sklearn.cluster import DBSCAN\n",
    "\n",
    "# dbscan = DBSCAN(eps=3.5, min_samples=4)  # Parameter ggf. anpassen\n",
    "# df_cluster[\"Cluster_DBSCAN\"] = dbscan.fit_predict(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cluster[\"Cluster_DBSCAN\"].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cluster[df_cluster.index == \"Delhi\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entscheidung: Tehran war schon rausgenommen, weil es ein eigenes Cluster bildet. Ohne Tehran bildet Delhi ein eigenes Cluster. Das lassen wir jetzt erst mal so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zusammenführung Geodaten und Clusternummern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geodata = pd.read_csv(\"df_geodata.csv\")\n",
    "df_geodata.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cluster_numbers.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cluster_numbers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cluster_numbers.index[:10])  # Zeigt die ersten 10 Indexwerte von df_cluster_numbers\n",
    "print(df_geodata[\"City\"].unique()[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geodata[\"City\"] = df_geodata[\"City\"].str.strip().str.lower()\n",
    "df_cluster_numbers.index = df_cluster_numbers.index.str.strip().str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geodata = df_geodata.merge(df_cluster_numbers[[\"Cluster\"]], left_on=\"City\", right_index=True, how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geodata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geodata = df_geodata.dropna(subset=[\"Cluster\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_geodata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster farbig plotten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import geodatasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Weltkarte laden\n",
    "world = gpd.read_file(geodatasets.get_path(\"naturalearth.land\"))\n",
    "\n",
    "# Städte aus df_geodata in einen GeoDataFrame umwandeln\n",
    "gdf_cities = gpd.GeoDataFrame(df_geodata, \n",
    "                              geometry=gpd.points_from_xy(df_geodata[\"Longitude\"], df_geodata[\"Latitude\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "\n",
    "# Eigene 5-Farben-Palette aus 'tab10' extrahieren\n",
    "custom_cmap = mcolors.ListedColormap(plt.get_cmap(\"tab10\").colors[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_cmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot erstellen\n",
    "fig, ax = plt.subplots(figsize=(15, 12))\n",
    "\n",
    "# Umrisse der Weltkarte plotten\n",
    "world.plot(ax=ax, color='white', edgecolor='black')\n",
    "\n",
    "# Städte als farbige Punkte nach Cluster einfärben\n",
    "scatter = gdf_cities.plot(column=\"Cluster\", cmap=custom_cmap, ax=ax, markersize=30, legend=True, alpha=1.0)\n",
    "\n",
    "# Titel & Achsen\n",
    "plt.title(\"Clusteranalyse der Städte basierend auf Luftverschmutzung\")\n",
    "plt.xlabel(\"Längengrad\")\n",
    "plt.ylabel(\"Breitengrad\")\n",
    "\n",
    "plt.savefig(\"../Images/cluster_plot.png\", dpi=300, bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.savefig(\"cluster_plot.png\", dpi=300, bbox_inches=\"tight\")\n",
    "plt.savefig(\"../Images/cluster_plot.png\", dpi=300, bbox_inches=\"tight\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
