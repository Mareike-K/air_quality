{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifikation\n",
    "\n",
    "In diesem Notebook werden verschiedene Klassifikationsmodelle trainiert. Ziel ist es, die St√§dte im Datensatz aufgrund ihrer Feinstaubbelastung in zwei Klassen einzuteilen. Als Zielvariable wird also die Belastung mit mittelgro√üen Feinstaubpartikeln (PM2.5, gemessen in ¬µg/m¬≥) angesetzt. \n",
    "\n",
    "Als Schwellenwert werden zwei Ans√§tze getestet:\n",
    "1. WHO-Richtline von 5 ¬µg/m¬≥: fachlicher Standard\n",
    "2. Median: datengetriebene Gr√∂√üe\n",
    "\n",
    "Als Modelle werden verglichen:\n",
    "1. Logistische Regression\n",
    "2. Random Forest\n",
    "3. Gradient Boosting\n",
    "\n",
    "Verwendet werden verschiedene Module der Python Bibliothek **Scitkit-learn** f√ºr maschinelles Lernen\n",
    "\n",
    "üìå **Datenstand:** `cleaned_air_quality_data_2025-03-27.csv`  \n",
    "üìÅ **Importiert aus:** lokaler Datei (--> gitignore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Inhaltsverzeichnis \n",
    "(Diese Art von Inhaltsverzeichnis mit Link funktioniert leider in Notebooks nicht, weil die as JSON gespeichert werden und nicht als HTML...)\n",
    "\n",
    "- [0. Datensatz laden](#0-datensatz-laden)\n",
    "- [1. Dataframe vorbereiten](#1-dateframe-vorbereiten)\n",
    "- [2. WHO-Richtlinie](#2-who-richtlinie)\n",
    "- [3. Median der Zielvariablen](#3-median-der-zielvariablen)\n",
    "- [4. Features, Target, Train-/Test-Split](#4-features-target-train-test-split)\n",
    "- [5. Logistic Regression](#5-logistic-regression)\n",
    "- [6. Random Forest](#6-random-forest)\n",
    "- [7. Gradient Boosting](#7-gradient-boosting)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Datensatz laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/cleaned_air_quality_data_2025-03-27.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dateframe vorbereiten\n",
    "\n",
    "Als Target benutzen wir mittelgro√üe Feinstaubpartikel (PM2.5), als Features alle anderen Schadstoffe im Datensatz: CO, NO‚ÇÇ, SO‚ÇÇ, O‚ÇÉ und (im allerersten Modell) PM10.\n",
    "\n",
    "Weil das Imputieren von Werten f√ºr nicht vorhandenen Kategorien (Schadstoffen) f√ºr eine Stadt nicht mehr als \"Raten\" ist, werden nur St√§dte in die Analyse mit aufgenommen, f√ºr die Messwerte zu allen sechs Luftschadstoffen vorliegen. (--> Wiebke: Was ich meine, ist: Ich kann innerhalb einer Stadt Werte imputieren, aber es ist ziemlicher Quatsch, die Werte von einer Stadt auf die andere zu √ºbertragen, also stadt√ºbergreifend zu imputieren.)\n",
    "\n",
    "Die Luftqualit√§t kann auch auf dem arithmetischen Mittel berechnet werden. Dies hat den Vorteil, dass die nat√ºrliche Varianz besser abgebildet wird und den Nachteil, dass Machine-Learning-Modelle sich bei der Klassifikation schlechter abschneiden. Beide Varianten wurden komplett durchgerechnet. Da hier das Verhalten unterschiedlicher Klassifikationsmodelle gezeigt werden soll, wurde f√ºr die finale Analyse der Median gew√§hlt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste relevanter Schadstoffe\n",
    "pollutants = ['Co', 'No2', 'O3', 'Pm10', 'Pm25', 'So2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mittelwerte pro Stadt berechnen (Index = City)\n",
    "df_median = df.groupby('City')[pollutants].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F√ºr jede Stadt: Wie viele Mittelwerte sind vorhanden?\n",
    "df_median['Num_Valid_Pollutants'] = df_median[pollutants].notna().sum(axis=1)\n",
    "\n",
    "# √úbersicht: Wie viele St√§dte haben wie viele g√ºltige Schadstoffwerte?\n",
    "coverage_summary = df_median['Num_Valid_Pollutants'].value_counts().sort_index()\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "coverage_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nur St√§dte mit allen 6 Schadstoff-Mittelwerten\n",
    "\n",
    "df_median_complete = df_median[df_median['Num_Valid_Pollutants'] == 6]\n",
    "\n",
    "len(df_median_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Dataframe enth√§lt nun 406 St√§dte, f√ºr die jeweils Werte f√ºr jeden Schadstoff vorliegen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. WHO-Richtlinie\n",
    "\n",
    "Als erstes wird die Klasseneinteilung auf der Grundlage einen fachlichen Standards, n√§mlich des aktuellen WHO-Grenzwerts f√ºr PM2.5 von 5‚ÄØ¬µg/m¬≥ vorgenommen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl St√§dte mit guter/schlechter Luft (nach WHO-Grenzwert)\n",
    "(df_median_complete['Pm25'] <= 5).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# St√§dte mit PM2.5 ‚â§ 5 ¬µg/m¬≥ filtern\n",
    "clean_cities = df_median_complete[df_median_complete['Pm25'] <= 5]\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "clean_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl g√ºltiger PM2.5-Werte pro Stadt\n",
    "pm25_counts = df.groupby('City')['Pm25'].count().sort_values()\n",
    "\n",
    "# Zeige nur die \"sauberen\" St√§dte\n",
    "pm25_counts.loc[['Plovdiv', 'Yazd']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dem WHO-Grenzwert entsprechen in unserem Datensatz nur zwei von 406 St√§dten: Plovdiv (Bulgarien), Yazd (Iran). Bei genauerem Hinschauen f√§llt allerdings auf, dass es f√ºr Plovidiv nur einen einzigen Messwert gibt und f√ºr Yazd nur sehr wenige. Die Messwerte sind damit nicht aussagekr√§ftig.\n",
    "\n",
    "Die WHO-Richtline kann also f√ºr das Training von Klassifikationsmodellen nicht als Schwellenwert verwendet werden - es h√§tte keine zweite Klasse, von der es lernen k√∂nnte.\n",
    "\n",
    "**OFFENE FRAGE**: Ist es gut, f√ºr die restliche Analyse alle St√§dte drinzulassen, auch wenn sie nur wenige Messwerte pro Schadstoff haben? Sollte man da noch was aussortieren? Oder einfach mal so lassen, weil in der Realit√§t die Datenqualit√§t auch nur selten optimal ist?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Median der Zielvariablen\n",
    "\n",
    "Als Alternative wird der Median als datengetriebener Grenzwert gew√§hlt. Die Einteilung in St√§dte mit guter und schlechter Luftqualit√§t basiert also auf dem Medianwert der durchschnittlichen PM2.5-Konzentration aller St√§dte im Datensatz. \n",
    "\n",
    "Durch die Verwendung des Medians entsteht eine ausgewogene Verteilung zwischen den beiden Klassen, die ein stabiles Training und eine faire Bewertung des Modells erm√∂glicht.\n",
    "\n",
    "Um ein Klassifikationsmodell zur Vorhersage der Luftqualit√§t von St√§dten zu erstellen, wird eine Zielvariable mit dem Namen **AirQualityLabel** eingef√ºhrt. Diese ordnet jeder Stadt eine von zwei Klassen zu:\n",
    "\n",
    "- 0 ‚Üí Gute Luftqualit√§t\n",
    "\n",
    "- 1 ‚Üí Schlechte Luftqualit√§t\n",
    "\n",
    "Die Luftqualit√§t wird aus den Medianen der einzelnen Schadstoffe pro Stadt berechnet. St√§dte mit einem PM2.5-Mittelwert √ºber dem Median werden als \"schlechte Luftqualit√§t\" (1) klassifiziert, alle anderen als \"gute Luftqualit√§t\" (0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classification = df_median_complete.copy()\n",
    "\n",
    "# Median von PM2.5 berechnen\n",
    "pm25_median = df_classification['Pm25'].median()\n",
    "\n",
    "# Zielvariable hinzuf√ºgen\n",
    "df_classification['AirQualityLabel'] = (df_classification['Pm25'] > pm25_median).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umgang mit NaN-Werten\n",
    "\n",
    "# Anzahl fehlender Werte pro Spalte\n",
    "df_classification[pollutants].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classification.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classification.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Features, Target, Train-/Test-Split\n",
    "\n",
    "Der Datensatz f√ºr die Klassifikation (df_classification) enth√§lt 406 St√§dte mit Medianwerten f√ºr die Schadstoffe, die als Features verwendet werden: CO, NO‚ÇÇ, SO‚ÇÇ, O‚ÇÉ und (im allerersten Modell) PM10.\n",
    "\n",
    "Als Target wird AirQualityLabel angesetzt, dessen Wert entsprechend dem Median von PM2.5 berechnet wurde (s. Abschnitt 3).\n",
    "\n",
    "Wir verwenden den Standard-Trainings-Test-Split von scikit-learn und nehmen 80% der Daten f√ºr das Training und 20% f√ºr den Test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lr_pm10 = ['Co', 'No2', 'O3', 'Pm10', 'So2']\n",
    "X = df_classification[features_lr_pm10]\n",
    "y = df_classification['AirQualityLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Split in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Logistic Regression\n",
    "\n",
    "Als erstes Modell wird die logistische Regression verwendet. Die logistische Regression ist ein statistisches Modell zur Vorhersage bin√§rer Ergebnisse, indem sie die Wahrscheinlichkeit eines Ereignisses anhand einer linearen Kombination von Variablen sch√§tzt. Dabei wird die lineare Ausgabe √ºber eine logistische Funktion in einen Wahrscheinlichkeitswert umgewandelt. Ein gro√üer Vorteil ist die einfache Interpretierbarkeit und schnelle Berechnung, was sie zu einem guten Ausgangspunkt f√ºr Klassifikationsaufgaben macht. Allerdings eignet sie sich prim√§r f√ºr lineare Zusammenh√§nge und st√∂√üt bei komplexeren Datenstrukturen schnell an ihre Grenzen.\n",
    "\n",
    "Im ersten Modell wird PM10 als zus√§tzliches Feature eingebunden, um experimentell zu untersuchen, wie sich dieses stark mit PM2.5 korrelierte Merkmal auf das Modell auswirkt. Da PM2.5 als Basis zur Berechnung von AirQualityLabel dient, k√∂nnte PM10 das Modell verzerren, indem es indirekt bereits bekannte Informationen liefert. In der zweiten Runde wird PM10 entfernt, um zu evaluieren, wie sich die Modellleistung ohne diesen ‚Äûk√ºnstlichen‚Äú Informationsvorsprung ver√§ndert."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Modelltraining\n",
    "model_lr_pm10 = LogisticRegression(max_iter=1000)\n",
    "model_lr_pm10.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen & Bewertung\n",
    "y_pred_lr_pm10 = model_lr_pm10.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_lr_pm10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mit PM10 als Feature liegt der F1-Score bei 90%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_lr_pm10 = confusion_matrix(y_test, y_pred_lr_pm10)\n",
    "\n",
    "cm_df = pd.DataFrame(cm_lr_pm10, \n",
    "                     index=[\"Tats√§chlich Negativ\", \"Tats√§chlich Positiv\"], \n",
    "                     columns=[\"Vorhergesagt Negativ\", \"Vorhergesagt Positiv\"])\n",
    "\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Das folgende Modell ist eien Wiederholung des vorhergehenden, aber ohne PM10 als Feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_lr = ['Co', 'No2', 'O3', 'So2']\n",
    "X = df_classification[features_lr]\n",
    "y = df_classification['AirQualityLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelltraining\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen & Bewertung\n",
    "y_pred_lr = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_lr))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ohne PM10 als Feature wird nur noch ein F1-Score von 77% erreicht."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
    "\n",
    "cm_df = pd.DataFrame(cm_lr, \n",
    "                     index=[\"Tats√§chlich Negativ\", \"Tats√§chlich Positiv\"], \n",
    "                     columns=[\"Vorhergesagt Negativ\", \"Vorhergesagt Positiv\"])\n",
    "\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Beide Modelle erscheinen ausgewogen - keine der beiden Klassen wird bevorzugt. Das Modell mit PM10 als Feature erreicht mit 90% einen deutlich h√∂heren F1-Score als das Modell ohne PM10 (F1: 77%).\n",
    "\n",
    "Dennoch spricht einiges daf√ºr, PM10 als Feature wegzulassen: Da PM10 hoch mit PM2.5 korreliert ‚Äì aus dem ja das AirQualityLabel abgeleitet wird ‚Äì besteht die Gefahr eines Informationslecks, bei dem das Modell indirekt schon ‚Äûvorab‚Äú Informationen √ºber das Ziel erh√§lt. Dies kann zu verzerrten Validierungsergebnissen und schlechterer Generalisierbarkeit f√ºhren, insbesondere wenn das Modell auf neuen, unbekannten Daten angewendet wird. Zudem erh√∂ht die Einbeziehung hoch korrelierter Features das Risiko von Overfitting, wodurch das Modell zu sehr auf spezifische Trainingsdaten abgestimmt wird.\n",
    "\n",
    "Daher ist es sinnvoll, PM10 zu entfernen, um ein robusteres und interpretierbareres Klassifikationsmodell zu entwickeln. Die folgenden Modelle werden nur mit dem reduzierten Feature-Satz berechnet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Random Forest\n",
    "\n",
    "Der Random Forest ist ein Ensemble-Verfahren, das viele Entscheidungsb√§ume (decision trees) kombiniert, um robustere und stabilere Vorhersagen zu erzielen. Jeder Baum wird auf einer zuf√§lligen Teilmenge der Daten sowie einer zuf√§lligen Auswahl von Merkmalen trainiert, wodurch das Modell insgesamt weniger anf√§llig f√ºr √úberanpassung ist. Ein wesentlicher Vorteil ist seine hohe Genauigkeit und Robustheit gegen√ºber Ausrei√üern. Auf der anderen Seite leidet die Interpretierbarkeit, da es schwierig ist, den Einfluss einzelner Variablen im Ensemble nachzuvollziehen, und der Rechenaufwand kann bei gro√üen Datens√§tzen erheblich sein."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and train test split repeated from previous model, just to make clear what is being used:\n",
    "\n",
    "features_rf = ['Co', 'No2', 'O3', 'So2']\n",
    "X = df_classification[features_rf]\n",
    "y = df_classification['AirQualityLabel']\n",
    "\n",
    "# Split in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest-Modell erstellen\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Modell trainieren\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen & Bewertung drucken\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "cm_df = pd.DataFrame(cm_rf, \n",
    "                     index=[\"Tats√§chlich Negativ\", \"Tats√§chlich Positiv\"], \n",
    "                     columns=[\"Vorhergesagt Negativ\", \"Vorhergesagt Positiv\"])\n",
    "\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Random Forest erreicht mit 82% einen leicht h√∂heren F1-Score als die Logistische Regression. Auch diese Modell erscheint einigerma√üen ausgewogen (6 false negatives zu 9 false positives).\n",
    "\n",
    "Ein Nachteil des random Forests gegen√ºber der Logistischen Regression ist, dass der Einfluss einzelner Features auf das Modell im Ensemble schwer nachzuvollziehen ist. Hilfreiche Anhaltspunkte kann hier die Berechnung der Feature Importances geben, die zeigen, wie stark einzelne Features zur Verringerung der Unreinheit in den Entscheidungsb√§umen beitragen. Allerdings sollte man sich bewusst sein, dass die Feature Importances nicht alle komplexen Wechselwirkungen zwischen den Features vollst√§ndig abbilden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance extrahieren\n",
    "importances = rf_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Importance in ein DataFrame umwandeln\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': features_rf,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Feature Importance anzeigen mit \"Feature\" als Hue und deaktivierter Legende\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df,\n",
    "            hue='Feature', palette='viridis', dodge=False)\n",
    "plt.legend([], [], frameon=False)\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout();\n",
    "\n",
    "plt.savefig(\"./images/Feature_Importance_Random_Forest.png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Am wichtigsten f√ºr die Klassifizierung ist das Feature \"CO\". Welche St√§dte wurden falsch klassifiziert?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Falsch klassifizierte St√§dte finden\n",
    "incorrect_predictions = X_test.copy()\n",
    "incorrect_predictions['True Label'] = y_test\n",
    "incorrect_predictions['Predicted Label'] = y_pred_rf\n",
    "\n",
    "# Nur falsch klassifizierte St√§dte herausfiltern\n",
    "incorrect_predictions = incorrect_predictions[incorrect_predictions['True Label'] != incorrect_predictions['Predicted Label']]\n",
    "\n",
    "# CO-Werte der falsch klassifizierten St√§dte\n",
    "incorrect_predictions['CO'] = X_test.loc[incorrect_predictions.index, 'Co']\n",
    "\n",
    "# Ausgabe der St√§dte mit ihren CO-Werten\n",
    "# incorrect_predictions[['True Label', 'Predicted Label', 'CO', 'So2', 'O3', 'No2']].sort_values(by='CO', ascending=False)\n",
    "incorrect_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incorrect_predictions.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Welche Messwerte (Median) haben die St√§dte im einzelnen?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classification.loc[['Budapest', 'Okayama', 'Prato', 'Lampang', 'Nara-shi', 'Tuzla',\n",
    "          'Abu dhabi', 'Worcester', 'Suncheon', 'San luis potos√≠', 'Zabrze',\n",
    "          'Concepci√≥n', 'Tainan', 'Douliu', 'Winnipeg']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CO-Werte der falsch klassifizierten St√§dte\n",
    "co_values = incorrect_predictions['CO']\n",
    "\n",
    "# Berechne die wichtigsten Statistiken (Durchschnitt, IQR)\n",
    "co_mean = co_values.mean()\n",
    "co_std = co_values.std()\n",
    "co_min = co_values.min()\n",
    "co_max = co_values.max()\n",
    "\n",
    "# Berechne Interquartilsabstand (IQR)\n",
    "Q1 = co_values.quantile(0.25)\n",
    "Q3 = co_values.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Anzeigen der CO-Statistiken\n",
    "print(f\"Durchschnittlicher CO-Wert: {co_mean:.2f}\")\n",
    "print(f\"Standardabweichung: {co_std:.2f}\")\n",
    "print(f\"Minimaler CO-Wert: {co_min:.2f}\")\n",
    "print(f\"Maximaler CO-Wert: {co_max:.2f}\")\n",
    "print(f\"Interquartilsabstand (IQR): {IQR:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Man sieht, dass das Modell vor allem dann falsch klassifiziert, wenn das Feature mit der h√∂chsten Feature Importance (CO) unerwartet niedrig ist.\n",
    "\n",
    "Ich glaube nicht, dass man da noch viel drehen kann. Das Modell ist eigentlich recht gut, wenn man bedenkt, dass die Messwerte zum Teil recht abenteuerlich sind."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Gradient Boosting\n",
    "\n",
    "Gradient Boosting ist ein sequentielles Ensemble-Verfahren, bei dem schwache Lernmodelle ‚Äì meist kleine Entscheidungsb√§ume ‚Äì iterativ trainiert werden, um die Fehler der vorherigen Modelle zu korrigieren. Das Modell optimiert dabei schrittweise eine Verlustfunktion mithilfe von Gradientenabstieg, was zu einer sehr pr√§zisen Vorhersage f√ºhrt.\n",
    "\n",
    "Zu den Vorteilen z√§hlen eine hohe Leistungsf√§higkeit und die F√§higkeit, komplexe Zusammenh√§nge zu erfassen. Allerdings kann Gradient Boosting bei unzureichender Abstimmung der Hyperparameter schnell √ºberanpassen und ist in der Regel rechenintensiver als einfachere Modelle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Modell erstellen\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Modell trainieren\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen & Bewertung\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "# print(confusion_matrix(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm_gb = confusion_matrix(y_test, y_pred_gb)\n",
    "\n",
    "cm_df = pd.DataFrame(cm_gb, \n",
    "                     index=[\"Tats√§chlich Negativ\", \"Tats√§chlich Positiv\"], \n",
    "                     columns=[\"Vorhergesagt Negativ\", \"Vorhergesagt Positiv\"])\n",
    "\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gradient Boosting erreicht mit 84% noch einmal einen leicht h√∂heren F1-Score. Auch diese Modell erscheint einigerma√üen ausgewogen (5 false negatives zu 8 false positives)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
