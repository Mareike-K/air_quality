{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#- Morgen testen, ob der download von den pop daten mit dem flex namen auch funktioniert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import():\n",
    "    \"\"\"\n",
    "    Import der Daten aus allen Dateien, die mit 'waqi-covid-' anfangen.\n",
    "    Entfernen von Duplikaten und Umbenennung bestimmter Spaltenwerte.\n",
    "    Zusammenführung der DataFrames.\n",
    "    \"\"\"\n",
    "    data_folder = './data/'\n",
    "    all_files = [f for f in os.listdir(data_folder) if f.startswith('waqi-covid-') and f.endswith('.csv') or f == 'airquality-covid19-cities.json']\n",
    "    dataframes = []\n",
    "\n",
    "    if not all_files:\n",
    "        print(\"Keine Dateien gefunden.\")\n",
    "        return None\n",
    "\n",
    "    for file in all_files:\n",
    "        file_path = os.path.join(data_folder, file)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, comment='#')\n",
    "\n",
    "            if \"Specie\" not in df.columns:\n",
    "                print(f\"Spalte 'Specie' fehlt in {file}\")\n",
    "                continue\n",
    "\n",
    "            df[\"Specie\"] = df[\"Specie\"].replace(\"wind gust\", \"wind-gust\")\n",
    "            df[\"Specie\"] = df[\"Specie\"].replace(\"wind speed\", \"wind-speed\")\n",
    "            df = df.drop_duplicates()\n",
    "\n",
    "            if df.empty:\n",
    "                print(f\"{file} enthält nach Duplikat-Entfernung keine Daten mehr.\")\n",
    "                continue\n",
    "\n",
    "            dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Verarbeiten von {file}: {e}\")\n",
    "\n",
    "    if not dataframes:\n",
    "        print(\"Keine gültigen Daten vorhanden.\")\n",
    "        return None\n",
    "\n",
    "    return pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spalte 'Specie' fehlt in airquality-covid19-cities.json\n",
      "waqi-covid-2022Q1.csv enthält nach Duplikat-Entfernung keine Daten mehr.\n",
      "                Date Country        City    Specie  count     min     max  \\\n",
      "0         2015-01-06      KR      Jeonju        co    124     0.1    12.3   \n",
      "1         2015-01-22      KR      Jeonju        co    116     4.5    10.0   \n",
      "2         2015-03-30      KR      Jeonju        co    118     1.2    11.2   \n",
      "3         2015-05-27      KR      Jeonju        co     93     2.3     5.6   \n",
      "4         2015-02-03      KR      Jeonju        co    133     4.5    13.4   \n",
      "...              ...     ...         ...       ...    ...     ...     ...   \n",
      "14257913  2024-10-05      MN  Ulan Bator  pressure     46  1027.0  1031.0   \n",
      "14257914  2025-02-17      MN  Ulan Bator  pressure    264  1025.0  1027.0   \n",
      "14257915  2025-02-26      MN  Ulan Bator  pressure    264  1002.0  1016.0   \n",
      "14257916  2024-04-04      MN  Ulan Bator  pressure    240  1016.0  1019.0   \n",
      "14257917  2024-05-15      MN  Ulan Bator  pressure    240  1011.0  1026.0   \n",
      "\n",
      "          median  variance  \n",
      "0            4.5     55.74  \n",
      "1            6.7     16.09  \n",
      "2            5.6     35.98  \n",
      "3            3.4      6.54  \n",
      "4            7.8     39.24  \n",
      "...          ...       ...  \n",
      "14257913  1029.0     15.54  \n",
      "14257914  1026.0      6.06  \n",
      "14257915  1009.0    213.15  \n",
      "14257916  1018.0      6.68  \n",
      "14257917  1018.0    283.89  \n",
      "\n",
      "[14257918 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "df=data_import()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geo_data(df):\n",
    "    \"\"\"\n",
    "    Fügt die Geodaten zu den Städten hinzu\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # JSON-Datei laden mit Fehlerbehandlung\n",
    "    try:\n",
    "        with open('./data/airquality-covid19-cities.json', 'r', encoding='utf-8') as file:\n",
    "            geodata = json.load(file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "        print(f\"Fehler beim Laden der JSON-Datei: {e}\")\n",
    "        return df\n",
    "\n",
    "    geodata = geodata.get(\"data\", [])\n",
    "\n",
    "    # Erstellen eines DataFrames mit Städten und Geokoordinaten\n",
    "    df_places = pd.DataFrame([\n",
    "        {\n",
    "            \"City\": entry.get(\"Place\", {}).get(\"name\"),\n",
    "            \"Latitude\": entry.get(\"Place\", {}).get(\"geo\", [None, None])[0],\n",
    "            \"Longitude\": entry.get(\"Place\", {}).get(\"geo\", [None, None])[1]\n",
    "        }\n",
    "        for entry in geodata if \"Place\" in entry and \"geo\" in entry.get(\"Place\", {})\n",
    "    ])\n",
    "\n",
    "    # Entferne Zeilen mit fehlenden Stadtnamen\n",
    "    df_places.dropna(subset=[\"City\"], inplace=True)\n",
    "\n",
    "    # Standardisiere Stadtnamen\n",
    "    df_places[\"City\"] = df_places[\"City\"].str.lower().str.strip()\n",
    "    df[\"City\"] = df[\"City\"].str.lower().str.strip()\n",
    "\n",
    "    # Zusammenführen der beiden DataFrames über \"City\"\n",
    "    df = df.merge(df_places, on=\"City\", how=\"left\")\n",
    "\n",
    "    # Überprüfung auf fehlende Geodaten\n",
    "    fehlende_staedte = df[df[\"Latitude\"].isna()][\"City\"].unique()\n",
    "    if fehlende_staedte.size > 0:\n",
    "        print(f\"Keine Geodaten gefunden für: {', '.join(fehlende_staedte)}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keine Geodaten gefunden für: washington d.c.\n",
      "                Date Country      City      Specie  count     min     max  \\\n",
      "11269325  2023-06-11      CN      wuxi        pm10    119    13.0    64.0   \n",
      "5523550   2020-07-17      TR   antakya        pm10     24    28.0    35.0   \n",
      "11500873  2023-08-30      US  honolulu    pressure     48  1016.5  1019.2   \n",
      "7958225   2021-07-10      CN    haikou  wind-speed    147     0.5     6.6   \n",
      "13668752  2024-08-26      FR  besançon          o3     10     5.9    36.5   \n",
      "184450    2015-04-29      US    queens          o3     48    16.8    40.0   \n",
      "8122962   2021-10-27      FR     nancy    humidity    168    59.0   100.0   \n",
      "1743650   2018-05-20      BA     tuzla    pressure     82     0.0     0.0   \n",
      "10957200  2023-06-11      RS       niš    humidity     48    44.5   100.0   \n",
      "2296344   2019-05-06      US    austin    pressure     56  1009.5  1015.8   \n",
      "\n",
      "          median  variance  Latitude  Longitude  \n",
      "11269325    29.0   1868.08  31.56887  120.28857  \n",
      "5523550     32.0     49.55  36.20655   36.15722  \n",
      "11500873  1018.2      7.04  21.30694 -157.85833  \n",
      "7958225      1.5     43.34  20.04583  110.34167  \n",
      "13668752    13.2   1001.39  47.24878    6.01815  \n",
      "184450      31.2    536.69  40.68149  -73.83652  \n",
      "8122962     93.0   1463.54  48.68439    6.18496  \n",
      "1743650      0.0      0.00  44.53842   18.66709  \n",
      "10957200    79.5   3327.66  43.32472   21.90333  \n",
      "2296344   1012.1     26.17  30.26715  -97.74306  \n"
     ]
    }
   ],
   "source": [
    "df = geo_data(df)\n",
    "print(df.sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    \"\"\"Bereinigung der Daten\n",
    "    - nicht benötigte Spalten löschen\n",
    "    - Zusammenfassung der Daten nach Datum, Land, Stadt und Spezies, so dass nur ein Messwert je Species (Median) pro Tag/ Stadt verbleibt\n",
    "    - Spalte Species aufteilen\n",
    "    - df als csv speichern im Datenverzeichnis\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df.drop(columns=['variance', 'min', 'max'], errors='ignore')\n",
    "\n",
    "    df = df.groupby([\"Date\", \"Country\", \"City\", \"Specie\"], as_index=False).agg({\"median\": \"mean\"})  \n",
    "\n",
    "    df = df.pivot(index=[\"Date\", \"Country\", \"City\"], columns=\"Specie\", values='median').reset_index()\n",
    "\n",
    "    df[\"City\"] = df[\"City\"].str.lower().str.strip()\n",
    "    df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    df = geo_data(df)\n",
    "\n",
    "    df = weather_data(df)\n",
    "\n",
    "    output_path = './data/cleaned_data.csv'\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✅ Datei wurde gespeichert: {output_path}\")\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Country</th>\n",
       "      <th>City</th>\n",
       "      <th>Specie</th>\n",
       "      <th>count</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>median</th>\n",
       "      <th>variance</th>\n",
       "      <th>Latitude</th>\n",
       "      <th>Longitude</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>499693</th>\n",
       "      <td>2016-04-10</td>\n",
       "      <td>CN</td>\n",
       "      <td>nanjing</td>\n",
       "      <td>pm10</td>\n",
       "      <td>239</td>\n",
       "      <td>55.0</td>\n",
       "      <td>190.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2607.26</td>\n",
       "      <td>32.06167</td>\n",
       "      <td>118.77778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210023</th>\n",
       "      <td>2015-01-08</td>\n",
       "      <td>JP</td>\n",
       "      <td>kumamoto</td>\n",
       "      <td>pm10</td>\n",
       "      <td>300</td>\n",
       "      <td>1.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>388.20</td>\n",
       "      <td>32.80589</td>\n",
       "      <td>130.69181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963955</th>\n",
       "      <td>2019-03-26</td>\n",
       "      <td>TR</td>\n",
       "      <td>kayseri</td>\n",
       "      <td>pm10</td>\n",
       "      <td>68</td>\n",
       "      <td>4.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>2222.46</td>\n",
       "      <td>38.73222</td>\n",
       "      <td>35.48528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11549837</th>\n",
       "      <td>2023-07-10</td>\n",
       "      <td>AU</td>\n",
       "      <td>newcastle</td>\n",
       "      <td>temperature</td>\n",
       "      <td>142</td>\n",
       "      <td>8.5</td>\n",
       "      <td>19.9</td>\n",
       "      <td>12.7</td>\n",
       "      <td>94.67</td>\n",
       "      <td>-32.92953</td>\n",
       "      <td>151.78010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2466876</th>\n",
       "      <td>2019-06-22</td>\n",
       "      <td>CN</td>\n",
       "      <td>hangzhou</td>\n",
       "      <td>pressure</td>\n",
       "      <td>312</td>\n",
       "      <td>1003.0</td>\n",
       "      <td>1007.0</td>\n",
       "      <td>1006.0</td>\n",
       "      <td>8.54</td>\n",
       "      <td>30.29365</td>\n",
       "      <td>120.16142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10050520</th>\n",
       "      <td>2022-11-07</td>\n",
       "      <td>CN</td>\n",
       "      <td>wuxi</td>\n",
       "      <td>co</td>\n",
       "      <td>84</td>\n",
       "      <td>3.7</td>\n",
       "      <td>18.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>142.89</td>\n",
       "      <td>31.56887</td>\n",
       "      <td>120.28857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943538</th>\n",
       "      <td>2019-01-26</td>\n",
       "      <td>FR</td>\n",
       "      <td>paris</td>\n",
       "      <td>wind-gust</td>\n",
       "      <td>384</td>\n",
       "      <td>0.8</td>\n",
       "      <td>20.4</td>\n",
       "      <td>9.8</td>\n",
       "      <td>145.67</td>\n",
       "      <td>48.85341</td>\n",
       "      <td>2.34880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8594842</th>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>NL</td>\n",
       "      <td>utrecht</td>\n",
       "      <td>pressure</td>\n",
       "      <td>120</td>\n",
       "      <td>986.4</td>\n",
       "      <td>1005.0</td>\n",
       "      <td>989.2</td>\n",
       "      <td>545.17</td>\n",
       "      <td>52.09083</td>\n",
       "      <td>5.12222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9953723</th>\n",
       "      <td>2022-11-23</td>\n",
       "      <td>ZA</td>\n",
       "      <td>vereeniging</td>\n",
       "      <td>o3</td>\n",
       "      <td>102</td>\n",
       "      <td>0.5</td>\n",
       "      <td>24.2</td>\n",
       "      <td>12.3</td>\n",
       "      <td>460.95</td>\n",
       "      <td>-26.67313</td>\n",
       "      <td>27.92615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11911752</th>\n",
       "      <td>2023-10-18</td>\n",
       "      <td>CA</td>\n",
       "      <td>winnipeg</td>\n",
       "      <td>no2</td>\n",
       "      <td>13</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>5.43</td>\n",
       "      <td>49.88440</td>\n",
       "      <td>-97.14704</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Date Country         City       Specie  count     min     max  \\\n",
       "499693    2016-04-10      CN      nanjing         pm10    239    55.0   190.0   \n",
       "210023    2015-01-08      JP     kumamoto         pm10    300     1.0    36.0   \n",
       "1963955   2019-03-26      TR      kayseri         pm10     68     4.0    76.0   \n",
       "11549837  2023-07-10      AU    newcastle  temperature    142     8.5    19.9   \n",
       "2466876   2019-06-22      CN     hangzhou     pressure    312  1003.0  1007.0   \n",
       "10050520  2022-11-07      CN         wuxi           co     84     3.7    18.1   \n",
       "1943538   2019-01-26      FR        paris    wind-gust    384     0.8    20.4   \n",
       "8594842   2021-11-03      NL      utrecht     pressure    120   986.4  1005.0   \n",
       "9953723   2022-11-23      ZA  vereeniging           o3    102     0.5    24.2   \n",
       "11911752  2023-10-18      CA     winnipeg          no2     13     0.2     2.7   \n",
       "\n",
       "          median  variance  Latitude  Longitude  \n",
       "499693      86.0   2607.26  32.06167  118.77778  \n",
       "210023      13.0    388.20  32.80589  130.69181  \n",
       "1963955     31.0   2222.46  38.73222   35.48528  \n",
       "11549837    12.7     94.67 -32.92953  151.78010  \n",
       "2466876   1006.0      8.54  30.29365  120.16142  \n",
       "10050520     8.2    142.89  31.56887  120.28857  \n",
       "1943538      9.8    145.67  48.85341    2.34880  \n",
       "8594842    989.2    545.17  52.09083    5.12222  \n",
       "9953723     12.3    460.95 -26.67313   27.92615  \n",
       "11911752     0.6      5.43  49.88440  -97.14704  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meteostat import Daily, Stations\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "def weather_data(df):\n",
    "    \"\"\"\n",
    "    Ruft Wetterdaten für Städte im DataFrame ab und integriert sie.\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # Städte extrahieren und Duplikate entfernen\n",
    "    cities = df[['City', 'Latitude', 'Longitude']].drop_duplicates()\n",
    "\n",
    "    # Zeitspanne festlegen\n",
    "    start = datetime(2015, 1, 1)\n",
    "    end = datetime(2024, 12, 31)\n",
    "\n",
    "    # DataFrame für alle Städte vorbereiten\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    # Wetterdaten für jede Stadt abrufen und hinzufügen\n",
    "    for _, city in cities.iterrows():\n",
    "        try:\n",
    "            # Nächste Wetterstation suchen\n",
    "            stations = Stations().nearby(city['Latitude'], city['Longitude'])\n",
    "            station = stations.fetch(1)\n",
    "\n",
    "            if not station.empty:\n",
    "                station_id = station.index[0]\n",
    "\n",
    "                # Tägliche Wetterdaten abrufen\n",
    "                data = Daily(station_id, start, end).fetch()\n",
    "\n",
    "                # NaN-Daten rausfiltern\n",
    "                data.dropna(how='all', inplace=True)\n",
    "\n",
    "                if not data.empty:\n",
    "                    # Stadtname hinzufügen\n",
    "                    data[\"City\"] = city[\"City\"]\n",
    "\n",
    "                    # Daten in den Gesamtdaten-Frame einfügen\n",
    "                    all_data = pd.concat([all_data, data])\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Fehler beim Abrufen der Daten für {city['City']}: {e}\")\n",
    "\n",
    "    # Index zurücksetzen\n",
    "    all_data.reset_index(inplace=True)\n",
    "\n",
    "    # Spalte 'time' umbenennen in 'Date'\n",
    "    all_data.rename(columns={'time': 'Date'}, inplace=True)\n",
    "\n",
    "    # Standardisiere den Stadtnamen\n",
    "    all_data[\"City\"] = all_data[\"City\"].str.lower().str.strip()\n",
    "\n",
    "    print(f\"✅ Wetterdaten gesammelt für {all_data['City'].nunique()} Städte\")\n",
    "\n",
    "    # Konvertiere die 'Date'-Spalte in beiden DataFrames zu String-Format\n",
    "    # df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
    "    all_data['Date'] = pd.to_datetime(all_data['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Berechne den Anteil der NaN-Werte pro Spalte\n",
    "    missing_percentage = all_data.isna().mean() * 100\n",
    "    # Lösche Spalten mit mehr als 80% NaN-Werten\n",
    "    all_data = all_data.loc[:, missing_percentage <= 80]\n",
    "\n",
    "    # Zusammenführen der beiden DataFrames über \"City\" und \"Date\"\n",
    "    df = pd.merge(df, all_data, on=[\"City\", 'Date'], how=\"left\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keine Geodaten gefunden für: washington d.c.\n",
      "✅ Wetterdaten gesammelt für 578 Städte\n",
      "✅ Datei wurde gespeichert: ./data/cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "df = data_cleaning(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  331432      235178      1403671     1306809     530657   \\\n",
      "Date           2018-05-21  2017-05-09  2024-05-20  2023-10-24  2019-11-06   \n",
      "Country                MY          JP          PL          NP          AT   \n",
      "City           alor setar     okayama      zabrze     pokhara        linz   \n",
      "aqi                  20.0         NaN         NaN         NaN         NaN   \n",
      "co                    NaN         4.5         NaN         NaN         0.1   \n",
      "d                     NaN         NaN         NaN         NaN         NaN   \n",
      "dew                   NaN         NaN         NaN        14.1         5.0   \n",
      "humidity             88.0         NaN        82.6        78.1        87.0   \n",
      "mepaqi                NaN         NaN         NaN         NaN         NaN   \n",
      "neph                  NaN         NaN         NaN         NaN         NaN   \n",
      "no2                   NaN        20.4         NaN         NaN        15.1   \n",
      "o3                    NaN        26.4         NaN         NaN         NaN   \n",
      "pm1                   NaN         NaN         NaN        41.0         NaN   \n",
      "pm10                  NaN        40.0        15.0        10.0        18.0   \n",
      "pm25                  NaN        91.0         NaN        42.0        57.0   \n",
      "pol                   NaN         NaN         NaN         NaN         NaN   \n",
      "precipitation         NaN         NaN         NaN         NaN         NaN   \n",
      "pressure           1007.0         NaN      1011.1       924.5      1006.9   \n",
      "psi                   NaN         NaN         NaN         NaN         NaN   \n",
      "so2                   NaN        12.9         NaN         NaN         1.1   \n",
      "temperature          28.1         NaN        15.8        18.3         6.6   \n",
      "uvi                   NaN         NaN         NaN         NaN         NaN   \n",
      "wd                    NaN         NaN         NaN         NaN         NaN   \n",
      "wind-gust             NaN         NaN         3.3         NaN         1.7   \n",
      "wind-speed            NaN         NaN         1.5         0.6         1.0   \n",
      "Latitude          6.12104       34.65    50.32492    28.26689    48.30639   \n",
      "Longitude       100.36014   133.93333    18.78576    83.96851    14.28611   \n",
      "tavg                 28.5        16.4        16.3        19.0         7.1   \n",
      "tmin                 26.0         NaN        10.6        11.9         5.6   \n",
      "tmax                 32.0        19.6        22.8        27.4         8.8   \n",
      "prcp                  NaN         0.0         0.0         0.0         NaN   \n",
      "wdir                  NaN         NaN       146.0       287.0       229.0   \n",
      "wspd                  6.9         NaN         5.3         6.3         2.4   \n",
      "pres               1007.2         NaN      1013.0      1018.9      1004.9   \n",
      "\n",
      "                  708419      528017      446658        864203      395996   \n",
      "Date           2020-08-23  2019-11-01  2019-06-17    2021-05-07  2019-03-20  \n",
      "Country                CN          JP          BH            GR          CN  \n",
      "City            guangzhou   takamatsu      manama  thessaloníki      shiyan  \n",
      "aqi                   NaN         NaN         NaN           NaN         NaN  \n",
      "co                    6.4         4.5         NaN           NaN         9.1  \n",
      "d                     NaN         NaN         NaN           NaN         NaN  \n",
      "dew                  23.0         NaN        22.5           NaN         NaN  \n",
      "humidity             70.5        83.0        39.0          60.0        67.0  \n",
      "mepaqi                NaN         NaN         NaN           NaN         NaN  \n",
      "neph                  NaN         NaN         NaN           NaN         NaN  \n",
      "no2                  12.4         9.3         NaN           NaN         8.7  \n",
      "o3                   26.4        24.1         NaN          17.5         NaN  \n",
      "pm1                   NaN         NaN         NaN           NaN         NaN  \n",
      "pm10                 41.0        19.0         NaN          21.0        48.0  \n",
      "pm25                 85.0        53.0       142.0          46.0        93.0  \n",
      "pol                   NaN         NaN         NaN           NaN         NaN  \n",
      "precipitation         NaN         NaN         NaN           NaN         NaN  \n",
      "pressure           1006.6      1020.2      1000.0        1013.7      1003.9  \n",
      "psi                   NaN         NaN         NaN           NaN         NaN  \n",
      "so2                   3.6         2.9         NaN           6.1         5.1  \n",
      "temperature          31.0        14.7        36.0          20.3        11.9  \n",
      "uvi                   NaN         NaN         NaN           NaN         NaN  \n",
      "wd                    NaN         NaN         NaN           NaN         NaN  \n",
      "wind-gust             4.9         3.5         NaN           2.0         NaN  \n",
      "wind-speed            1.0         1.0         7.2           0.5         NaN  \n",
      "Latitude         23.11667    34.33333    26.22787      40.64361     32.6475  \n",
      "Longitude          113.25      134.05    50.58565      22.93086   110.77806  \n",
      "tavg                 31.1        17.9        37.0          19.4        19.4  \n",
      "tmin                 25.2        11.7        33.4          13.8        11.6  \n",
      "tmax                 35.7        23.0        40.4          24.0         NaN  \n",
      "prcp                  0.0         0.0         NaN           NaN         0.5  \n",
      "wdir                 14.0         NaN       302.0         151.0         NaN  \n",
      "wspd                  4.9         NaN        22.0           6.3         NaN  \n",
      "pres               1006.2         NaN       999.9        1012.9         NaN  \n"
     ]
    }
   ],
   "source": [
    "print(df.sample(10).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_copy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmeteostat\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Daily, Stations\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mdatetime\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datetime\n\u001b[1;32m----> 7\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf_copy\u001b[49m()\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Städte\u001b[39;00m\n\u001b[0;32m     10\u001b[0m cities \u001b[38;5;241m=\u001b[39m df[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCity\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mdrop_duplicates()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_copy' is not defined"
     ]
    }
   ],
   "source": [
    "#WEtterdaten integrieren\n",
    "\n",
    "\n",
    "from meteostat import Daily, Stations\n",
    "from datetime import datetime\n",
    "\n",
    "df = df_copy()\n",
    "\n",
    "# Städte\n",
    "cities = df[['City', 'Latitude', 'Longitude']].drop_duplicates()\n",
    "\n",
    "# Zeitspanne festlegen\n",
    "start = datetime(2015, 1, 1)\n",
    "end = datetime(2024, 12, 31)\n",
    "\n",
    "# DataFrame für alle Städte vorbereiten\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Daten für jede Stadt abrufen und hinzufügen\n",
    "for _, city in cities.iterrows():\n",
    "    # Nächste Wetterstation suchen\n",
    "    stations = Stations().nearby(city['Latitude'], city['Longitude'])\n",
    "    station = stations.fetch(1)\n",
    "\n",
    "    if not station.empty:\n",
    "        station_id = station.index[0]\n",
    "\n",
    "        # Tägliche Wetterdaten abrufen\n",
    "        data = Daily(station_id, start, end).fetch()\n",
    "\n",
    "        # Nan-Daten rausfiltern\n",
    "        data.dropna(how='all', inplace=True)\n",
    "\n",
    "        if not data.empty:\n",
    "            # Stadtname hinzufügen\n",
    "            data[\"City\"] = city[\"City\"]\n",
    "\n",
    "            # Daten in den Gesamtdaten-Frame einfügen\n",
    "            all_data = pd.concat([all_data, data])\n",
    "\n",
    "\n",
    "# Index zurücksetzen\n",
    "all_data.reset_index(inplace=True)\n",
    "\n",
    "# Spalte time umbennen in Date\n",
    "all_data.rename(columns={'time': 'Date'}, inplace=True) \n",
    "\n",
    "# Standardisiere den Stadtnamen für eine bessere Übereinstimmung\n",
    "all_data[\"City\"] = all_data[\"City\"].str.lower().str.strip()\n",
    "\n",
    "print(f\"✅ Wetterdaten gesammelt für {all_data['City'].nunique()} Städte\")\n",
    "\n",
    "# # Ergebnis anzeigen\n",
    "# print(all_data.head())\n",
    "\n",
    "# Konvertiere die 'Date' Spalte in beiden DataFrames zu datetime\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
    "all_data['Date'] = pd.to_datetime(all_data['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "# Berechne den Anteil der NaN-Werte pro Spalte\n",
    "missing_percentage = all_data.isna().mean() * 100\n",
    "\n",
    "# Lösche die Spalten, bei denen der Anteil an NaN-Werten größer als 80% ist\n",
    "all_data = all_data.loc[:, missing_percentage <= 80]\n",
    "\n",
    "\n",
    "# Zusammenführen der beiden DataFrames über \"City\"\n",
    "df = pd.merge(df, all_data, on=[\"City\", 'Date'],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df.shape)\n",
    "df.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
