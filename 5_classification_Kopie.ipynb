{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Klassifikation\n",
    "\n",
    "In diesem Notebook werden verschiedene Klassifikationsmodelle trainiert. Ziel ist es, die St√§dte im Datensatz aufgrund ihrer Feinstaubbelastung in zwei Klassen einzuteilen. Als Zielvariable wird also die Belastung mit mittelgro√üen Feinstaubpartikeln (PM2.5, gemessen in ¬µg/m¬≥) angesetzt. \n",
    "\n",
    "Als Schwellenwert werden zwei Ans√§tze getestet:\n",
    "1. WHO-Richtline von 5 ¬µg/m¬≥: fachlicher Standard\n",
    "2. Median: datengetriebene Gr√∂√üe\n",
    "\n",
    "Als Modelle werden verglichen:\n",
    "1. Logistische Regression\n",
    "2. Random Forest\n",
    "3. Gradient Boosting\n",
    "\n",
    "Verwendet werden verschiedene Module der Python Bibliothek **Scitkit-learn** f√ºr maschinelles Lernen\n",
    "\n",
    "üìå **Datenstand:** `cleaned_air_quality_data_2025-03-27.csv`  \n",
    "üìÅ **Importiert aus:** lokaler Datei (--> gitignore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Inhaltsverzeichnis \n",
    "(Diese Art von Inhaltsverzeichnis mit Link funktioniert leider in Notebooks nicht, weil die as JSON gespeichert werden und nicht als HTML...)\n",
    "\n",
    "- [0. Datensatz laden](#0-datensatz-laden)\n",
    "- [1. Vollst√§ndige Schadstoffmessungen und geographische Verteilung](#1-vollst√§ndige-schadstoffmessungen-und-geographische-verteilung)\n",
    "- [2. Clusterberechnung - mehrstufig](#2-clusterberechnung-mehrstufig)\n",
    "- [3. Clusterbeschreibung mit PCA](#3-clusterbeschreibung-mit-pca)\n",
    "- [4. Geographische Verteilung der Schadstoffcluster](#4-geographische-verteilung-der-schadstoffcluster)\n",
    "- [5. Inhaltliche Interpretation](#5-inhaltliche-interpretation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Datensatz laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/cleaned_air_quality_data_2025-03-27.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dateframe vorbereiten\n",
    "\n",
    "Als Target benutzen wir mittelgro√üe Feinstaubpartikel (PM2.5), als Features alle anderen Schadstoffe im Datensatz: CO, NO‚ÇÇ, SO‚ÇÇ, O‚ÇÉ und (im allerersten Modell) PM10.\n",
    "\n",
    "Weil das Imputieren von Werten f√ºr nicht vorhandenen Kategorien (Schadstoffen) f√ºr eine Stadt nicht mehr als \"Raten\" ist, werden nur St√§dte in die Analyse mit aufgenommen, f√ºr die Messwerte zu allen sechs Luftschadstoffen vorliegen. (--> Wiebke: Was ich meine, ist: Ich kann innerhalb einer Stadt Werte imputieren, aber es ist ziemlicher Quatsch, die Werte von einer Stadt auf die andere zu √ºbertragen, also stadt√ºbergreifend zu imputieren.)\n",
    "\n",
    "Die Luftqualit√§t kann auch auf dem arithmetischen Mittel berechnet werden. Dies hat den Vorteil, dass die nat√ºrliche Varianz besser abgebildet wird und den Nachteil, dass Machine-Learning-Modelle sich bei der Klassifikation schlechter abschneiden. Beide Varianten wurden komplett durchgerechnet. Da hier das Verhalten unterschiedlicher Klassifikationsmodelle gezeigt werden soll, wurde f√ºr die finale Analyse der Median gew√§hlt.\n",
    "\n",
    "Um ein Klassifikationsmodell zur Vorhersage der Luftqualit√§t von St√§dten zu erstellen, wird eine Zielvariable mit dem Namen **AirQualityLabel** eingef√ºhrt. Diese ordnet jeder Stadt eine von zwei Klassen zu:\n",
    "\n",
    "- 0 ‚Üí Gute Luftqualit√§t\n",
    "\n",
    "- 1 ‚Üí Schlechte Luftqualit√§t\n",
    "\n",
    "Die Luftqualit√§t wird aus den Medianen der einzelnen Schadstoffe pro Stadt berechnet.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste relevanter Schadstoffe\n",
    "pollutants = ['Co', 'No2', 'O3', 'Pm10', 'Pm25', 'So2']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mittelwerte pro Stadt berechnen (Index = City)\n",
    "df_median = df.groupby('City')[pollutants].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# F√ºr jede Stadt: Wie viele Mittelwerte sind vorhanden?\n",
    "df_median['Num_Valid_Pollutants'] = df_median[pollutants].notna().sum(axis=1)\n",
    "\n",
    "# √úbersicht: Wie viele St√§dte haben wie viele g√ºltige Schadstoffwerte?\n",
    "coverage_summary = df_median['Num_Valid_Pollutants'].value_counts().sort_index()\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "coverage_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Nur St√§dte mit allen 6 Schadstoff-Mittelwerten\n",
    "\n",
    "df_median_complete = df_median[df_median['Num_Valid_Pollutants'] == 6]\n",
    "\n",
    "len(df_median_complete)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Der Dataframe enth√§lt nun noch 406 St√§dte, f√ºr die jeweils Wertte f√ºr jeden Schadstoff vorliegen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. WHO-Richtlinie\n",
    "\n",
    "Als erstes wird die Klasseneinteilung auf der Grundlage einen fachlichen Standards, n√§mlich des aktuellen WHO-Grenzwerts f√ºr PM2.5 von 5‚ÄØ¬µg/m¬≥ vorgenommen:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl St√§dte mit guter/schlechter Luft (nach WHO-Grenzwert)\n",
    "(df_median_complete['Pm25'] <= 5).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# St√§dte mit PM2.5 ‚â§ 5 ¬µg/m¬≥ filtern\n",
    "clean_cities = df_median_complete[df_median_complete['Pm25'] <= 5]\n",
    "\n",
    "# Ergebnis anzeigen\n",
    "clean_cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl g√ºltiger PM2.5-Werte pro Stadt\n",
    "pm25_counts = df.groupby('City')['Pm25'].count().sort_values()\n",
    "\n",
    "# Zeige nur die \"sauberen\" St√§dte\n",
    "pm25_counts.loc[['Plovdiv', 'Yazd']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dem WHO-Grenzwert entsprechen in unserem Datensatz nur zwei von 406 St√§dten: Plovdiv (Bulgarien), Yazd (Iran). Bei genauerem Hinschauen f√§llt allerdings auf, dass es f√ºr Plovidiv nur einen einzigen Messwert gibt und f√ºr Yazd nur sehr wenige. Die Messwerte sind damit nicht aussagekr√§ftig.\n",
    "\n",
    "Die WHO-Richtline kann also f√ºr das Training von Klassifikationsmodellen nicht als Schwellenwert verwendet werden - es h√§tte keine zweite Klasse, von der es lernen k√∂nnte.\n",
    "\n",
    "**OFFENE FRAGE**: Ist es gut, f√ºr die restliche Analyse alle St√§dte drinzulassen, auch wenn sie nur wenige Messwerte pro Schadstoff haben? Sollte man da noch was aussortieren? Oder einfach mal so lassen, weil in der Realit√§t die Datenqualit√§t auch nur selten optimal ist?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Median der Zielvariablen\n",
    "\n",
    "Als Alternative wird der Median als datengetriebener Grenzwert gew√§hlt. Die Einteilung in St√§dte mit guter und schlechter Luftqualit√§t basiert also auf dem Medianwert der durchschnittlichen PM2.5-Konzentration aller St√§dte im Datensatz. \n",
    "\n",
    "Durch die Verwendung des Medians entsteht eine ausgewogene Verteilung zwischen den beiden Klassen, die ein stabiles Training und eine faire Bewertung des Modells erm√∂glicht.\n",
    "\n",
    "Die Berechnung erfolgte folgenderma√üen:\n",
    "\n",
    "    pm25_median = df_median['Pm25'].median()\n",
    "    df_median['AirQualityLabel'] = (df_median['Pm25'] > pm25_median).astype(int)\n",
    "\n",
    " St√§dte mit einem PM2.5-Mittelwert √ºber dem Median werden als \"schlechte Luftqualit√§t\" (1) klassifiziert, alle anderen als \"gute Luftqualit√§t\" (0).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Median von PM2.5 berechnen\n",
    "pm25_median = df_median['Pm25'].median()\n",
    "\n",
    "# Zielvariable hinzuf√ºgen\n",
    "df_median['AirQualityLabel'] = (df_median['Pm25'] > pm25_median).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Umgang mit NaN-Werten\n",
    "\n",
    "# Anzahl fehlender Werte pro Spalte\n",
    "df[[\"City\"] + pollutants].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anzahl g√ºltiger Werte pro Stadt und Schadstoff\n",
    "df.groupby('City')[pollutants].count().sort_values(by='Pm25')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weil das Imputieren von √ºberhaupt nicht vorhandenen Kategorien (Schadstoffen) f√ºr eine Stadt eigentlich nicht mehr als \"Raten\" ist, machen wir das hier nicht und reduzieren die Trainingsdaten auf die 404 St√§dte, die f√ºr alle Schadstoffe Werte gemeldet haben."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_median_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_median_complete.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['Co', 'No2', 'O3', 'Pm10', 'So2']\n",
    "X = df_median_complete[features]\n",
    "y = df_median_complete['AirQualityLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wir haben  aktuell 404 St√§dte in df_median_complete. Davon nehmen wir 80% f√ºr das Training und 20% f√ºr den Test.\n",
    "# Wir verwenden den Standard-Trainings-Test-Split von scikit-learn.\n",
    "\n",
    "# Split in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell 1: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Modelltraining\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen & Bewertung\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn wir PM10 als Feature drinlassen, klassifiziert das Modell prima - und das ist auch zu erwarten, weil PM2.5 eine Teilmenge von PM10 ist. Also lassen wir PM10 jetzt mal raus und schauen, was dann passiert:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_no_PM10 = ['Co', 'No2', 'O3', 'So2']\n",
    "X = df_median_complete[features_no_PM10]\n",
    "y = df_median_complete['AirQualityLabel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Modelltraining\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen & Bewertung\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     index=[\"Tats√§chlich Negativ\", \"Tats√§chlich Positiv\"], \n",
    "                     columns=[\"Vorhergesagt Negativ\", \"Vorhergesagt Positiv\"])\n",
    "\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.ylabel(\"Tats√§chliche Werte\")\n",
    "plt.xlabel(\"Vorhergesagte Werte\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßæ Entscheidung zur Feature-Auswahl: PM10 aus den Features entfernen\n",
    "\n",
    "Um die Luftqualit√§t in St√§dten zu klassifizieren, wurden zun√§chst alle Schadstoffe (CO, NO‚ÇÇ, O‚ÇÉ, PM10, PM2.5, SO‚ÇÇ) als Features in das Modell aufgenommen, obwohl PM10 und PM2.5 naturgem√§√ü eine hohe Korrelation aufweisen (√ºber 97%).\n",
    "\n",
    "üîπ Test mit PM10 als Feature:\n",
    "\n",
    "Das Modell erzielte eine hohe Genauigkeit von 91% und einen sehr hohen F1-Score von 0.92 f√ºr die Vorhersage von schlechter Luft (Klasse 1).\n",
    "\n",
    "Pr√§zision und Recall bei der Klassifikation von ‚Äûschlechter Luft‚Äú waren sehr hoch (nahe 1.0), was das Modell besonders pr√§zise bei der Vorhersage von schlechter Luft machte.\n",
    "\n",
    "Allerdings zeigte sich auch, dass das Modell zwischen den Klassen kaum differenzierte, was die klassenspezifische Leistung bei guter Luft (Klasse 0) beeintr√§chtigte.\n",
    "\n",
    "üîπ Test ohne PM10 als Feature:\n",
    "\n",
    "Nachdem PM10 entfernt wurde, ging die Genauigkeit leicht zur√ºck auf 80% und der F1-Score f√ºr schlechte Luft sank von 0.92 auf 0.83.\n",
    "\n",
    "Das Modell zeigt nun jedoch eine ausgewogenere Klassifikation (bevorzogt nicht mehr das Label \"schlechte Luft\") und ist weniger von redundanten Informationen beeinflusst.\n",
    "\n",
    "üß† Ergebnis:\n",
    "\n",
    "Die Tests haben gezeigt, dass das Modell besser differenziert, wenn PM10 aus den Features entfernt wird. Auch wenn die Gesamtgenauigkeit etwas zur√ºckgeht, ist das Modell nun besser in der Lage, zwischen guter und schlechter Luft zu unterscheiden.\n",
    "Die Entscheidung, PM10 aus den Features zu entfernen, basiert auf der starken Korrelation mit PM2.5, die zu einer Redundanz f√ºhrte und das Modell verzerrte.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell 2: Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and train test split repeated from previous model, just to make clear what is being used:\n",
    "\n",
    "features_no_PM10 = ['Co', 'No2', 'O3', 'So2']\n",
    "X = df_median_complete[features_no_PM10]\n",
    "y = df_median_complete['AirQualityLabel']\n",
    "\n",
    "# Split in Trainings- und Testdaten\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest-Modell erstellen\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Modell trainieren\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vorhersagen & Bewertung drucken\n",
    "print(classification_report(y_test, y_pred_rf))\n",
    "# print(confusion_matrix(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_rf)\n",
    "\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     index=[\"Tats√§chlich Negativ\", \"Tats√§chlich Positiv\"], \n",
    "                     columns=[\"Vorhergesagt Negativ\", \"Vorhergesagt Positiv\"])\n",
    "\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.ylabel(\"Tats√§chliche Werte\")\n",
    "plt.xlabel(\"Vorhergesagte Werte\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance extrahieren\n",
    "importances = rf_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature-Importanz in ein DataFrame umwandeln\n",
    "feature_importance_df = pd.DataFrame({\n",
    "    'Feature': features_no_PM10,\n",
    "    'Importance': importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Feature-Importanz anzeigen\n",
    "plt.figure(figsize=(8, 4))\n",
    "sns.barplot(x='Importance', y='Feature', data=feature_importance_df, palette='viridis')\n",
    "plt.title('Feature Importance (Random Forest)')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Am wichtigsten f√ºr die Klassifizierung ist das Feature \"CO\". Kann es sein, dass die falsch klassifizierten St√§dte auff√§llige CO-Werte haben?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Falsch klassifizierte St√§dte finden\n",
    "incorrect_predictions = X_test.copy()\n",
    "incorrect_predictions['True Label'] = y_test\n",
    "incorrect_predictions['Predicted Label'] = y_pred_rf\n",
    "\n",
    "# Nur falsch klassifizierte St√§dte herausfiltern\n",
    "incorrect_predictions = incorrect_predictions[incorrect_predictions['True Label'] != incorrect_predictions['Predicted Label']]\n",
    "\n",
    "# CO-Werte der falsch klassifizierten St√§dte\n",
    "incorrect_predictions['CO'] = X_test.loc[incorrect_predictions.index, 'Co']\n",
    "\n",
    "# Ausgabe der St√§dte mit ihren CO-Werten\n",
    "incorrect_predictions[['True Label', 'Predicted Label', 'CO']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CO-Werte der falsch klassifizierten St√§dte\n",
    "co_values = incorrect_predictions['CO']\n",
    "\n",
    "# Berechne die wichtigsten Statistiken (Durchschnitt, IQR)\n",
    "co_mean = co_values.mean()\n",
    "co_std = co_values.std()\n",
    "co_min = co_values.min()\n",
    "co_max = co_values.max()\n",
    "\n",
    "# Berechne Interquartilsabstand (IQR)\n",
    "Q1 = co_values.quantile(0.25)\n",
    "Q3 = co_values.quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Anzeigen der CO-Statistiken\n",
    "print(f\"Durchschnittlicher CO-Wert: {co_mean:.2f}\")\n",
    "print(f\"Standardabweichung: {co_std:.2f}\")\n",
    "print(f\"Minimaler CO-Wert: {co_min:.2f}\")\n",
    "print(f\"Maximaler CO-Wert: {co_max:.2f}\")\n",
    "print(f\"Interquartilsabstand (IQR): {IQR:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hier muss man noch nachdenken, wie man das Modell verbessern kann. Man sollte die falsch zugeordneten St√§dte √ºberpr√ºfen, ob da mit den Daten was nicht stimmt. Und dann noch die Hyperparameter besser einstellen und so. Nicht mehr heute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell 3: Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gradient Boosting Modell erstellen\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Modell trainieren\n",
    "gb_model.fit(X_train, y_train)\n",
    "\n",
    "# Vorhersagen & Bewertung\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred_gb))\n",
    "# print(confusion_matrix(y_test, y_pred_gb))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred_gb)\n",
    "\n",
    "cm_df = pd.DataFrame(cm, \n",
    "                     index=[\"Tats√§chlich Negativ\", \"Tats√§chlich Positiv\"], \n",
    "                     columns=[\"Vorhergesagt Negativ\", \"Vorhergesagt Positiv\"])\n",
    "\n",
    "print(cm_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.ylabel(\"Tats√§chliche Werte\")\n",
    "plt.xlabel(\"Vorhergesagte Werte\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
