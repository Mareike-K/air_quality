{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import():\n",
    "    \"\"\"\n",
    "    Import der Daten aus allen Dateien, die mit 'waqi-covid-' anfangen.\n",
    "    Entfernen von Kommentaren, Duplikaten und Umbenennung bestimmter Spaltenwerte.\n",
    "    Zusammenf√ºhrung der DataFrames.\n",
    "    \"\"\"\n",
    "    data_folder = './data/'\n",
    "    all_files = [f for f in os.listdir(data_folder) if f.startswith('waqi-covid-') and f.endswith('.csv') or f == 'airquality-covid19-cities.json']\n",
    "    dataframes = []\n",
    "\n",
    "    if not all_files:\n",
    "        print(\"Keine Dateien gefunden.\")\n",
    "        return None\n",
    "\n",
    "    for file in all_files:\n",
    "        file_path = os.path.join(data_folder, file)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, comment='#')\n",
    "\n",
    "            if \"Specie\" not in df.columns:\n",
    "                print(f\"Spalte 'Specie' fehlt in {file}\")\n",
    "                continue\n",
    "\n",
    "            df[\"Specie\"] = df[\"Specie\"].replace(\"wind gust\", \"wind-gust\")\n",
    "            df[\"Specie\"] = df[\"Specie\"].replace(\"wind speed\", \"wind-speed\")\n",
    "            df = df.drop_duplicates()\n",
    "\n",
    "            if df.empty:\n",
    "                print(f\"{file} enth√§lt nach Duplikat-Entfernung keine Daten mehr.\")\n",
    "                continue\n",
    "\n",
    "            dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Verarbeiten von {file}: {e}\")\n",
    "\n",
    "    if not dataframes:\n",
    "        print(\"Keine g√ºltigen Daten vorhanden.\")\n",
    "        return None\n",
    "\n",
    "    return pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spalte 'Specie' fehlt in airquality-covid19-cities.json\n",
      "waqi-covid-2022Q1.csv enth√§lt nach Duplikat-Entfernung keine Daten mehr.\n",
      "                Date Country    City Specie  count   min    max  median  \\\n",
      "0         2015-01-06      KR  Jeonju     co    124   0.1   12.3     4.5   \n",
      "1         2015-01-22      KR  Jeonju     co    116   4.5   10.0     6.7   \n",
      "2         2015-03-30      KR  Jeonju     co    118   1.2   11.2     5.6   \n",
      "3         2015-05-27      KR  Jeonju     co     93   2.3    5.6     3.4   \n",
      "4         2015-02-03      KR  Jeonju     co    133   4.5   13.4     7.8   \n",
      "...              ...     ...     ...    ...    ...   ...    ...     ...   \n",
      "14251935  2024-08-12      IR  Tehran    so2    154   6.0  101.0    12.0   \n",
      "14251936  2025-01-13      IR  Tehran    so2    516  10.0   74.0    19.0   \n",
      "14251937  2024-02-10      IR  Tehran    so2    299   5.0   76.0    34.0   \n",
      "14251938  2024-05-16      IR  Tehran    so2    559   6.0   92.0    17.0   \n",
      "14251939  2025-01-04      IR  Tehran    so2    160  18.0  157.0    68.0   \n",
      "\n",
      "          variance  \n",
      "0            55.74  \n",
      "1            16.09  \n",
      "2            35.98  \n",
      "3             6.54  \n",
      "4            39.24  \n",
      "...            ...  \n",
      "14251935   4176.17  \n",
      "14251936   1741.16  \n",
      "14251937   2347.67  \n",
      "14251938   2447.24  \n",
      "14251939  15077.50  \n",
      "\n",
      "[14251940 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "df=data_import()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geodata(df):\n",
    "    \"\"\"\n",
    "    F√ºgt die Geodaten zu den St√§dten hinzu\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # JSON-Datei laden\n",
    "    with open('./data/airquality-covid19-cities.json', 'r', encoding='utf-8') as file:\n",
    "        geodata = json.load(file)\n",
    "    \n",
    "    geodata = geodata[\"data\"] \n",
    "\n",
    "    # Erstellen eines DataFrames mit St√§dten und Geokoordinaten\n",
    "    df_places = pd.DataFrame([\n",
    "        {\n",
    "            \"City\": entry[\"Place\"][\"name\"],  # Stadtname\n",
    "            \"Latitude\": entry[\"Place\"][\"geo\"][0],  \n",
    "            \"Longitude\": entry[\"Place\"][\"geo\"][1]\n",
    "        }\n",
    "        for entry in geodata if \"Place\" in entry])  # Nur Eintr√§ge mit \"Place\" verwenden\n",
    "    \n",
    "\n",
    "    # Standardisiere den Stadtnamen f√ºr eine bessere √úbereinstimmung\n",
    "    df[\"City\"] = df[\"City\"].str.lower().str.strip()\n",
    "    df_places[\"City\"] = df_places[\"City\"].str.lower().str.strip()\n",
    "\n",
    "    # Zusammenf√ºhren der beiden DataFrames √ºber \"City\"\n",
    "    df = df.merge(df_places, on=\"City\", how=\"left\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    \"\"\"Bereinigung der Daten\n",
    "    - nicht ben√∂tigte Spalten l√∂schen\n",
    "    - Zusammenfassung der Daten nach Datum, Land, Stadt und Spezies, so dass nur ein Messwert je Species (Median) pro Tag/ Stadt verbleibt\n",
    "    - Spalte Species aufteilen\n",
    "    - df als csv speichern im Datenverzeichnis\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df.drop(columns=['variance', 'min', 'max'], errors='ignore')\n",
    "\n",
    "    df = df.groupby([\"Date\", \"Country\", \"City\", \"Specie\"], as_index=False).agg({\"median\": \"mean\"})  \n",
    "\n",
    "    df = df.pivot(index=[\"Date\", \"Country\", \"City\"], columns=\"Specie\", values='median').reset_index()\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    output_path = './data/cleaned_data.csv'\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"‚úÖ Datei wurde gespeichert: {output_path}\")\n",
    "\n",
    "    #evt hier nochmal umarbeiten\n",
    "    #geo_data = add_geodata(df)\n",
    "    #und dann nochmal mergen au√üerhakb von geodata\n",
    "    #df = pd.merge(df, geo_data, on=[\"City\"], how=\"left\")\n",
    "    df = geodata(df)\n",
    "\n",
    "    # weather_data = add_weather(df)\n",
    "\n",
    "    # Zusammenf√ºhren der beiden DataFrames √ºber \"City und Date\"\n",
    "    # df = pd.merge(df, weather_data, on=[\"City\", 'Date'],how=\"left\")\n",
    "\n",
    "    df= convert_date(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(df):\n",
    "    \"\"\"\n",
    "    Teilt die Spalte Date in Year, Month, Day auf\n",
    "    \"\"\"\n",
    "    # Convert 'Date' column to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # Split 'Date' column into 'year', 'month' and 'day'\n",
    "    df['year'] = df['Date'].dt.year\n",
    "    df['month'] = df['Date'].dt.month\n",
    "    df['day'] = df['Date'].dt.day\n",
    "\n",
    "    # Remove 'Date' column\n",
    "    if 'Date' in df.columns:\n",
    "        df.drop(columns=['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>2015-01-22</td>\n",
       "      <td>2015-03-30</td>\n",
       "      <td>2015-05-27</td>\n",
       "      <td>2015-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <td>KR</td>\n",
       "      <td>KR</td>\n",
       "      <td>KR</td>\n",
       "      <td>KR</td>\n",
       "      <td>KR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <td>Jeonju</td>\n",
       "      <td>Jeonju</td>\n",
       "      <td>Jeonju</td>\n",
       "      <td>Jeonju</td>\n",
       "      <td>Jeonju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specie</th>\n",
       "      <td>co</td>\n",
       "      <td>co</td>\n",
       "      <td>co</td>\n",
       "      <td>co</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>124</td>\n",
       "      <td>116</td>\n",
       "      <td>118</td>\n",
       "      <td>93</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>4.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variance</th>\n",
       "      <td>55.74</td>\n",
       "      <td>16.09</td>\n",
       "      <td>35.98</td>\n",
       "      <td>6.54</td>\n",
       "      <td>39.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0           1           2           3           4\n",
       "Date      2015-01-06  2015-01-22  2015-03-30  2015-05-27  2015-02-03\n",
       "Country           KR          KR          KR          KR          KR\n",
       "City          Jeonju      Jeonju      Jeonju      Jeonju      Jeonju\n",
       "Specie            co          co          co          co          co\n",
       "count            124         116         118          93         133\n",
       "min              0.1         4.5         1.2         2.3         4.5\n",
       "max             12.3        10.0        11.2         5.6        13.4\n",
       "median           4.5         6.7         5.6         3.4         7.8\n",
       "variance       55.74       16.09       35.98        6.54       39.24"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_cleaning(df):\n",
    "#     \"\"\"Bereinigung der Daten\n",
    "#     - nicht ben√∂tigte Spalten l√∂schen\n",
    "#     - Eine Stadt pro Land mit den meisten Messwerten \n",
    "#     - und die Liste als csv ins Datenverzeichnis speichern\n",
    "#     - Zusammenfassung der Daten nach Datum, Land, Stadt und Spezies, so dass nur ein Messwert je Species (Median) pro Tag/ Stadt verbleibt\n",
    "#     - filtern des df nach den ausgew√§hlten St√§dten\n",
    "#     - Spalte Species aufteilen\n",
    "#     - df als csv speichern im Datenverzeichnis\n",
    "#     \"\"\"\n",
    "#     df = df.copy()\n",
    "\n",
    "#     df = df.drop(columns=['variance', 'min', 'max'], errors='ignore')\n",
    "\n",
    "#     # city_counts = df.groupby([\"Country\", \"City\"]).size().reset_index(name=\"count\")\n",
    "#     # cities = city_counts.loc[city_counts.groupby(\"Country\")[\"count\"].idxmax()]\n",
    "  \n",
    "#     # output_path = './data/city_per_country.csv'\n",
    "#     # os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "#     # cities.to_csv(output_path, index=False)\n",
    "#     # print(f\"‚úÖ Datei wurde gespeichert: {output_path}\")\n",
    "    \n",
    "#     # cities=cities['City'].tolist()\n",
    "#     # df = df[df['City'].isin(cities)]\n",
    "\n",
    "#     df = df.groupby([\"Date\", \"Country\", \"City\", \"Specie\"], as_index=False).agg({\"median\": \"mean\"})  \n",
    "\n",
    "#     df = df.pivot(index=[\"Date\", \"Country\", \"City\"], columns=\"Specie\", values='median').reset_index()\n",
    "\n",
    "#     output_path = './data/cleaned_data.csv'\n",
    "#     os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "#     df.to_csv(output_path, index=False)\n",
    "#     print(f\"‚úÖ Datei wurde gespeichert: {output_path}\")\n",
    "\n",
    "#     return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_, weather_data = data_cleaning(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.head().T\n",
    "weather_data.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_, weather_data, on=[\"City\", 'Date'],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=data_cleaning(df)\n",
    "# print(df.shape)\n",
    "# df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cities = df[['City', 'Latitude', 'Longitude']]\n",
    "# print(cities.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from meteostat import Stations\n",
    "\n",
    "# # Test mit einer Stadt\n",
    "# city = {'City': 'Berlin', 'Latitude': 52.5200, 'Longitude': 13.4050}\n",
    "\n",
    "# # N√§chste Wetterstation suchen\n",
    "# stations = Stations().nearby(city['Latitude'], city['Longitude'])\n",
    "# station = stations.fetch(5)  # Hol dir mal die n√§chsten 5 Stationen zum Vergleich\n",
    "\n",
    "# print(station)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from meteostat import Daily\n",
    "# from datetime import datetime\n",
    "\n",
    "# # Test mit der ersten Station\n",
    "# start = datetime(2023, 1, 1)\n",
    "# end = datetime(2023, 1, 31)\n",
    "\n",
    "# if not station.empty:\n",
    "#     station_id = station.index[0]\n",
    "#     print(f\"üì° Verwende Station: {station_id}\")\n",
    "\n",
    "#     # T√§gliche Wetterdaten abrufen\n",
    "#     data = Daily(station_id, start, end)\n",
    "#     data = data.fetch()\n",
    "\n",
    "#     print(data.head())\n",
    "# else:\n",
    "#     print(\"‚ö†Ô∏è Keine Wetterstation gefunden!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WEtterdaten integrieren\n",
    "\n",
    "from meteostat import Daily, Stations\n",
    "from datetime import datetime\n",
    "\n",
    "# St√§dte\n",
    "cities = df[['City', 'Latitude', 'Longitude']].drop_duplicates()\n",
    "\n",
    "# Zeitspanne festlegen\n",
    "start = datetime(2015, 1, 1)\n",
    "end = datetime(2024, 12, 31)\n",
    "\n",
    "# DataFrame f√ºr alle St√§dte vorbereiten\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Daten f√ºr jede Stadt abrufen und hinzuf√ºgen\n",
    "for _, city in cities.iterrows():\n",
    "    # N√§chste Wetterstation suchen\n",
    "    stations = Stations().nearby(city['Latitude'], city['Longitude'])\n",
    "    station = stations.fetch(1)\n",
    "\n",
    "    if not station.empty:\n",
    "        station_id = station.index[0]\n",
    "\n",
    "        # T√§gliche Wetterdaten abrufen\n",
    "        data = Daily(station_id, start, end).fetch()\n",
    "\n",
    "        # Nan-Daten rausfiltern\n",
    "        data.dropna(how='all', inplace=True)\n",
    "\n",
    "        if not data.empty:\n",
    "            # Stadtname hinzuf√ºgen\n",
    "            data[\"City\"] = city[\"City\"]\n",
    "\n",
    "            # Daten in den Gesamtdaten-Frame einf√ºgen\n",
    "            all_data = pd.concat([all_data, data])\n",
    "\n",
    "    # if station.empty:\n",
    "    #     print(f\"‚ö†Ô∏è Keine Wetterstation f√ºr {city['City']} gefunden, √ºbersprungen.\")\n",
    "    #     continue\n",
    "\n",
    "    # # T√§gliche Wetterdaten abrufen\n",
    "    # data = Daily(station.index[0], start, end)\n",
    "    # data = data.fetch()\n",
    "\n",
    "    # if data.empty:\n",
    "    #     print(f\"‚ö†Ô∏è Keine Wetterdaten f√ºr {city['City']} gefunden, √ºbersprungen.\")\n",
    "    #     continue\n",
    "\n",
    "    # # Stadtname hinzuf√ºgen\n",
    "    # data[\"City\"] = city[\"City\"]\n",
    "\n",
    "    # # Daten in den Gesamtdaten-Frame einf√ºgen\n",
    "    # all_data = pd.concat([all_data, data])\n",
    "\n",
    "# Index zur√ºcksetzen\n",
    "all_data.reset_index(inplace=True)\n",
    "\n",
    "# Spalte time umbennen in Date\n",
    "all_data.rename(columns={'time': 'Date'}, inplace=True) \n",
    "\n",
    "# Standardisiere den Stadtnamen f√ºr eine bessere √úbereinstimmung\n",
    "all_data[\"City\"] = all_data[\"City\"].str.lower().str.strip()\n",
    "\n",
    "print(f\"‚úÖ Wetterdaten gesammelt f√ºr {all_data['City'].nunique()} St√§dte\")\n",
    "\n",
    "# # Ergebnis anzeigen\n",
    "print(all_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meteostat import Daily, Stations\n",
    "from datetime import datetime\n",
    "\n",
    "def add_weather(df):\n",
    "    \"\"\"F√ºgt die Wetterdaten zu den St√§dten hinzu\n",
    "    \"\"\"\n",
    "    # St√§dte\n",
    "    cities = df[['City', 'Latitude', 'Longitude']].drop_duplicates()\n",
    "\n",
    "    # Zeitspanne festlegen\n",
    "    start = datetime(2015, 1, 1)\n",
    "    end = datetime(2024, 12, 31)\n",
    "\n",
    "    # DataFrame f√ºr alle St√§dte vorbereiten\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    # Daten f√ºr jede Stadt abrufen und hinzuf√ºgen\n",
    "    for _, city in cities.iterrows():\n",
    "        # N√§chste Wetterstation suchen\n",
    "        stations = Stations().nearby(city['Latitude'], city['Longitude'])\n",
    "        station = stations.fetch(1)\n",
    "\n",
    "        if not station.empty:\n",
    "            station_id = station.index[0]\n",
    "\n",
    "            # T√§gliche Wetterdaten abrufen\n",
    "            data = Daily(station_id, start, end).fetch()\n",
    "\n",
    "            # Nan-Daten rausfiltern\n",
    "            data.dropna(how='all', inplace=True)\n",
    "\n",
    "            if not data.empty:\n",
    "                # Stadtname hinzuf√ºgen\n",
    "                data[\"City\"] = city[\"City\"]\n",
    "\n",
    "                # Daten in den Gesamtdaten-Frame einf√ºgen\n",
    "                all_data = pd.concat([all_data, data])\n",
    "\n",
    "    # Index zur√ºcksetzen\n",
    "    all_data.reset_index(inplace=True)\n",
    "\n",
    "    # Spalte time umbennen in Date\n",
    "    all_data.rename(columns={'time': 'Date'}, inplace=True) \n",
    "\n",
    "    # Standardisiere den Stadtnamen f√ºr eine bessere √úbereinstimmung\n",
    "    all_data[\"City\"] = all_data[\"City\"].str.lower().str.strip()\n",
    "\n",
    "    # Datum formatieren f√ºr bessere √úbereinstimmung\n",
    "    all_data['Date'] = pd.to_datetime(all_data['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Berechne den Anteil der NaN-Werte pro Spalte\n",
    "    missing_percentage = all_data.isna().mean() * 100\n",
    "    # L√∂sche die Spalten, bei denen der Anteil an NaN-Werten gr√∂√üer als 80% ist\n",
    "    all_data = all_data.loc[:, missing_percentage <= 80]\n",
    "    \n",
    "    print(f\"‚úÖ Wetterdaten gesammelt f√ºr {all_data['City'].nunique()} St√§dte\")    \n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = add_weather(df)\n",
    "print(weather.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammenf√ºhren der beiden DataFrames √ºber \"City und Date\"\n",
    "df = pd.merge(df, all_data, on=[\"City\", 'Date'],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_weather(df)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Date' column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Split 'Date' column into 'year', 'month' and 'day'\n",
    "df['year'] = df['Date'].dt.year\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['day'] = df['Date'].dt.day\n",
    "\n",
    "# Remove 'Date' column\n",
    "if 'Date' in df.columns:\n",
    "    df.drop(columns=['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print(df[['City', 'Date']].head())\n",
    "# print(all_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df['Date'].dtype)\n",
    "# print(all_data['Date'].dtype)\n",
    "# print(df['City'].dtype)\n",
    "# print(all_data['City'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df['City'].unique())\n",
    "# print(all_data['City'].unique())\n",
    "\n",
    "# print(set(df['Date']).difference(set(all_data['Date'])))\n",
    "# print(set(df['City']).difference(set(all_data['City'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(type(df))\n",
    "# print(type(all_data))\n",
    "\n",
    "# print(df.shape)\n",
    "# print(all_data.shape)\n",
    "\n",
    "\n",
    "# Konvertiere die 'Date' Spalte in beiden DataFrames zu datetime\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
    "all_data['Date'] = pd.to_datetime(all_data['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "#print(len(set(df['Date']).difference(set(all_data['Date']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_data.sample(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Funktion f√ºr √úbersicht √ºber dtypes, missing values, unique values etc.\n",
    "# def overview(df):\n",
    "#     '''\n",
    "#     Erstelle einen √úberblick √ºber einige Eigenschaften der Spalten eines DataFrames.\n",
    "#     VARs\n",
    "#         df: Der zu betrachtende DataFrame\n",
    "#     RETURNS:\n",
    "#         None\n",
    "#     '''\n",
    "#     display(pd.DataFrame({'dtype': df.dtypes,\n",
    "#                           'total': df.count(),\n",
    "#                           'missing': df.isna().sum(),\n",
    "#                           'missing%': df.isna().mean()*100,\n",
    "#                           'n_uniques': df.nunique(),\n",
    "#                           'uniques%': df.nunique()/df.shape[0]*100,\n",
    "#                           'uniques': [df[col].unique() for col in df.columns]\n",
    "#                          }))\n",
    "# overview(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne den Anteil der NaN-Werte pro Spalte\n",
    "missing_percentage = all_data.isna().mean() * 100\n",
    "\n",
    "# L√∂sche die Spalten, bei denen der Anteil an NaN-Werten gr√∂√üer als 80% ist\n",
    "all_data = all_data.loc[:, missing_percentage <= 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Zusammenf√ºhren der beiden DataFrames √ºber \"City\"\n",
    "df = pd.merge(df, all_data, on=[\"City\", 'Date'],how=\"left\")\n",
    "print(df.shape)\n",
    "df.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.sample(5).T)\n",
    "#df.isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
