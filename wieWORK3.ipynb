{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import requests\n",
    "import json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_import():\n",
    "    \"\"\"\n",
    "    Import der Daten aus allen Dateien, die mit 'waqi-covid-' anfangen.\n",
    "    Entfernen von Kommentaren, Duplikaten und Umbenennung bestimmter Spaltenwerte.\n",
    "    Zusammenführung der DataFrames.\n",
    "    \"\"\"\n",
    "    data_folder = './data/'\n",
    "    all_files = [f for f in os.listdir(data_folder) if f.startswith('waqi-covid-') and f.endswith('.csv') or f == 'airquality-covid19-cities.json']\n",
    "    dataframes = []\n",
    "\n",
    "    if not all_files:\n",
    "        print(\"Keine Dateien gefunden.\")\n",
    "        return None\n",
    "\n",
    "    for file in all_files:\n",
    "        file_path = os.path.join(data_folder, file)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, comment='#')\n",
    "\n",
    "            if \"Specie\" not in df.columns:\n",
    "                print(f\"Spalte 'Specie' fehlt in {file}\")\n",
    "                continue\n",
    "\n",
    "            df[\"Specie\"] = df[\"Specie\"].replace(\"wind gust\", \"wind-gust\")\n",
    "            df[\"Specie\"] = df[\"Specie\"].replace(\"wind speed\", \"wind-speed\")\n",
    "            df = df.drop_duplicates()\n",
    "\n",
    "            if df.empty:\n",
    "                print(f\"{file} enthält nach Duplikat-Entfernung keine Daten mehr.\")\n",
    "                continue\n",
    "\n",
    "            dataframes.append(df)\n",
    "        except Exception as e:\n",
    "            print(f\"Fehler beim Verarbeiten von {file}: {e}\")\n",
    "\n",
    "    if not dataframes:\n",
    "        print(\"Keine gültigen Daten vorhanden.\")\n",
    "        return None\n",
    "\n",
    "    return pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spalte 'Specie' fehlt in airquality-covid19-cities.json\n",
      "waqi-covid-2022Q1.csv enthält nach Duplikat-Entfernung keine Daten mehr.\n",
      "                Date Country    City Specie  count   min    max  median  \\\n",
      "0         2015-01-06      KR  Jeonju     co    124   0.1   12.3     4.5   \n",
      "1         2015-01-22      KR  Jeonju     co    116   4.5   10.0     6.7   \n",
      "2         2015-03-30      KR  Jeonju     co    118   1.2   11.2     5.6   \n",
      "3         2015-05-27      KR  Jeonju     co     93   2.3    5.6     3.4   \n",
      "4         2015-02-03      KR  Jeonju     co    133   4.5   13.4     7.8   \n",
      "...              ...     ...     ...    ...    ...   ...    ...     ...   \n",
      "14251935  2024-08-12      IR  Tehran    so2    154   6.0  101.0    12.0   \n",
      "14251936  2025-01-13      IR  Tehran    so2    516  10.0   74.0    19.0   \n",
      "14251937  2024-02-10      IR  Tehran    so2    299   5.0   76.0    34.0   \n",
      "14251938  2024-05-16      IR  Tehran    so2    559   6.0   92.0    17.0   \n",
      "14251939  2025-01-04      IR  Tehran    so2    160  18.0  157.0    68.0   \n",
      "\n",
      "          variance  \n",
      "0            55.74  \n",
      "1            16.09  \n",
      "2            35.98  \n",
      "3             6.54  \n",
      "4            39.24  \n",
      "...            ...  \n",
      "14251935   4176.17  \n",
      "14251936   1741.16  \n",
      "14251937   2347.67  \n",
      "14251938   2447.24  \n",
      "14251939  15077.50  \n",
      "\n",
      "[14251940 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "df=data_import()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def geodata(df):\n",
    "    \"\"\"\n",
    "    Fügt die Geodaten zu den Städten hinzu\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    # JSON-Datei laden\n",
    "    with open('./data/airquality-covid19-cities.json', 'r', encoding='utf-8') as file:\n",
    "        geodata = json.load(file)\n",
    "    \n",
    "    geodata = geodata[\"data\"] \n",
    "\n",
    "    # Erstellen eines DataFrames mit Städten und Geokoordinaten\n",
    "    df_places = pd.DataFrame([\n",
    "        {\n",
    "            \"City\": entry[\"Place\"][\"name\"],  # Stadtname\n",
    "            \"Latitude\": entry[\"Place\"][\"geo\"][0],  \n",
    "            \"Longitude\": entry[\"Place\"][\"geo\"][1]\n",
    "        }\n",
    "        for entry in geodata if \"Place\" in entry])  # Nur Einträge mit \"Place\" verwenden\n",
    "    \n",
    "\n",
    "    # Standardisiere den Stadtnamen für eine bessere Übereinstimmung\n",
    "    df[\"City\"] = df[\"City\"].str.lower().str.strip()\n",
    "    df_places[\"City\"] = df_places[\"City\"].str.lower().str.strip()\n",
    "\n",
    "    # Zusammenführen der beiden DataFrames über \"City\"\n",
    "    df = df.merge(df_places, on=\"City\", how=\"left\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_cleaning(df):\n",
    "    \"\"\"Bereinigung der Daten\n",
    "    - nicht benötigte Spalten löschen\n",
    "    - Zusammenfassung der Daten nach Datum, Land, Stadt und Spezies, so dass nur ein Messwert je Species (Median) pro Tag/ Stadt verbleibt\n",
    "    - Spalte Species aufteilen\n",
    "    - df als csv speichern im Datenverzeichnis\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "\n",
    "    df = df.drop(columns=['variance', 'min', 'max'], errors='ignore')\n",
    "\n",
    "    df = df.groupby([\"Date\", \"Country\", \"City\", \"Specie\"], as_index=False).agg({\"median\": \"mean\"})  \n",
    "\n",
    "    df = df.pivot(index=[\"Date\", \"Country\", \"City\"], columns=\"Specie\", values='median').reset_index()\n",
    "\n",
    "    df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    output_path = './data/cleaned_data.csv'\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"✅ Datei wurde gespeichert: {output_path}\")\n",
    "\n",
    "    #evt hier nochmal umarbeiten\n",
    "    #geo_data = add_geodata(df)\n",
    "    #und dann nochmal mergen außerhakb von geodata\n",
    "    #df = pd.merge(df, geo_data, on=[\"City\"], how=\"left\")\n",
    "    df = geodata(df)\n",
    "\n",
    "    # weather_data = add_weather(df)\n",
    "\n",
    "    # Zusammenführen der beiden DataFrames über \"City und Date\"\n",
    "    # df = pd.merge(df, weather_data, on=[\"City\", 'Date'],how=\"left\")\n",
    "\n",
    "    df= convert_date(df)\n",
    "\n",
    "    return df\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_date(df):\n",
    "    \"\"\"\n",
    "    Teilt die Spalte Date in Year, Month, Day auf\n",
    "    \"\"\"\n",
    "    # Convert 'Date' column to datetime\n",
    "    df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "    # Split 'Date' column into 'year', 'month' and 'day'\n",
    "    df['year'] = df['Date'].dt.year\n",
    "    df['month'] = df['Date'].dt.month\n",
    "    df['day'] = df['Date'].dt.day\n",
    "\n",
    "    # Remove 'Date' column\n",
    "    if 'Date' in df.columns:\n",
    "        df.drop(columns=['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <td>2015-01-06</td>\n",
       "      <td>2015-01-22</td>\n",
       "      <td>2015-03-30</td>\n",
       "      <td>2015-05-27</td>\n",
       "      <td>2015-02-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Country</th>\n",
       "      <td>KR</td>\n",
       "      <td>KR</td>\n",
       "      <td>KR</td>\n",
       "      <td>KR</td>\n",
       "      <td>KR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>City</th>\n",
       "      <td>Jeonju</td>\n",
       "      <td>Jeonju</td>\n",
       "      <td>Jeonju</td>\n",
       "      <td>Jeonju</td>\n",
       "      <td>Jeonju</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Specie</th>\n",
       "      <td>co</td>\n",
       "      <td>co</td>\n",
       "      <td>co</td>\n",
       "      <td>co</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>124</td>\n",
       "      <td>116</td>\n",
       "      <td>118</td>\n",
       "      <td>93</td>\n",
       "      <td>133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12.3</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>5.6</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>median</th>\n",
       "      <td>4.5</td>\n",
       "      <td>6.7</td>\n",
       "      <td>5.6</td>\n",
       "      <td>3.4</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>variance</th>\n",
       "      <td>55.74</td>\n",
       "      <td>16.09</td>\n",
       "      <td>35.98</td>\n",
       "      <td>6.54</td>\n",
       "      <td>39.24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   0           1           2           3           4\n",
       "Date      2015-01-06  2015-01-22  2015-03-30  2015-05-27  2015-02-03\n",
       "Country           KR          KR          KR          KR          KR\n",
       "City          Jeonju      Jeonju      Jeonju      Jeonju      Jeonju\n",
       "Specie            co          co          co          co          co\n",
       "count            124         116         118          93         133\n",
       "min              0.1         4.5         1.2         2.3         4.5\n",
       "max             12.3        10.0        11.2         5.6        13.4\n",
       "median           4.5         6.7         5.6         3.4         7.8\n",
       "variance       55.74       16.09       35.98        6.54       39.24"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def data_cleaning(df):\n",
    "#     \"\"\"Bereinigung der Daten\n",
    "#     - nicht benötigte Spalten löschen\n",
    "#     - Eine Stadt pro Land mit den meisten Messwerten \n",
    "#     - und die Liste als csv ins Datenverzeichnis speichern\n",
    "#     - Zusammenfassung der Daten nach Datum, Land, Stadt und Spezies, so dass nur ein Messwert je Species (Median) pro Tag/ Stadt verbleibt\n",
    "#     - filtern des df nach den ausgewählten Städten\n",
    "#     - Spalte Species aufteilen\n",
    "#     - df als csv speichern im Datenverzeichnis\n",
    "#     \"\"\"\n",
    "#     df = df.copy()\n",
    "\n",
    "#     df = df.drop(columns=['variance', 'min', 'max'], errors='ignore')\n",
    "\n",
    "#     # city_counts = df.groupby([\"Country\", \"City\"]).size().reset_index(name=\"count\")\n",
    "#     # cities = city_counts.loc[city_counts.groupby(\"Country\")[\"count\"].idxmax()]\n",
    "  \n",
    "#     # output_path = './data/city_per_country.csv'\n",
    "#     # os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "#     # cities.to_csv(output_path, index=False)\n",
    "#     # print(f\"✅ Datei wurde gespeichert: {output_path}\")\n",
    "    \n",
    "#     # cities=cities['City'].tolist()\n",
    "#     # df = df[df['City'].isin(cities)]\n",
    "\n",
    "#     df = df.groupby([\"Date\", \"Country\", \"City\", \"Specie\"], as_index=False).agg({\"median\": \"mean\"})  \n",
    "\n",
    "#     df = df.pivot(index=[\"Date\", \"Country\", \"City\"], columns=\"Specie\", values='median').reset_index()\n",
    "\n",
    "#     output_path = './data/cleaned_data.csv'\n",
    "#     os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "#     df.to_csv(output_path, index=False)\n",
    "#     print(f\"✅ Datei wurde gespeichert: {output_path}\")\n",
    "\n",
    "#     return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_, weather_data = data_cleaning(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.head().T\n",
    "weather_data.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.merge(df_, weather_data, on=[\"City\", 'Date'],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=data_cleaning(df)\n",
    "# print(df.shape)\n",
    "# df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cities = df[['City', 'Latitude', 'Longitude']]\n",
    "# print(cities.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from meteostat import Stations\n",
    "\n",
    "# # Test mit einer Stadt\n",
    "# city = {'City': 'Berlin', 'Latitude': 52.5200, 'Longitude': 13.4050}\n",
    "\n",
    "# # Nächste Wetterstation suchen\n",
    "# stations = Stations().nearby(city['Latitude'], city['Longitude'])\n",
    "# station = stations.fetch(5)  # Hol dir mal die nächsten 5 Stationen zum Vergleich\n",
    "\n",
    "# print(station)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from meteostat import Daily\n",
    "# from datetime import datetime\n",
    "\n",
    "# # Test mit der ersten Station\n",
    "# start = datetime(2023, 1, 1)\n",
    "# end = datetime(2023, 1, 31)\n",
    "\n",
    "# if not station.empty:\n",
    "#     station_id = station.index[0]\n",
    "#     print(f\"📡 Verwende Station: {station_id}\")\n",
    "\n",
    "#     # Tägliche Wetterdaten abrufen\n",
    "#     data = Daily(station_id, start, end)\n",
    "#     data = data.fetch()\n",
    "\n",
    "#     print(data.head())\n",
    "# else:\n",
    "#     print(\"⚠️ Keine Wetterstation gefunden!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WEtterdaten integrieren\n",
    "\n",
    "from meteostat import Daily, Stations\n",
    "from datetime import datetime\n",
    "\n",
    "# Städte\n",
    "cities = df[['City', 'Latitude', 'Longitude']].drop_duplicates()\n",
    "\n",
    "# Zeitspanne festlegen\n",
    "start = datetime(2015, 1, 1)\n",
    "end = datetime(2024, 12, 31)\n",
    "\n",
    "# DataFrame für alle Städte vorbereiten\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "# Daten für jede Stadt abrufen und hinzufügen\n",
    "for _, city in cities.iterrows():\n",
    "    # Nächste Wetterstation suchen\n",
    "    stations = Stations().nearby(city['Latitude'], city['Longitude'])\n",
    "    station = stations.fetch(1)\n",
    "\n",
    "    if not station.empty:\n",
    "        station_id = station.index[0]\n",
    "\n",
    "        # Tägliche Wetterdaten abrufen\n",
    "        data = Daily(station_id, start, end).fetch()\n",
    "\n",
    "        # Nan-Daten rausfiltern\n",
    "        data.dropna(how='all', inplace=True)\n",
    "\n",
    "        if not data.empty:\n",
    "            # Stadtname hinzufügen\n",
    "            data[\"City\"] = city[\"City\"]\n",
    "\n",
    "            # Daten in den Gesamtdaten-Frame einfügen\n",
    "            all_data = pd.concat([all_data, data])\n",
    "\n",
    "    # if station.empty:\n",
    "    #     print(f\"⚠️ Keine Wetterstation für {city['City']} gefunden, übersprungen.\")\n",
    "    #     continue\n",
    "\n",
    "    # # Tägliche Wetterdaten abrufen\n",
    "    # data = Daily(station.index[0], start, end)\n",
    "    # data = data.fetch()\n",
    "\n",
    "    # if data.empty:\n",
    "    #     print(f\"⚠️ Keine Wetterdaten für {city['City']} gefunden, übersprungen.\")\n",
    "    #     continue\n",
    "\n",
    "    # # Stadtname hinzufügen\n",
    "    # data[\"City\"] = city[\"City\"]\n",
    "\n",
    "    # # Daten in den Gesamtdaten-Frame einfügen\n",
    "    # all_data = pd.concat([all_data, data])\n",
    "\n",
    "# Index zurücksetzen\n",
    "all_data.reset_index(inplace=True)\n",
    "\n",
    "# Spalte time umbennen in Date\n",
    "all_data.rename(columns={'time': 'Date'}, inplace=True) \n",
    "\n",
    "# Standardisiere den Stadtnamen für eine bessere Übereinstimmung\n",
    "all_data[\"City\"] = all_data[\"City\"].str.lower().str.strip()\n",
    "\n",
    "print(f\"✅ Wetterdaten gesammelt für {all_data['City'].nunique()} Städte\")\n",
    "\n",
    "# # Ergebnis anzeigen\n",
    "print(all_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from meteostat import Daily, Stations\n",
    "from datetime import datetime\n",
    "\n",
    "def add_weather(df):\n",
    "    \"\"\"Fügt die Wetterdaten zu den Städten hinzu\n",
    "    \"\"\"\n",
    "    # Städte\n",
    "    cities = df[['City', 'Latitude', 'Longitude']].drop_duplicates()\n",
    "\n",
    "    # Zeitspanne festlegen\n",
    "    start = datetime(2015, 1, 1)\n",
    "    end = datetime(2024, 12, 31)\n",
    "\n",
    "    # DataFrame für alle Städte vorbereiten\n",
    "    all_data = pd.DataFrame()\n",
    "\n",
    "    # Daten für jede Stadt abrufen und hinzufügen\n",
    "    for _, city in cities.iterrows():\n",
    "        # Nächste Wetterstation suchen\n",
    "        stations = Stations().nearby(city['Latitude'], city['Longitude'])\n",
    "        station = stations.fetch(1)\n",
    "\n",
    "        if not station.empty:\n",
    "            station_id = station.index[0]\n",
    "\n",
    "            # Tägliche Wetterdaten abrufen\n",
    "            data = Daily(station_id, start, end).fetch()\n",
    "\n",
    "            # Nan-Daten rausfiltern\n",
    "            data.dropna(how='all', inplace=True)\n",
    "\n",
    "            if not data.empty:\n",
    "                # Stadtname hinzufügen\n",
    "                data[\"City\"] = city[\"City\"]\n",
    "\n",
    "                # Daten in den Gesamtdaten-Frame einfügen\n",
    "                all_data = pd.concat([all_data, data])\n",
    "\n",
    "    # Index zurücksetzen\n",
    "    all_data.reset_index(inplace=True)\n",
    "\n",
    "    # Spalte time umbennen in Date\n",
    "    all_data.rename(columns={'time': 'Date'}, inplace=True) \n",
    "\n",
    "    # Standardisiere den Stadtnamen für eine bessere Übereinstimmung\n",
    "    all_data[\"City\"] = all_data[\"City\"].str.lower().str.strip()\n",
    "\n",
    "    # Datum formatieren für bessere Übereinstimmung\n",
    "    all_data['Date'] = pd.to_datetime(all_data['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    # Berechne den Anteil der NaN-Werte pro Spalte\n",
    "    missing_percentage = all_data.isna().mean() * 100\n",
    "    # Lösche die Spalten, bei denen der Anteil an NaN-Werten größer als 80% ist\n",
    "    all_data = all_data.loc[:, missing_percentage <= 80]\n",
    "    \n",
    "    print(f\"✅ Wetterdaten gesammelt für {all_data['City'].nunique()} Städte\")    \n",
    "\n",
    "    return all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = add_weather(df)\n",
    "print(weather.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zusammenführen der beiden DataFrames über \"City und Date\"\n",
    "df = pd.merge(df, all_data, on=[\"City\", 'Date'],how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = add_weather(df)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'Date' column to datetime\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Split 'Date' column into 'year', 'month' and 'day'\n",
    "df['year'] = df['Date'].dt.year\n",
    "df['month'] = df['Date'].dt.month\n",
    "df['day'] = df['Date'].dt.day\n",
    "\n",
    "# Remove 'Date' column\n",
    "if 'Date' in df.columns:\n",
    "    df.drop(columns=['Date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(5).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #print(df[['City', 'Date']].head())\n",
    "# print(all_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df['Date'].dtype)\n",
    "# print(all_data['Date'].dtype)\n",
    "# print(df['City'].dtype)\n",
    "# print(all_data['City'].dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(df['City'].unique())\n",
    "# print(all_data['City'].unique())\n",
    "\n",
    "# print(set(df['Date']).difference(set(all_data['Date'])))\n",
    "# print(set(df['City']).difference(set(all_data['City'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# print(type(df))\n",
    "# print(type(all_data))\n",
    "\n",
    "# print(df.shape)\n",
    "# print(all_data.shape)\n",
    "\n",
    "\n",
    "# Konvertiere die 'Date' Spalte in beiden DataFrames zu datetime\n",
    "df['Date'] = pd.to_datetime(df['Date']).dt.strftime('%Y-%m-%d')\n",
    "all_data['Date'] = pd.to_datetime(all_data['Date']).dt.strftime('%Y-%m-%d')\n",
    "\n",
    "#print(len(set(df['Date']).difference(set(all_data['Date']))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_data.sample(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Funktion für Übersicht über dtypes, missing values, unique values etc.\n",
    "# def overview(df):\n",
    "#     '''\n",
    "#     Erstelle einen Überblick über einige Eigenschaften der Spalten eines DataFrames.\n",
    "#     VARs\n",
    "#         df: Der zu betrachtende DataFrame\n",
    "#     RETURNS:\n",
    "#         None\n",
    "#     '''\n",
    "#     display(pd.DataFrame({'dtype': df.dtypes,\n",
    "#                           'total': df.count(),\n",
    "#                           'missing': df.isna().sum(),\n",
    "#                           'missing%': df.isna().mean()*100,\n",
    "#                           'n_uniques': df.nunique(),\n",
    "#                           'uniques%': df.nunique()/df.shape[0]*100,\n",
    "#                           'uniques': [df[col].unique() for col in df.columns]\n",
    "#                          }))\n",
    "# overview(all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Berechne den Anteil der NaN-Werte pro Spalte\n",
    "missing_percentage = all_data.isna().mean() * 100\n",
    "\n",
    "# Lösche die Spalten, bei denen der Anteil an NaN-Werten größer als 80% ist\n",
    "all_data = all_data.loc[:, missing_percentage <= 80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Zusammenführen der beiden DataFrames über \"City\"\n",
    "df = pd.merge(df, all_data, on=[\"City\", 'Date'],how=\"left\")\n",
    "print(df.shape)\n",
    "df.sample(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.sample(5).T)\n",
    "#df.isna().sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
