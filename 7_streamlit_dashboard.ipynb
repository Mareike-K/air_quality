{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dashboard \n",
    "\n",
    "*Disclaimer: Das Dashboard wurde zunächst mit Vise-Coding aufgebaut: Es wurde mit ChatGPT konzipiert und in allen Details manuell optimiert.*\n",
    "\n",
    "Zum Abschluss des Projekts soll ein interaktives Dashboard mit Streamlit erstellt werden.\n",
    "\n",
    "in einem ersten Schritt wird ein MVP (Minimal Viable Product) entworfen, um die Funktionalitäten zu entwickeln und zu testen. Das MVP enthält nur Daten aus drei Städten: Hamburg, Berlin und Karlsruhe.\n",
    "\n",
    "Der Datensatz für das MVP ist gespeichert als `test_dashboard_air_quality.csv`.\n",
    "\n",
    "Note to self: Run app from VS Code terminal with \"uv run streamlit run app.py\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧭 Plan für das Streamlit-Dashboard zur Luftqualität\n",
    "\n",
    "## ✅ 1. Basisfunktionen (bereits umgesetzt oder fast fertig):\n",
    "\n",
    "- Dropdown zur Stadtauswahl (Stadt A & Stadt B)\n",
    "- Dropdown zur Schadstoffauswahl (z. B. PM2.5, NO₂, SO₂, O₃, CO)\n",
    "- Liniendiagramm mit dem gewählten Schadstoff über die Zeit\n",
    "- Vergleich zweier Städte im gemeinsamen Diagramm\n",
    "- Achsen-Labels und Titel verbessern (PM2.5 statt „Pm25“ usw.)\n",
    "\n",
    "## 🧩 2. Nächste Ausbaustufe (geplant):\n",
    "a) Zusätzliche Filtermöglichkeiten\n",
    "\n",
    "- Auswahl eines Jahres oder Monats (Slider oder Selectbox)\n",
    "- Filter nach Jahreszeit (z. B. Frühling, Sommer...)\n",
    "\n",
    "b) Statistische Kennzahlen\n",
    "\n",
    "- Durchschnitt, Minimum, Maximum des gewählten Schadstoffs für jede Stadt\n",
    "- Darstellung unterhalb des Plots oder in einer kleinen Infobox\n",
    "\n",
    "c) Darstellung Wetterdaten\n",
    "\n",
    "- Auswahl eines Wetterparameters (Tavg, Humidity, etc.)\n",
    "- Zweiter Plot oder zusätzliche Linie im selben Plot (Sekundärachse)\n",
    "\n",
    "## 🖼 3. Späterer Ausbau (optional):\n",
    "a) Interaktive Visualisierungen mit Plotly\n",
    "\n",
    "- Hover-Effekte, dynamisches Zoomen, bessere Tooltips\n",
    "\n",
    "b) Karte mit Clusterfarben\n",
    "\n",
    "- z. B. Städte auf einer Karte mit Farben nach Cluster oder Mittelwert PM2.5\n",
    "\n",
    "c) Infoboxen / Erläuterungen\n",
    "\n",
    "- Kleine Textboxen mit verständlichen Erklärungen zur Interpretation der Daten\n",
    "- Z. B. „PM2.5 ist Feinstaub unter 2.5 Mikrometer…“\n",
    "\n",
    "d) Dashboard mit Datums- und Städteauswahl\n",
    "\n",
    "- Auswahl eines Datums → Anzeige der Messwerte für alle Variablen\n",
    "- Interaktive Heatmap oder Vergleichstabelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📚 Inhaltsverzeichnis \n",
    "(Diese Art von Inhaltsverzeichnis mit Link funktioniert leider in Notebooks nicht, weil die as JSON gespeichert werden und nicht als HTML...)\n",
    "\n",
    "- [0. Datensatz laden](#0-datensatz-laden)\n",
    "- [1. Dataframe für MVP vorbereiten]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Datensatz laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/cleaned_air_quality_data_2025-03-27.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataframe für MVP vorbereiten\n",
    "\n",
    "Für das MVP sollten drei Städte gewählt werden, die möglichst vollständige Messdaten für alle relevanten Variablen übermittelt haben, damit die Funktionalitäten gut getestet werden können. Auch sollte die Anzahl an Datenpunkten pro Stadt ausreichend sein und den geamten relevanten Zeitraum abdecken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: nur Spalten betrachten, die im Dashboard relevant sind\n",
    "relevante_spalten = [\"City\", \"Year\", \"Month\", \"Day\", \"Pm25\", \"Co\", \"No2\", \"So2\", \"O3\", \"Tavg\", \"Humidity\"]\n",
    "df = df[relevante_spalten]\n",
    "\n",
    "# NaN-Anzahl je Stadt berechnen (über alle relevanten Spalten hinweg)\n",
    "stadt_nan = df.groupby(\"City\").apply(lambda x: x.isna().sum().sum())\n",
    "\n",
    "# Alternativ: Anteil an NaN-Werten je Stadt\n",
    "stadt_nan_anteil = df.groupby(\"City\").apply(lambda x: x.isna().mean().mean())\n",
    "\n",
    "# Sortieren: Städte mit den wenigsten fehlenden Werten zuerst\n",
    "stadt_nan = stadt_nan.sort_values()\n",
    "stadt_nan_anteil = stadt_nan_anteil.sort_values()\n",
    "\n",
    "# Die Top 10 anzeigen\n",
    "print(\"Städte mit absolut wenigsten NaNs:\")\n",
    "print(stadt_nan.head(10))\n",
    "\n",
    "print(\"\\nStädte mit dem geringsten Anteil an NaNs:\")\n",
    "print(stadt_nan_anteil.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste der drei gewünschten Städte\n",
    "städte = [\"Delhi\", \"Tokyo\", \"Osaka\"]\n",
    "\n",
    "# Relevante Spalten definieren\n",
    "relevante_spalten = [\"Pm25\", \"Co\", \"No2\", \"So2\", \"O3\", \"Tavg\", \"Humidity\"]\n",
    "\n",
    "# DataFrame auf die drei Städte und die relevanten Spalten beschränken\n",
    "df_subset = df[df[\"City\"].isin(städte)][[\"City\"] + relevante_spalten]\n",
    "\n",
    "# Fehlende Werte je Stadt und Variable zählen\n",
    "fehlende_werte = df_subset.groupby(\"City\").apply(lambda x: x[relevante_spalten].isna().sum())\n",
    "\n",
    "# Alternativ: Anteil an NaN-Werten je Stadt und Variable\n",
    "anteil_nan = df_subset.groupby(\"City\").apply(lambda x: x[relevante_spalten].isna().mean())\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "print(\"Anzahl fehlender Werte:\")\n",
    "print(fehlende_werte)\n",
    "\n",
    "print(\"\\nAnteil fehlender Werte:\")\n",
    "print(anteil_nan.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-DataFrame für das Dashboard erstellen\n",
    "df_mvp = df[df[\"City\"].isin([\"Delhi\", \"Tokyo\", \"Osaka\"])].copy()\n",
    "\n",
    "# Relevante Spalten wählen\n",
    "columns = [\"Year\", \"Month\", \"Day\", \"City\", \"Pm25\", \"Co\", \"No2\", \"So2\", \"O3\", \"Tavg\", \"Humidity\"]\n",
    "df_mvp = df_mvp[columns]\n",
    "\n",
    "# Fürs MVP: nur Zeilen ohne NaNs behalten\n",
    "df_mvp.dropna(inplace=True)\n",
    "\n",
    "# In Datei speichern\n",
    "df_mvp.to_csv(\"data/test_dashboard_air_quality.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zeitreihenzerlegung für die Teststädte, analog zu NB 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date column\n",
    "df_mvp[\"Date\"] = pd.to_datetime(df_mvp[[\"Year\", \"Month\", \"Day\"]])\n",
    "# Set date as index\n",
    "df_mvp.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Plotting\n",
    "# plt.figure(figsize=(14, 7))\n",
    "# plt.plot(df_mvp[df_mvp[\"City\"] == \"Delhi\"][\"Pm25\"], label=\"Delhi Pm25\")\n",
    "# plt.plot(df_mvp[df_mvp[\"City\"] == \"Tokyo\"][\"Pm25\"], label=\"Tokyo Pm25\")\n",
    "# plt.plot(df_mvp[df_mvp[\"City\"] == \"Osaka\"][\"Pm25\"], label=\"Osaka Pm25\")\n",
    "# plt.title(\"Pm25 Levels in Delhi, Tokyo, and Osaka\")\n",
    "# plt.xlabel(\"Date\")\n",
    "# plt.ylabel(\"Pm25 Levels\")\n",
    "# plt.legend()\n",
    "# plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Osaka\n",
    "df_osaka = df_mvp[df_mvp[\"City\"] == \"Osaka\"].copy()\n",
    "df_osaka.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokyo\n",
    "df_tokyo = df_mvp[df_mvp[\"City\"] == \"Tokyo\"].copy()\n",
    "df_tokyo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delhi\n",
    "df_delhi = df_mvp[df_mvp[\"City\"] == \"Delhi\"].copy()\n",
    "df_delhi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Filtern: Nur Daten von 2015 bis 2024 behalten\n",
    "df_tokyo_filtered = df_tokyo[(df_tokyo.index.year >= 2015) & (df_tokyo.index.year <= 2024)]\n",
    "\n",
    "# Überprüfen, welche Jahre jetzt enthalten sind\n",
    "print(\"Enthaltene Jahre:\", sorted(df_tokyo_filtered.index.year.unique()))\n",
    "\n",
    "# Aggregiere die PM2.5-Daten auf monatlicher Basis (mittlere Werte)\n",
    "df_tokyo_monthly = df_tokyo_filtered['Pm25'].resample('M').mean().dropna()\n",
    "\n",
    "# Zeitreihenzerlegung (additives Modell mit period=12 für monatliche Daten\n",
    "result = seasonal_decompose(df_tokyo_monthly, model='additive', period=12)\n",
    "\n",
    "# Visualisierung der Zerlegung\n",
    "result.plot()\n",
    "\n",
    "plt.suptitle('Zeitreihenzerlegung der monatlichen PM2.5-Daten in Tokyo (2015-2024)', fontsize=16)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend extrahieren und als DataFrame speichern\n",
    "trend_tokyo = result.trend.dropna().reset_index()\n",
    "trend_tokyo.columns = [\"Datum\", \"Trend\"]\n",
    "trend_tokyo[\"City\"] = \"Tokyo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_tokyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Filtern: Nur Daten von 2015 bis 2024 behalten\n",
    "df_osaka_filtered = df_osaka[(df_osaka.index.year >= 2015) & (df_osaka.index.year <= 2024)]\n",
    "\n",
    "# Überprüfen, welche Jahre jetzt enthalten sind\n",
    "print(\"Enthaltene Jahre:\", sorted(df_osaka_filtered.index.year.unique()))\n",
    "\n",
    "# Aggregiere die PM2.5-Daten auf monatlicher Basis (mittlere Werte)\n",
    "df_osaka_monthly = df_osaka_filtered['Pm25'].resample('M').mean().dropna()\n",
    "\n",
    "# Zeitreihenzerlegung (additives Modell mit period=12 für monatliche Daten\n",
    "result = seasonal_decompose(df_osaka_monthly, model='additive', period=12)\n",
    "\n",
    "# Visualisierung der Zerlegung\n",
    "result.plot()\n",
    "\n",
    "plt.suptitle('Zeitreihenzerlegung der monatlichen PM2.5-Daten in Osaka (2015-2024)', fontsize=16)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend extrahieren und als DataFrame speichern\n",
    "trend_osaka = result.trend.dropna().reset_index()\n",
    "trend_osaka.columns = [\"Datum\", \"Trend\"]\n",
    "trend_osaka[\"City\"] = \"Osaka\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_osaka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Filtern: Nur Daten von 2015 bis 2024 behalten\n",
    "df_delhi_filtered = df_delhi[(df_delhi.index.year >= 2015) & (df_delhi.index.year <= 2024)]\n",
    "\n",
    "# Überprüfen, welche Jahre jetzt enthalten sind\n",
    "print(\"Enthaltene Jahre:\", sorted(df_delhi_filtered.index.year.unique()))\n",
    "\n",
    "# Aggregiere die PM2.5-Daten auf monatlicher Basis (mittlere Werte)\n",
    "df_delhi_monthly = df_delhi_filtered['Pm25'].resample('M').mean().dropna()\n",
    "\n",
    "# Zeitreihenzerlegung (additives Modell mit period=12 für monatliche Daten\n",
    "result = seasonal_decompose(df_delhi_monthly, model='additive', period=12)\n",
    "\n",
    "# Visualisierung der Zerlegung\n",
    "result.plot()\n",
    "\n",
    "plt.suptitle('Zeitreihenzerlegung der monatlichen PM2.5-Daten in Delhi (2015-2024)', fontsize=16)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend extrahieren und als DataFrame speichern\n",
    "trend_delhi = result.trend.dropna().reset_index()\n",
    "trend_delhi.columns = [\"Datum\", \"Trend\"]\n",
    "trend_delhi[\"City\"] = \"Delhi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_delhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_gesamt = pd.concat([trend_tokyo, trend_osaka, trend_delhi], ignore_index=True)\n",
    "trend_gesamt.to_csv(\"data/trendlinien_pm25.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trend = pd.read_csv(\"data/trendlinien_pm25.csv\")\n",
    "print(df_trend[\"City\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dokumentation\n",
    "\n",
    "Was man später beim Skalieren nicht vergesen darf:\n",
    "\n",
    "Liniendiagramm:\n",
    "\n",
    "✅ Mein Plan für den skalierbaren Umgang mit mehr Städten:\n",
    "🔹 1. Stadtanzahl begrenzen (z. B. Top 10 nach Jahresmittelwert)\n",
    "\n",
    "# Top 10 Städte mit höchsten Mittelwerten im letzten Jahr\n",
    "top_staedte = df_letztes_jahr.sort_values(by=auswahl, ascending=False).head(10)\n",
    "\n",
    "So bleibt das Diagramm übersichtlich und zeigt die „interessantesten Fälle“ zuerst.\n",
    "\n",
    "🔹 2. Farben automatisch generieren (mit Colormap)\n",
    "\n",
    "Wir lassen Matplotlib die Farben aus einer Farbpalette wählen – z. B. \"viridis\", \"plasma\", \"Set2\", \"tab10\", etc.\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "# Colormap definieren\n",
    "cmap = cm.get_cmap(\"tab10\", len(top_staedte))\n",
    "\n",
    "# Farben automatisch zuweisen\n",
    "colors = [cmap(i) for i in range(len(top_staedte))]\n",
    "\n",
    "\n",
    "Dann beim Plotten:\n",
    "\n",
    "ax_bar.bar(\n",
    "    top_staedte[\"City\"],\n",
    "    top_staedte[auswahl],\n",
    "    color=colors\n",
    ")\n",
    "\n",
    "🔹 3. Optional: Dropdown mit Städteauswahl oder Jahr\n",
    "\n",
    "So kann man z. B. sagen:\n",
    "\n",
    "    „Zeig mir die Top 10 Städte im Jahr 2022“\n",
    "    oder\n",
    "    „Zeig mir die 5 Städte mit der niedrigsten NO₂-Belastung im aktuellen Jahr“\n",
    "\n",
    "🎁 Fazit für später:\n",
    "\n",
    "Wenn du den Datensatz erweiterst, dann machen wir:\n",
    "\n",
    "    intelligente Auswahl, z. B. Top 10\n",
    "\n",
    "    automatische Farben\n",
    "\n",
    "    flexible Steuerung durch Dropdown oder Slider\n",
    "\n",
    "So bleibt dein Dashboard schön, verständlich und performant – auch bei vielen Städten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skalieren der Trendlinien\n",
    "# seasonal_decompose rechnet nicht so schnell, deshalb sollte man die Daten vorher abspeichern.\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Original-DataFrame mit vielen Städten\n",
    "df = pd.read_csv(\"deine_komplettdaten.csv\")\n",
    "df[\"Datum\"] = pd.to_datetime(df[[\"Year\", \"Month\", \"Day\"]])\n",
    "df = df.set_index(\"Datum\")\n",
    "\n",
    "alle_staedte = df[\"City\"].unique()\n",
    "alle_trends = []\n",
    "\n",
    "for stadt in alle_staedte:\n",
    "    df_stadt = df[df[\"City\"] == stadt][\"Pm25\"].resample(\"M\").mean().dropna()\n",
    "\n",
    "    if len(df_stadt) < 24:  # Sicherstellen: genug Daten für Trendberechnung\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        result = seasonal_decompose(df_stadt, model=\"additive\", period=12)\n",
    "        trend = result.trend.dropna().reset_index()\n",
    "        trend.columns = [\"Datum\", \"Trend\"]\n",
    "        trend[\"City\"] = stadt\n",
    "        alle_trends.append(trend)\n",
    "    except:\n",
    "        print(f\"Fehler bei Stadt: {stadt}\")\n",
    "        continue\n",
    "\n",
    "# Alles zusammenführen\n",
    "trend_gesamt = pd.concat(alle_trends, ignore_index=True)\n",
    "\n",
    "# Speichern\n",
    "trend_gesamt.to_csv(\"data/trendlinien_pm25_alle_staedte.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
