{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dashboard \n",
    "\n",
    "*Disclaimer: Das Dashboard wurde zunÃ¤chst mit Vise-Coding aufgebaut: Es wurde mit ChatGPT konzipiert und in allen Details manuell optimiert.*\n",
    "\n",
    "Zum Abschluss des Projekts soll ein interaktives Dashboard mit Streamlit erstellt werden.\n",
    "\n",
    "in einem ersten Schritt wird ein MVP (Minimal Viable Product) entworfen, um die FunktionalitÃ¤ten zu entwickeln und zu testen. Das MVP enthÃ¤lt nur Daten aus drei StÃ¤dten: Hamburg, Berlin und Karlsruhe.\n",
    "\n",
    "Der Datensatz fÃ¼r das MVP ist gespeichert als `test_dashboard_air_quality.csv`.\n",
    "\n",
    "Note to self: Run app from VS Code terminal with \"uv run streamlit run app.py\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§­ Plan fÃ¼r das Streamlit-Dashboard zur LuftqualitÃ¤t\n",
    "\n",
    "## âœ… 1. Basisfunktionen (bereits umgesetzt oder fast fertig):\n",
    "\n",
    "- Dropdown zur Stadtauswahl (Stadt A & Stadt B)\n",
    "- Dropdown zur Schadstoffauswahl (z.â€¯B. PM2.5, NOâ‚‚, SOâ‚‚, Oâ‚ƒ, CO)\n",
    "- Liniendiagramm mit dem gewÃ¤hlten Schadstoff Ã¼ber die Zeit\n",
    "- Vergleich zweier StÃ¤dte im gemeinsamen Diagramm\n",
    "- Achsen-Labels und Titel verbessern (PM2.5 statt â€žPm25â€œ usw.)\n",
    "\n",
    "## ðŸ§© 2. NÃ¤chste Ausbaustufe (geplant):\n",
    "a) ZusÃ¤tzliche FiltermÃ¶glichkeiten\n",
    "\n",
    "- Auswahl eines Jahres oder Monats (Slider oder Selectbox)\n",
    "- Filter nach Jahreszeit (z.â€¯B. FrÃ¼hling, Sommer...)\n",
    "\n",
    "b) Statistische Kennzahlen\n",
    "\n",
    "- Durchschnitt, Minimum, Maximum des gewÃ¤hlten Schadstoffs fÃ¼r jede Stadt\n",
    "- Darstellung unterhalb des Plots oder in einer kleinen Infobox\n",
    "\n",
    "c) Darstellung Wetterdaten\n",
    "\n",
    "- Auswahl eines Wetterparameters (Tavg, Humidity, etc.)\n",
    "- Zweiter Plot oder zusÃ¤tzliche Linie im selben Plot (SekundÃ¤rachse)\n",
    "\n",
    "## ðŸ–¼ 3. SpÃ¤terer Ausbau (optional):\n",
    "a) Interaktive Visualisierungen mit Plotly\n",
    "\n",
    "- Hover-Effekte, dynamisches Zoomen, bessere Tooltips\n",
    "\n",
    "b) Karte mit Clusterfarben\n",
    "\n",
    "- z.â€¯B. StÃ¤dte auf einer Karte mit Farben nach Cluster oder Mittelwert PM2.5\n",
    "\n",
    "c) Infoboxen / ErlÃ¤uterungen\n",
    "\n",
    "- Kleine Textboxen mit verstÃ¤ndlichen ErklÃ¤rungen zur Interpretation der Daten\n",
    "- Z.â€¯B. â€žPM2.5 ist Feinstaub unter 2.5 Mikrometerâ€¦â€œ\n",
    "\n",
    "d) Dashboard mit Datums- und StÃ¤dteauswahl\n",
    "\n",
    "- Auswahl eines Datums â†’ Anzeige der Messwerte fÃ¼r alle Variablen\n",
    "- Interaktive Heatmap oder Vergleichstabelle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ“š Inhaltsverzeichnis \n",
    "(Diese Art von Inhaltsverzeichnis mit Link funktioniert leider in Notebooks nicht, weil die as JSON gespeichert werden und nicht als HTML...)\n",
    "\n",
    "- [0. Datensatz laden](#0-datensatz-laden)\n",
    "- [1. Dataframe fÃ¼r MVP vorbereiten]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Datensatz laden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/cleaned_air_quality_data_2025-03-27.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dataframe fÃ¼r MVP vorbereiten\n",
    "\n",
    "FÃ¼r das MVP sollten drei StÃ¤dte gewÃ¤hlt werden, die mÃ¶glichst vollstÃ¤ndige Messdaten fÃ¼r alle relevanten Variablen Ã¼bermittelt haben, damit die FunktionalitÃ¤ten gut getestet werden kÃ¶nnen. Auch sollte die Anzahl an Datenpunkten pro Stadt ausreichend sein und den geamten relevanten Zeitraum abdecken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: nur Spalten betrachten, die im Dashboard relevant sind\n",
    "relevante_spalten = [\"City\", \"Year\", \"Month\", \"Day\", \"Pm25\", \"Co\", \"No2\", \"So2\", \"O3\", \"Tavg\", \"Humidity\"]\n",
    "df = df[relevante_spalten]\n",
    "\n",
    "# NaN-Anzahl je Stadt berechnen (Ã¼ber alle relevanten Spalten hinweg)\n",
    "stadt_nan = df.groupby(\"City\").apply(lambda x: x.isna().sum().sum())\n",
    "\n",
    "# Alternativ: Anteil an NaN-Werten je Stadt\n",
    "stadt_nan_anteil = df.groupby(\"City\").apply(lambda x: x.isna().mean().mean())\n",
    "\n",
    "# Sortieren: StÃ¤dte mit den wenigsten fehlenden Werten zuerst\n",
    "stadt_nan = stadt_nan.sort_values()\n",
    "stadt_nan_anteil = stadt_nan_anteil.sort_values()\n",
    "\n",
    "# Die Top 10 anzeigen\n",
    "print(\"StÃ¤dte mit absolut wenigsten NaNs:\")\n",
    "print(stadt_nan.head(10))\n",
    "\n",
    "print(\"\\nStÃ¤dte mit dem geringsten Anteil an NaNs:\")\n",
    "print(stadt_nan_anteil.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Liste der drei gewÃ¼nschten StÃ¤dte\n",
    "stÃ¤dte = [\"Delhi\", \"Tokyo\", \"Osaka\"]\n",
    "\n",
    "# Relevante Spalten definieren\n",
    "relevante_spalten = [\"Pm25\", \"Co\", \"No2\", \"So2\", \"O3\", \"Tavg\", \"Humidity\"]\n",
    "\n",
    "# DataFrame auf die drei StÃ¤dte und die relevanten Spalten beschrÃ¤nken\n",
    "df_subset = df[df[\"City\"].isin(stÃ¤dte)][[\"City\"] + relevante_spalten]\n",
    "\n",
    "# Fehlende Werte je Stadt und Variable zÃ¤hlen\n",
    "fehlende_werte = df_subset.groupby(\"City\").apply(lambda x: x[relevante_spalten].isna().sum())\n",
    "\n",
    "# Alternativ: Anteil an NaN-Werten je Stadt und Variable\n",
    "anteil_nan = df_subset.groupby(\"City\").apply(lambda x: x[relevante_spalten].isna().mean())\n",
    "\n",
    "# Ergebnisse anzeigen\n",
    "print(\"Anzahl fehlender Werte:\")\n",
    "print(fehlende_werte)\n",
    "\n",
    "print(\"\\nAnteil fehlender Werte:\")\n",
    "print(anteil_nan.round(2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-DataFrame fÃ¼r das Dashboard erstellen\n",
    "df_mvp = df[df[\"City\"].isin([\"Delhi\", \"Tokyo\", \"Osaka\"])].copy()\n",
    "\n",
    "# Relevante Spalten wÃ¤hlen\n",
    "columns = [\"Year\", \"Month\", \"Day\", \"City\", \"Pm25\", \"Co\", \"No2\", \"So2\", \"O3\", \"Tavg\", \"Humidity\"]\n",
    "df_mvp = df_mvp[columns]\n",
    "\n",
    "# FÃ¼rs MVP: nur Zeilen ohne NaNs behalten\n",
    "df_mvp.dropna(inplace=True)\n",
    "\n",
    "# In Datei speichern\n",
    "df_mvp.to_csv(\"data/test_dashboard_air_quality.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zeitreihenzerlegung fÃ¼r die TeststÃ¤dte, analog zu NB 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create date column\n",
    "df_mvp[\"Date\"] = pd.to_datetime(df_mvp[[\"Year\", \"Month\", \"Day\"]])\n",
    "# Set date as index\n",
    "df_mvp.set_index(\"Date\", inplace=True)\n",
    "\n",
    "# Plotting\n",
    "# plt.figure(figsize=(14, 7))\n",
    "# plt.plot(df_mvp[df_mvp[\"City\"] == \"Delhi\"][\"Pm25\"], label=\"Delhi Pm25\")\n",
    "# plt.plot(df_mvp[df_mvp[\"City\"] == \"Tokyo\"][\"Pm25\"], label=\"Tokyo Pm25\")\n",
    "# plt.plot(df_mvp[df_mvp[\"City\"] == \"Osaka\"][\"Pm25\"], label=\"Osaka Pm25\")\n",
    "# plt.title(\"Pm25 Levels in Delhi, Tokyo, and Osaka\")\n",
    "# plt.xlabel(\"Date\")\n",
    "# plt.ylabel(\"Pm25 Levels\")\n",
    "# plt.legend()\n",
    "# plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Osaka\n",
    "df_osaka = df_mvp[df_mvp[\"City\"] == \"Osaka\"].copy()\n",
    "df_osaka.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokyo\n",
    "df_tokyo = df_mvp[df_mvp[\"City\"] == \"Tokyo\"].copy()\n",
    "df_tokyo.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delhi\n",
    "df_delhi = df_mvp[df_mvp[\"City\"] == \"Delhi\"].copy()\n",
    "df_delhi.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Filtern: Nur Daten von 2015 bis 2024 behalten\n",
    "df_tokyo_filtered = df_tokyo[(df_tokyo.index.year >= 2015) & (df_tokyo.index.year <= 2024)]\n",
    "\n",
    "# ÃœberprÃ¼fen, welche Jahre jetzt enthalten sind\n",
    "print(\"Enthaltene Jahre:\", sorted(df_tokyo_filtered.index.year.unique()))\n",
    "\n",
    "# Aggregiere die PM2.5-Daten auf monatlicher Basis (mittlere Werte)\n",
    "df_tokyo_monthly = df_tokyo_filtered['Pm25'].resample('M').mean().dropna()\n",
    "\n",
    "# Zeitreihenzerlegung (additives Modell mit period=12 fÃ¼r monatliche Daten\n",
    "result = seasonal_decompose(df_tokyo_monthly, model='additive', period=12)\n",
    "\n",
    "# Visualisierung der Zerlegung\n",
    "result.plot()\n",
    "\n",
    "plt.suptitle('Zeitreihenzerlegung der monatlichen PM2.5-Daten in Tokyo (2015-2024)', fontsize=16)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend extrahieren und als DataFrame speichern\n",
    "trend_tokyo = result.trend.dropna().reset_index()\n",
    "trend_tokyo.columns = [\"Datum\", \"Trend\"]\n",
    "trend_tokyo[\"City\"] = \"Tokyo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_tokyo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Filtern: Nur Daten von 2015 bis 2024 behalten\n",
    "df_osaka_filtered = df_osaka[(df_osaka.index.year >= 2015) & (df_osaka.index.year <= 2024)]\n",
    "\n",
    "# ÃœberprÃ¼fen, welche Jahre jetzt enthalten sind\n",
    "print(\"Enthaltene Jahre:\", sorted(df_osaka_filtered.index.year.unique()))\n",
    "\n",
    "# Aggregiere die PM2.5-Daten auf monatlicher Basis (mittlere Werte)\n",
    "df_osaka_monthly = df_osaka_filtered['Pm25'].resample('M').mean().dropna()\n",
    "\n",
    "# Zeitreihenzerlegung (additives Modell mit period=12 fÃ¼r monatliche Daten\n",
    "result = seasonal_decompose(df_osaka_monthly, model='additive', period=12)\n",
    "\n",
    "# Visualisierung der Zerlegung\n",
    "result.plot()\n",
    "\n",
    "plt.suptitle('Zeitreihenzerlegung der monatlichen PM2.5-Daten in Osaka (2015-2024)', fontsize=16)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend extrahieren und als DataFrame speichern\n",
    "trend_osaka = result.trend.dropna().reset_index()\n",
    "trend_osaka.columns = [\"Datum\", \"Trend\"]\n",
    "trend_osaka[\"City\"] = \"Osaka\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_osaka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Filtern: Nur Daten von 2015 bis 2024 behalten\n",
    "df_delhi_filtered = df_delhi[(df_delhi.index.year >= 2015) & (df_delhi.index.year <= 2024)]\n",
    "\n",
    "# ÃœberprÃ¼fen, welche Jahre jetzt enthalten sind\n",
    "print(\"Enthaltene Jahre:\", sorted(df_delhi_filtered.index.year.unique()))\n",
    "\n",
    "# Aggregiere die PM2.5-Daten auf monatlicher Basis (mittlere Werte)\n",
    "df_delhi_monthly = df_delhi_filtered['Pm25'].resample('M').mean().dropna()\n",
    "\n",
    "# Zeitreihenzerlegung (additives Modell mit period=12 fÃ¼r monatliche Daten\n",
    "result = seasonal_decompose(df_delhi_monthly, model='additive', period=12)\n",
    "\n",
    "# Visualisierung der Zerlegung\n",
    "result.plot()\n",
    "\n",
    "plt.suptitle('Zeitreihenzerlegung der monatlichen PM2.5-Daten in Delhi (2015-2024)', fontsize=16)\n",
    "plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trend extrahieren und als DataFrame speichern\n",
    "trend_delhi = result.trend.dropna().reset_index()\n",
    "trend_delhi.columns = [\"Datum\", \"Trend\"]\n",
    "trend_delhi[\"City\"] = \"Delhi\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_delhi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_gesamt = pd.concat([trend_tokyo, trend_osaka, trend_delhi], ignore_index=True)\n",
    "trend_gesamt.to_csv(\"data/trendlinien_pm25.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trend = pd.read_csv(\"data/trendlinien_pm25.csv\")\n",
    "print(df_trend[\"City\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Dokumentation\n",
    "\n",
    "Was man spÃ¤ter beim Skalieren nicht vergesen darf:\n",
    "\n",
    "Liniendiagramm:\n",
    "\n",
    "âœ… Mein Plan fÃ¼r den skalierbaren Umgang mit mehr StÃ¤dten:\n",
    "ðŸ”¹ 1. Stadtanzahl begrenzen (z.â€¯B. Top 10 nach Jahresmittelwert)\n",
    "\n",
    "# Top 10 StÃ¤dte mit hÃ¶chsten Mittelwerten im letzten Jahr\n",
    "top_staedte = df_letztes_jahr.sort_values(by=auswahl, ascending=False).head(10)\n",
    "\n",
    "So bleibt das Diagramm Ã¼bersichtlich und zeigt die â€žinteressantesten FÃ¤lleâ€œ zuerst.\n",
    "\n",
    "ðŸ”¹ 2. Farben automatisch generieren (mit Colormap)\n",
    "\n",
    "Wir lassen Matplotlib die Farben aus einer Farbpalette wÃ¤hlen â€“ z.â€¯B. \"viridis\", \"plasma\", \"Set2\", \"tab10\", etc.\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "\n",
    "# Colormap definieren\n",
    "cmap = cm.get_cmap(\"tab10\", len(top_staedte))\n",
    "\n",
    "# Farben automatisch zuweisen\n",
    "colors = [cmap(i) for i in range(len(top_staedte))]\n",
    "\n",
    "\n",
    "Dann beim Plotten:\n",
    "\n",
    "ax_bar.bar(\n",
    "    top_staedte[\"City\"],\n",
    "    top_staedte[auswahl],\n",
    "    color=colors\n",
    ")\n",
    "\n",
    "ðŸ”¹ 3. Optional: Dropdown mit StÃ¤dteauswahl oder Jahr\n",
    "\n",
    "So kann man z.â€¯B. sagen:\n",
    "\n",
    "    â€žZeig mir die Top 10 StÃ¤dte im Jahr 2022â€œ\n",
    "    oder\n",
    "    â€žZeig mir die 5 StÃ¤dte mit der niedrigsten NOâ‚‚-Belastung im aktuellen Jahrâ€œ\n",
    "\n",
    "ðŸŽ Fazit fÃ¼r spÃ¤ter:\n",
    "\n",
    "Wenn du den Datensatz erweiterst, dann machen wir:\n",
    "\n",
    "    intelligente Auswahl, z.â€¯B. Top 10\n",
    "\n",
    "    automatische Farben\n",
    "\n",
    "    flexible Steuerung durch Dropdown oder Slider\n",
    "\n",
    "So bleibt dein Dashboard schÃ¶n, verstÃ¤ndlich und performant â€“ auch bei vielen StÃ¤dten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Skalieren der Trendlinien\n",
    "# seasonal_decompose rechnet nicht so schnell, deshalb sollte man die Daten vorher abspeichern.\n",
    "\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "\n",
    "# Original-DataFrame mit vielen StÃ¤dten\n",
    "df = pd.read_csv(\"deine_komplettdaten.csv\")\n",
    "df[\"Datum\"] = pd.to_datetime(df[[\"Year\", \"Month\", \"Day\"]])\n",
    "df = df.set_index(\"Datum\")\n",
    "\n",
    "alle_staedte = df[\"City\"].unique()\n",
    "alle_trends = []\n",
    "\n",
    "for stadt in alle_staedte:\n",
    "    df_stadt = df[df[\"City\"] == stadt][\"Pm25\"].resample(\"M\").mean().dropna()\n",
    "\n",
    "    if len(df_stadt) < 24:  # Sicherstellen: genug Daten fÃ¼r Trendberechnung\n",
    "        continue\n",
    "\n",
    "    try:\n",
    "        result = seasonal_decompose(df_stadt, model=\"additive\", period=12)\n",
    "        trend = result.trend.dropna().reset_index()\n",
    "        trend.columns = [\"Datum\", \"Trend\"]\n",
    "        trend[\"City\"] = stadt\n",
    "        alle_trends.append(trend)\n",
    "    except:\n",
    "        print(f\"Fehler bei Stadt: {stadt}\")\n",
    "        continue\n",
    "\n",
    "# Alles zusammenfÃ¼hren\n",
    "trend_gesamt = pd.concat(alle_trends, ignore_index=True)\n",
    "\n",
    "# Speichern\n",
    "trend_gesamt.to_csv(\"data/trendlinien_pm25_alle_staedte.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
